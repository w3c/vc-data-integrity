<!DOCTYPE html>
<html>
<head>
    <title>Verifiable Credential Data Integrity 1.0</title>
    <meta http-equiv='Content-Type' content='text/html;charset=utf-8'/>
    <!--
      === NOTA BENE ===
      For the three scripts below, if your spec resides on dev.w3 you can check them
      out in the same tree and use relative links so that they'll work offline,
     -->
    <script src='//www.w3.org/Tools/respec/respec-w3c' class='remove'></script>
    <script class='remove' src="./common.js"></script>

    <script type="text/javascript" class="remove">
      var respecConfig = {
          // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
          specStatus:           "ED",

          // the specification's short name, as in http://www.w3.org/TR/short-name/
          shortName:            "vc-data-integrity",

          // subtitle
          subtitle: "Securing the Integrity of Verifiable Credential Data",

          // if you wish the publication date to be other than today, set this
          // publishDate:  "2009-08-06",

          // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
          // and its maturity status
          // previousPublishDate:  "1977-03-15",
          // previousMaturity:  "WD",

          // if there a publicly available Editor's Draft, this is the link
          edDraftURI:           "https://w3c.github.io/vc-data-integrity/",

          // if this is a LCWD, uncomment and set the end of its review period
          // lcEnd: "2009-08-05",

          // if you want to have extra CSS, append them to this list
          // it is recommended that the respec.css stylesheet be kept
          //extraCSS:             ["spec.css", "prettify.css"],

          // editors, add as many as you like
          // only "name" is required
          editors: [{
            name: "Manu Sporny", url: "https://digitalbazaar.com/",
            company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/"
          }, {
            name: "Dave Longley", url: "https://digitalbazaar.com/",
            company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/",
            note: "2014-2022"
          }, {
            name: "Mike Prorock", url: "https://www.linkedin.com/in/mprorock",
            company: "Mesur.io", companyURL: "https://mesur.io/"
          }],

          // authors, add as many as you like.
          // This is optional, uncomment if you have authors as well as editors.
          // only "name" is required. Same format as editors.

          authors:  [
              { name: "Dave Longley", url: "http://digitalbazaar.com/",
                company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/" },
              { name: "Manu Sporny", url: "http://digitalbazaar.com/",
                company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/" }
          ],

          // extend the bibliography entries
          //localBiblio: webpayments.localBiblio,

          // name of the WG
          group:           "vc",

          // name (with the @w3c.org) of the public mailing to which comments are due
          wgPublicList: "public-credentials",

          github: "w3c/vc-data-integrity",

          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          wgPatentURI:  "",
          maxTocLevel: 3,
          /*preProcess: [ webpayments.preProcess ],
          alternateFormats: [ {uri: "diff-20111214.html", label: "diff to previous version"} ],
          */
          localBiblio:  {
            "RDF-DATASET-C14N": {
              title:    "RDF Dataset Normalization",
              href:     "https://json-ld.github.io/normalization/spec/",
              authors:  ["David Longley", "Manu Sporny"],
              status:   "CGDRAFT",
              publisher:  "JSON-LD Community Group"
            },
            "SECURITY-VOCABULARY": {
              title:    "The Security Vocabulary",
              href:     "https://w3c-ccg.github.io/security-vocab/",
              authors:  ["Manu Sporny","David Longley"],
              status:   "CGDRAFT",
              publisher:  "Credentials Community Group"
            },
            "ZCAP": {
              title:    "Authorization Capabilities for Linked Data",
              href:     "https://w3c-ccg.github.io/zcap-spec",
              status:   "CGDRAFT",
              publisher:  "Credentials Community Group"
            },
            "MULTIBASE": {
              title: "The Multibase Encoding Scheme",
              date: "February 2021",
              href: "https://datatracker.ietf.org/doc/html/draft-multiformats-multibase-03",
              authors: [
                "Juan Benet",
                "Manu Sporny"
              ],
              status: "Internet-Draft",
              publisher: "IETF"
            },
            "MULTICODEC": {
              title: "The Multi Codec Encoding Scheme",
              date: "February 2022",
              href: "https://github.com/multiformats/multicodec/blob/master/table.csv",
              authors: [
                "The Multiformats Community"
              ],
              status: "Internet-Draft",
              publisher: "IETF"
            },
            "VC-EXTENSION-REGISTRY": {
              title: "Verifiable Credentials Extension Registry",
              href: "https://w3c-ccg.github.io/vc-extension-registry/",
              authors: [
                "Manu Sporny"
              ],
              status: "CG-DRAFT",
              publisher: "Credentials Community Group"
            },
            "URDNA2015": {
              title:    "Universal RDF Dataset Canonicalization Algorithm 2015",
              href:     "https://json-ld.github.io/rdf-dataset-canonicalization/spec/",
              status:   "CGDRAFT",
              publisher:  "Credentials Community Group"
            }
          },
          postProcess: [restrictRefs]
      };
    </script>
    <style>
ol.algorithm { counter-reset:numsection; list-style-type: none; }
ol.algorithm li { margin: 0.5em 0; }
ol.algorithm li:before { font-weight: bold; counter-increment: numsection; content: counters(numsection, ".") ") "; }
    </style>
</head>
<body>
    <section id='abstract'>
      <p>
This specification describes mechanisms for ensuring the authenticity and
integrity of Verifiable Credentials and similar types of constrained digital
documents using cryptography, especially through the use of digital
signatures and related mathematical proofs.
      </p>
    </section>

    <section id='sotd'>
      <p>
This is an experimental specification and is undergoing regular revisions. It
is not fit for production deployment.
      </p>
    </section>

    <section>
      <h2>Introduction</h2>
      <p>
This specification describes mechanisms for ensuring the authenticity and
integrity of Verifiable Credentials and similar types of constrained digital
documents using cryptography, especially through the use of digital signatures
and related mathematical proofs. Cryptographic proofs enable functionality that
is useful to implementors of distributed systems. For example, proofs can be
used to:
      </p>

      <ul>
        <li>
Make statements that can be shared without loss of trust, because their
authorship can be verified by a third party, for example as part of Verifiable
Credentials [[VC-DATA-MODEL]] or social media posts.
        </li>
        <li>
Authenticate as an entity identified by a particular identifier, for example, as
the subject identified by a Decentralized Identifier (DID) [[DID-CORE]].
        </li>
        <li>
Delegate authorization for actions in a remote execution environment, via
mechanisms such as Authorization Capabilities [[ZCAP]].
        </li>
        <li>
Agree to contracts where the agreement can be verified by another party.
        </li>
        <li>
Additionally, many proofs that are based on cryptographic digital signatures
provide the benefit of integrity protection, making documents and data
tamper-evident.
        </li>
      </ul>

      <section>
        <h3>How it Works</h3>

        <p>
The operation of Data Integrity is conceptually simple. To create a
cryptographic proof, the following steps are performed: 1) Transformation,
2) Hashing, and 3) Proof Generation.
        </p>

        <figure id="hiw-creation">
          <img style="margin: auto; display: block; width: 100%;"
               src="diagrams/hiw-creation.svg" alt="
Diagram showing the three steps involved in the creation of a cryptographic
proof. The diagram is laid out left to right with a blue box labeled 'Data'
on the far left. The blue box travels, left to right, through three subsequent
yellow arrows labeled 'Transform Data', 'Hash Data', and 'Generate Proof'. The
resulting blue box at the far right is labeled 'Data with Proof'.
               ">
          <figcaption style="text-align: center;">
To create a cryptographic proof, data is transformed, hashed, and
cryptographically protected.
          </figcaption>
        </figure>

        <p>
<dfn>Transformation</dfn> is a process described by a <dfn>transformation
algorithm</dfn> that takes input data and prepares it for the hashing process.
One example of a possible transformation is to take a record of people's names
that attended a meeting, sort the list alphabetically by the individual's family
name, and rewrite the names on a piece of paper, one per line, in sorted order.
Possible transformations include
<a href="https://en.wikipedia.org/wiki/Canonicalization">canonicalization</a>
and
<a href="https://en.wikipedia.org/wiki/Binary-to-text_encoding">
binary-to-text</a> encoding.
        </p>

        <p>
<dfn>Hashing</dfn> is a process described by a <dfn>hashing algorithm</dfn> that
calculates an identifier for the transformed data using a
<a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function">
cryptographic hash function</a>. This process is conceptually similar to how a
phone address book functions, where one takes a person's name (the input data)
and maps that name to that individual's phone number (the hash). Possible
cryptographic hash functions include
<a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function#SHA-3">
SHA-3</a> and
<a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function#BLAKE3">
BLAKE-3</a>.
        </p>

        <p>
<dfn class="lint-ignore">Proof Generation</dfn> is a process described by a
<dfn>proof generation algorithm</dfn> that calculates a value that protects the
integrity of the input data from modification or otherwise proves a certain
desired threshold of trust. This process is conceptually similar to the way a
wax seal can be used on an envelope containing a letter to establish trust in
the sender and show that the letter has not been tampered with in transit.
Possible proof generation functions include
<a href="https://en.wikipedia.org/wiki/Digital_signature">digital signatures</a>
and
<a href="https://en.wikipedia.org/wiki/Proof_of_stake">proofs of stake</a>.
        </p>

        <p>
To verify a cryptographic proof, the following steps are performed:
1) Transformation, 2) Hashing, and 3) Proof Verification.
        </p>

        <figure id="hiw-verification">
          <img style="margin: auto; display: block; width: 100%;"
               src="diagrams/hiw-verification.svg" alt="
Diagram showing the three steps involved in the verification of a cryptographic
proof. The diagram is laid out left to right with a blue box labeled
'Data with Proof' on the far left. The blue box travels, left to right, through
three subsequent yellow arrows labeled 'Transform Data', 'Hash Data', and
'Verify Proof'. The resulting blue box at the far right is labeled 'Data with
Proof'.
               ">
          <figcaption style="text-align: center;">
To verify a cryptographic proof, data is transformed, hashed, and
checked for correctness.
          </figcaption>
        </figure>

        <p>
During verification, the <a>transformation</a> and <a>hashing</a> steps are
conceptually the same as described above.
        </p>

        <p>
<dfn class="lint-ignore">Proof Verification</dfn> is a process that is described
by a <dfn>proof verification algorithm</dfn> that applies a cryptographic proof
verification function to see if the input data can be trusted. Possible proof
verification functions include
<a href="https://en.wikipedia.org/wiki/Digital_signature">digital signatures</a>
and
<a href="https://en.wikipedia.org/wiki/Proof_of_stake">proofs of stake</a>.
        </p>

        <p>
This specification details how cryptographic software architects and
implementers can package these processes together into things called
<a>cryptographic suites</a> and provide them to application developers for the
purposes of protecting the integrity of application data in transit and at rest.
        </p>

      </section>

      <section>
        <h3>Design Goals and Rationale</h3>

        <p>
This specification optimizes for the following design goals:
        </p>

        <dl>
          <dt>Simplicity</dt>
          <dd>
The technology is designed to be easy to use for application developers,
without requiring significant training in cryptography. It optimizes for the
following priority of constituencies: application developers over cryptographic
suite implementers, over cryptographic suite designers, over cryptographic
algorithm specification authors.  The solution focuses on sensible defaults to
prevent the selection of ineffective protection mechanisms. See section
<a href="#protecting-application-developers"></a> and
<a href="#versioning-cryptography-suites"></a> for further details.
          </dd>
          <dt>Composability</dt>
          <dd>
A number of historical digital signature mechanisms have had monolithic
designs which limited use cases by combining data transformation, syntax,
digital signature, and serialization into a single specification. This
specification layers each component such that a broader range of use cases are
enabled, including generalized selective disclosure and serialization-agnostic
signatures. See section <a href="#transformations"></a>, section
<a href="#data-opacity"></a>, and <a href="#versioning-cryptography-suites"></a>
for further rationale.
          </dd>
          <dt>Resilience</dt>
          <dd>
Since digital proof mechanisms might be compromised without warning due to
technological advancements, it is important that <a>cryptographic suites</a>
provide multiple layers of protection and can be rapidly upgraded. This
specification provides for both algorithmic agility and cryptographic layering,
while still keeping the digital proof format easy for developers to understand
and use. See section <a href="#agility-and-layering"></a> to understand the
particulars.
          </dd>
          <dt>Progressive Extensibility</dt>
          <dd>
Creating and deploying new cryptographic protection mechanisms is designed to be
a deliberate, iterative, and careful process that acknowledges that extension
happens in phases from experimentation, to implementation, to standardization.
This specification strives to balance the need for an increase in the rate of
innovation in cryptography with the need for stable production-grade
cryptography suites. See section <a href="#cryptographic-suites"></a> for
instructions on establishing new types of cryptographic proofs.
          </dd>
          <dt>Serialization Flexibility</dt>
          <dd>
Cryptographic proofs can be serialized in many different but equivalent ways and
have often been tightly bound to the original document syntax. This
specification enables one to create cryptographic proofs that are not
bound to the original document syntax, which enables more advanced use cases
such as being able to use a single digital signature across a variety of
serialization syntaxes such as JSON and CBOR without the need to regenerate the
cryptographic proof. See section <a href="#transformations"></a> for an
explanation of the benefits of such an approach.
          </dd>
        </dl>

      <p class="note" title="Application of technology to broader use cases">
While this specification primarily focuses on Verifiable Credentials, the
design of this technology is generalized, such that it can be used for
non-Verifiable Credential use cases. In these instances, implementers are
expected to perform their own due diligence and expert review as to the
applicability of the technology to their use case.
      </p>

      </section>

      <section id="conformance">
      </section>

      <section>
        <h3>Terminology</h3>

        <div data-include="./terms.html"></div>
      </section>
    </section>

    <section>
      <h2>Data Model</h2>

      <p>
This section specifies the data model that is used for expressing
<a>data integrity proofs</a> and <a>verification methods</a>.
      </p>

      <section>
        <h3>Proofs</h3>
        <p>
A <a>data integrity proof</a> provides information about the proof mechanism,
parameters required to verify that proof, and the proof value itself. All of this
information is provided using Linked Data vocabularies such as the
[[SECURITY-VOCABULARY]].
        </p>

        <p>
The following attributes are defined for use in a <a>data integrity proof</a>:
        </p>

        <dl style="margin-left: 1em;">
          <dt><dfn>type</dfn></dt>
          <dd>
The specific <a>proof type</a> used for the cryptographic proof MUST be
specified as a string that maps to a URL [[URL]]. Examples of proof types
include <code>DataIntegrityProof</code> and <code>Ed25519Signature2020</code>.
Proof types determine what other fields are required to secure and
verify the proof.
          </dd>

          <dt><dfn class="lint-ignore">proofPurpose</dfn></dt>
          <dd>
The reason the proof was created MUST be specified as a string that maps to a
URL [[URL]]. The proof purpose acts as a safeguard to prevent the proof from
being misused by being applied to a purpose other than the one that was
intended. For example, without this value the creator of a proof could be
tricked into using cryptographic material typically used to create a Verifiable
Credential (<code>assertionMethod</code>) during a login process
(<code>authentication</code>) which would then result in the creation of a
Verifiable Credential they never meant to create instead of the intended action,
which was to merely logging into a website.
          </dd>

          <dt><dfn>verificationMethod</dfn></dt>
          <dd>
The means and information needed to verify the proof MUST be specified as a
string that maps to a [[URL]]. An example of a verification method is a
link to a public key which includes cryptographic material that is used by a
verifier during the verification process.
          </dd>

          <dt><dfn class="lint-ignore">created</dfn></dt>
          <dd>
The date and time the proof was created MUST be specified as an
[[XMLSCHEMA11-2]] combined date and time string.
          </dd>

          <dt>domain</dt>
          <dd>
The creator of a proof SHOULD include a string value that indicates its intended usage, which a verifier SHOULD use to ensure the proof was intended to be used by them. The
specification of the `domain` parameter is useful in challenge-response
protocols where the verifier is operating from within a security domain known to
the creator of the proof. Examples of a domain parameter include:
`domain.example` (DNS domain), `https://domain.example:8443` (full Web origin),
`mycorp-intranet` (well-known text string), and
`b31d37d4-dd59-47d3-9dd8-c973da43b63a` (UUID).
          </dd>

          <dt>challenge</dt>
          <dd>
A string value that SHOULD be included in a proof if a `domain` is specified.
The value is used once for a particular <a>domain</a> and window of time. This
value is used to mitigate replay attacks. Examples of a challenge value include:
`1235abcd6789`, `79d34551-ae81-44ae-823b-6dadbab9ebd4`, and `ruby`.
          </dd>

          <dt><dfn>proofValue</dfn></dt>
          <dd>
A string value that contains the data necessary to verify the digital proof
using the `verificationMethod` specified. The contents of the value MUST be a
multibase-encoded binary value. Alternative fields with different encodings MAY
be used to encode the data necessary to verify the digital proof instead of this
value. The contents of this value are determined by a cryptosuite and set to the
<em>proof value</em> generated by the
<a href="#create-proof-algorithm">Proof Algorithm</a>.
          </dd>
        </dl>

        <p class="note">
All of the terms above map to URLs. The vocabulary where these terms are defined
is the [[SECURITY-VOCABULARY]].
        </p>

        <p>
A proof can be added to a JSON document like the following:
        </p>

        <pre class="example highlight" title="A simple JSON data document">
  {
    "title": "Hello world!"
  };
        </pre>

        <p>
by adding the parameters outlined in this section:
        </p>

        <pre class="example highlight"
        style="overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;"
        title="A simple signed JSON data document">
  {
    "title": "Hello world!",
    "proof": {
      "type": "DataIntegrityProof",
      "cryptosuite": "example-signature-2022",
      "created": "2020-11-05T19:23:24Z",
      "verificationMethod": "https://di.example/issuer#z6MkjLrk3gKS2nnkeWcmcxi
        ZPGskmesDpuwRBorgHxUXfxnG",
      "proofPurpose": "assertionMethod",
      "proofValue": "zQeVbY4oey5q2M3XKaxup3tmzN4DRFTLVqpLMweBrSxMY2xHX5XTYV8nQA
        pmEcqaqA3Q1gVHMrXFkXJeV6doDwLWx"
    }
  }
        </pre>

        <p>
The example proof above suggests a ficticious
<code>example-signature-2022</code> cryptography suite that produces a
verifiable digital proof by presumptively transforming the input data using the
JSON Canonicalization Scheme [[RFC8785]] and then digitally signing it using an
Ed25519 elliptic curve signature.
        </p>

        <p>
Similarly, a proof can be added to a JSON-LD data document like the following:
        </p>

        <pre class="example highlight" title="A simple JSON-LD data document">
  {
    "@context": {"title": "https://schema.org/title"},
    "title": "Hello world!"
  };
        </pre>

        <p>
by adding the parameters outlined in this section:
        </p>

        <pre class="example highlight"
        style="overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;"
        title="A simple signed JSON-LD data document">
  {
    "@context": [
      {"title": "https://schema.org/title"},
      "https://w3id.org/security/data-integrity/v1"
    ],
    "title": "Hello world!",
    "proof": {
      "type": "DataIntegrityProof",
      "cryptosuite": "eddsa-2022",
      "created": "2020-11-05T19:23:24Z",
      "verificationMethod": "https://ldi.example/issuer#z6MkjLrk3gKS2nnkeWcmcxi
        ZPGskmesDpuwRBorgHxUXfxnG",
      "proofPurpose": "assertionMethod",
      "proofValue": "z4oey5q2M3XKaxup3tmzN4DRFTLVqpLMweBrSxMY2xHX5XTYVQeVbY8nQA
        VHMrXFkXJpmEcqdoDwLWxaqA3Q1geV6"
    }
  }
        </pre>

        <p>
The proof example above uses the <code>Ed25519Signature2020</code> <a>proof
type</a> to produce a verifiable digital proof by canonicalizing the input data
using the RDF Dataset Canonicalization algorithm [[RDF-DATASET-C14N]] and then
digitally signing it using an Ed25519 elliptic curve signature.
        </p>

<div class="issue">Create a separate section detailing an optional mechanism
for authenticating public key control via bi-directional links. How
to establish trust in controllers is out of scope but examples can
be given.</div>

<div class="issue">Specify algorithm agility mechanisms (additional attributes
from the security vocab can be used to indicate other signing and hash
algorithms). Rewrite algorithms to be parameterized on this basis and
move `Ed25519Signature2020` definition to a single supported
mechanism; specify its identifier as a URL. In order to make it easy to
specify a variety of combinations of algorithms, introduce a core
type `DataIntegrityProof` that allows for easy filtering/discover of
proof nodes, but that type on its own doesn't specify any default
proof or hash algorithms, those need to be given via other properties in the
nodes.</div>

      <p class="issue"
        title="Avoid signature format proliferation by using text-based suite value">
The pattern that Data Integrity Signatures use presently leads to a
proliferation in signature types and JSON-LD Contexts. This proliferation can be
avoided without any loss of the security characteristics of tightly binding a
cryptography suite version to one or more acceptable public keys. The
following signature suites are currently being contemplated: eddsa-2022,
nist-ecdsa-2022, koblitz-ecdsa-2022, rsa-2022, pgp-2022, bbs-2022, eascdsa-2022,
ibsa-2022, and jws-2022.
      </p>

      <pre class="example" title="A DataIntegrityProof example using a NIST ECDSA 2022 Cryptosuite">
{
  "@context": ["https://w3id.org/security/data-integrity/v1"],
  "type": "DataIntegrityProof",
  "cryptosuite": "ecdsa-2022",
  "created": "2022-11-29T20:35:38Z",
  "verificationMethod": "did:example:123456789abcdefghi#keys-1",
  "proofPurpose": "assertionMethod",
  "proofValue": "z2rb7doJxczUFBTdV5F5pehtbUXPDUgKVugZZ99jniVXCUpojJ9PqLYV
                 evMeB1gCyJ4HqpnTyQwaoRPWaD3afEZboXCBTdV5F5pehtbUXPDUgKVugUpoj"
}
      </pre>

<div class="issue">Add an explicit check on key type to prevent an
attacker from selecting an algorithm that could abuse how the key is
used/interpreted.</div>

<div class="issue">Add a note indicating that selective disclosure proof
mechanisms can be compatible with Data Integrity; for example,
an algorithm could produce a merkle tree from a canonicalized set of
N-Quads and then sign the root hash. Disclosure would involve including
the merkle paths for each N-Quad that is to be revealed. This mechanism
would merely consume the normalized output differently (this, and the
proof mechanism would be modifications to this core spec). It might also
be necessary to generate proof parameters such as a private key/seed
that can be used along with an algorithm to deterministically generate
nonces that are concatenated with each N-Quad to prevent rainbow
table or similar attacks.</div>

  <div class="issue">Add a note indicating that this specification should not
  be construed to indicate that public key controllers should be restricted to a
  single public key or that systems that use this spec and involve real people
  should identify each person as only ever being a single entity rather than
  perhaps N entities with M keys. There are no such restrictions and in many
  cases those kinds of restrictions are ill-advised due to privacy
  considerations.</div>

      <p>
The Data Integrity specification supports the concept of multiple
proofs in a single document. There are two types of multi-proof
approaches that are identified: Proof Sets (un-ordered) and Proof Chains
(ordered).
      </p>

      <section>
        <h3>Proof Sets</h3>
        <p>
A proof set is useful when the same data needs to be secured by multiple
entities, but where the order of proofs does not matter,
such as in the case of a set of signatures on a contract. A proof set,
which has no order, is represented by associating a set of proofs
with the <code>proof</code> key in a document.
        </p>
        <pre class="example highlight" title="A proof set in a data document">
{
  "@context": [
    {"title": "https://schema.org/title"},
    "https://w3id.org/security/data-integrity/v1"
],
  "title": "Hello world!",
  "proof": [{
    "type": "DataIntegrityProof",
    "cryptosuite": "eddsa-2022",
    "created": "2020-11-05T19:23:24Z",
    "verificationMethod": "https://ldi.example/issuer/1#z6MkjLrk3gKS2nnkeWcmcxi
      ZPGskmesDpuwRBorgHxUXfxnG",
    "proofPurpose": "assertionMethod",
    "proofValue": "z4oey5q2M3XKaxup3tmzN4DRFTLVqpLMweBrSxMY2xHX5XTYVQeVbY8nQA
      VHMrXFkXJpmEcqdoDwLWxaqA3Q1geV6"
  }, {
    "type": "DataIntegrityProof",
    "cryptosuite": "eddsa-2022",
    "created": "2020-11-05T13:08:49Z",
    "verificationMethod": "https://pfps.example/issuer/2#z6MkGskxnGjLrk3gKS2mes
      DpuwRBokeWcmrgHxUXfnncxiZP",
    "proofPurpose": "assertionMethod",
    "proofValue": "z5QLBrp19KiWXerb8ByPnAZ9wujVFN8PDsxxXeMoyvDqhZ6Qnzr5CG9876
      zNht8BpStWi8H2Mi7XCY3inbLrZrm95"
  }]
}
        </pre>

      </section>

      <section>
        <h3>Proof Chains</h3>
        <p>
A proof chain is useful when the same data needs to be signed by
multiple entities and the order of when the proofs occurred matters,
such as in the case of a notary counter-signing a proof that had been
created on a document. A proof chain, where order needs to be preserved, is
represented by associating an ordered list of proofs with the
<code>proofChain</code> key in a document.
        </p>
        <pre class="example highlight" title="A proof chain in a data document">
{
  "@context": [
    {"title": "https://schema.org/title"},
    "https://w3id.org/security/data-integrity/v1"
],
  "title": "Hello world!",
  "proofChain": [{
    "type": "DataIntegrityProof",
    "cryptosuite": "eddsa-2022",
    "created": "2020-11-05T19:23:42Z",
    "verificationMethod": "https://ldi.example/issuer/1#z6MkjLrk3gKS2nnkeWcmcxi
      ZPGskmesDpuwRBorgHxUXfxnG",
    "proofPurpose": "assertionMethod",
    "proofValue": "zVbY8nQAVHMrXFkXJpmEcqdoDwLWxaqA3Q1geV64oey5q2M3XKaxup3tmzN4
      DRFTLVqpLMweBrSxMY2xHX5XTYVQe"
  }, {
    "type": "DataIntegrityProof",
    "cryptosuite": "eddsa-2022",
    "created": "2020-11-05T21:28:14Z",
    "verificationMethod": "https://pfps.example/issuer/2#z6MkGskxnGjLrk3gKS2mes
      DpuwRBokeWcmrgHxUXfnncxiZP",
    "proofPurpose": "assertionMethod",
    "proofValue": "z6Qnzr5CG9876zNht8BpStWi8H2Mi7XCY3inbLrZrm955QLBrp19KiWXerb8
      ByPnAZ9wujVFN8PDsxxXeMoyvDqhZ"
  }]
}
        </pre>

      </section>
      </section>

      <section>
        <h3>Proof Purposes</h3>

        <p>
A proof that describes its purpose helps prevent it from being misused for some
other purpose.
        </p>

        <div class="issue">Add a mention of JWK's <code>key_ops</code>
parameter and WebCrypto's <code>KeyUsage</code> restrictions; explain that
Proof Purpose serves a similar goal but allows for finer-grained restrictions.
        </div>

        <p>
The following is a list of commonly used <a>proof purpose</a> values.
        </p>

        <dl>
          <dt>authentication</dt>
          <dd>
Indicates that a given proof is only to be used for the purposes of an
authentication protocol.
          </dd>
          <dt>assertionMethod</dt>
          <dd>
Indicates that a proof can only be used for making assertions, for example
signing a Verifiable Credential.
          </dd>
          <dt>keyAgreement</dt>
          <dd>
Indicates that a proof is used for for key agreement protocols, such as
Elliptic Curve Diffie Hellman key agreement used by popular encryption
libraries.
          </dd>
          <dt>capabilityDelegation</dt>
          <dd>
Indicates that the proof can only be used for delegating capabilities. See the
Authorization Capabilities [[ZCAP]] specification for more detail.
          </dd>
          <dt>capabilityInvocation</dt>
          <dd>
Indicates that the proof can only be used for invoking capabilities. See the
Authorization Capabilities [[ZCAP]] specification for more detail.
          </dd>
        </dl>

        <p>
Note: The Authorization Capabilities [[ZCAP]] specification defines additional
proof purposes for that use case, such as <code>capabilityInvocation</code> and
<code>capabilityDelegation</code>.
        </p>
      </section>

      <section>
        <h3>Controller Documents</h3>

        <p>
A <a>controller document</a> is a set of data that specifies one or more
relationships between a <a>controller</a> and a set of data, such as a set of
public cryptographic keys. The <a>controller document</a> SHOULD
contain <a>verification relationships</a> that explicitly permit the use of
certain <a>verification methods</a> for specific purposes.
        </p>

        <div class="issue">Add examples of common Controller documents, such as
controller documents published on a ledger-based registry, or on a mutable medium in
combination with an integrity protection mechanism such as Hashlinks.
        </div>

        <section>
          <h2>Verification Methods</h2>
          <p>
A <a>controller document</a> can express <a>verification methods</a>, such as
cryptographic public keys, which can be used to <a>authenticate</a> or authorize
interactions with the <a>controller</a> or associated parties. For example, a
cryptographic public key can be used as a <a>verification method</a> with
respect to a digital signature; in such usage, it verifies that the signer
could use the associated cryptographic private key. <a>Verification methods</a>
might take many parameters. An example of this is a set of five cryptographic
keys from which any three are required to contribute to a cryptographic
threshold signature.
          </p>

          <dl>
            <dt><a>verificationMethod</a></dt>
            <dd>
              <p>
The <code>verificationMethod</code> property is OPTIONAL. If present, the value
MUST be a <a data-cite="INFRA#ordered-set">set</a> of <a>verification
methods</a>, where each <a>verification method</a> is expressed using a <a
data-cite="INFRA#ordered-map">map</a>. The <a>verification method</a> <a
data-cite="INFRA#ordered-map">map</a> MUST include the <code>id</code>,
<code>type</code>, <code>controller</code>, and specific verification material
properties that are determined by the value of <code>type</code> and are defined
in <a href="#verification-material"></a>. A <a>verification method</a> MAY
include additional properties. <a>Verification methods</a> SHOULD be registered
in the Data Integrity Specification Registries [TBD - DIS-REGISTRIES].
              </p>

              <dl>
                <dt>id</dt>
                <dd>
                  <p>
The value of the <code>id</code> property for a <a>verification
method</a> MUST be a <a data-cite="INFRA#string">string</a> that conforms to the
conforms to the [[URL]] syntax.
                  </p>
                </dd>
                <dt>type</dt>
                <dd>
The value of the <code>type</code> property MUST be a <a
data-cite="INFRA#string">string</a> that references exactly one <a>verification
method</a> type. In order to maximize global interoperability, the
<a>verification method</a> type SHOULD be registered in the Data Integrity Specification
Registries [TBD -- DIS-REGISTRIES].
                </dd>
                <dt>controller</dt>
                <dd>
The value of the <code>controller</code> property MUST be a <a
data-cite="INFRA#string">string</a> that conforms to the [[URL]] syntax.
                </dd>
              </dl>
            </dd>
          </dl>

          <pre class="example" title="Example verification method structure">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/data-integrity/v1"
      ]
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "verificationMethod": [{
        "id": <span class="comment">...</span>,
        "type": <span class="comment">...</span>,
        "controller": <span class="comment">...</span>,
        "publicKeyJwk": <span class="comment">...</span>
      }, {
        "id": <span class="comment">...</span>,
        "type": <span class="comment">...</span>,
        "controller": <span class="comment">...</span>,
        "publicKeyMultibase": <span class="comment">...</span>
      }]
    }
          </pre>

          <p class="note"
            title="Verification method controller(s) and controller(s)">
The semantics of the <code>controller</code> property are the same when the
subject of the relationship is the <a>controller document</a> as when the subject of
the relationship is a <a>verification method</a>, such as a cryptographic public
key. Since a key can't control itself, and the key controller cannot be inferred
from the <a>controller document</a>, it is necessary to explicitly express the identity
of the controller of the key. The difference is that the value of
<code>controller</code> for a <a>verification method</a> is <em>not</em>
necessarily a <a>controller</a>. <a>controllers</a> are expressed
using the <code><a>controller</a></code> property at the highest level of the
<a>controller document</a>.
          </p>

          <section>
            <h3>Verification Material</h3>

            <p>
Verification material is any information that is used by a process that applies
a <a>verification method</a>. The <code>type</code> of a <a>verification
method</a> is expected to be used to determine its compatibility with such
processes. Examples of verification material properties are
<code><a>publicKeyJwk</a></code> or <code><a>publicKeyMultibase</a></code>. A
<a>cryptographic suite</a> specification is responsible for specifying the
<a>verification method</a> <code>type</code> and its associated verification
material. For example, see <a href="https://w3c-ccg.github.io/lds-jws2020/">JSON
Web Signature 2020</a> and <a
href="https://w3c-ccg.github.io/lds-ed25519-2020/">Ed25519 Signature 2020</a>.
For all registered <a>verification method</a> types and associated verification
material available for <a>controllers</a>, please see the Data Integrity
Specification Registries [TBD - DIS-REGISTRIES].
            </p>

            <p class=issue>
Ensuring that cryptographic suites are versioned and tightly scoped to a very
small set of possible key types and signature schemes (ideally one key type and
size and one signature output type) is a design goal for most Data Integrity
cryptographic suites. Historically, this has been done by defining both the
key type and the cryptographic suite that uses the key type in the same
specification. The downside of doing so, however, is that there might be a
proliferation of different key types in multikey that result in different
cryptosuites defining the same key material differently. For example, one
cryptosuite might use compressed Curve P-256 keys while another uses
uncompressed values. If that occurs, it will harm interoperability. It will be
important in the coming months to years to ensure that this does not happen
by fully defining the multikey format in a separate specification so
cryptosuite specifications, such as this one, can refer to the multikey
specification, thus reducing the chances of multikey type proliferation and
improving the chances of maximum interoperability for the multikey format.
            </p>

            <p>
To increase the likelihood of interoperable implementations, this specification
limits the number of formats for expressing verification material in a <a>controller
document</a>. The fewer formats that implementers have to
implement, the more likely it will be that they will support all of them. This
approach attempts to strike a delicate balance between ease of implementation
and supporting formats that have historically had broad deployment.
Two supported verification material properties are listed below:
            </p>

            <dl>
              <dt><dfn>publicKeyJwk</dfn></dt>
              <dd>
                <p>
The <code>publicKeyJwk</code> property is OPTIONAL. If present, the value MUST
be a <a data-cite="INFRA#ordered-map">map</a> representing a JSON Web Key that
conforms to [[RFC7517]]. The <a data-cite="INFRA#ordered-map">map</a> MUST NOT
contain "d", or any other members of the private information class as described
in <a href="https://tools.ietf.org/html/rfc7517#section-8.1.1">Registration
Template</a>. It is RECOMMENDED that verification methods that use JWKs
[[RFC7517]] to represent their public keys use the value of <code>kid</code> as
their fragment identifier. It is RECOMMENDED that JWK
<code>kid</code> values are set to the public key fingerprint [[RFC7638]]. See
the first key in <a href="#example-various-verification-method-types"></a> for
an example of a public key with a compound key identifier.
                </p>
              </dd>
              <dt><dfn>publicKeyMultibase</dfn></dt>
              <dd>
                <p>
The <code>publicKeyMultibase</code> property is OPTIONAL. This feature is
non-normative. If present, the value MUST be a <a
data-cite="INFRA#string">string</a> representation of a [[?MULTIBASE]] encoded
public key.
                </p>
                <p class="advisement">
Note that the [[?MULTIBASE]] specification is not yet a standard and is
subject to change. There might be some use cases for this data format
where <code><b>public</b>KeyMultibase</code> is defined, to allow for
expression of public keys, but <code><b>private</b>KeyMultibase</code>
is not defined, to protect against accidental leakage of secret keys.
                </p>
              </dd>
          </dl>

            <p>
A <a>verification method</a> MUST NOT contain multiple verification material
properties for the same material. For example, expressing key material in a
<a>verification method</a> using both <code>publicKeyJwk</code> and
<code>publicKeyMultibase</code> at the same time is prohibited.
            </p>

            <p>
An example of a <a>controller document</a> containing <a>verification methods</a> using
both properties above is shown below.
            </p>

            <pre id="example-various-verification-method-types"
              class="example nohighlight"
              title="Verification methods using publicKeyJwk and publicKeyMultibase">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/suites/jws-2020/v1",
        "https://w3id.org/security/multikey/v1"
      ]
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "verificationMethod": [{
        "id": "did:example:123#_Qq0UL2Fq651Q0Fjd6TvnYE-faHiOpRlPVQcY_-tA4A",
        "type": "JsonWebKey2020", <span class="comment">// external (property value)</span>
        "controller": "did:example:123",
        "publicKeyJwk": {
          "crv": "Ed25519", <span class="comment">// external (property name)</span>
          "x": "VCpo2LMLhn6iWku8MKvSLg2ZAoC-nlOyPVQaO3FxVeQ", <span class="comment">// external (property name)</span>
          "kty": "OKP", <span class="comment">// external (property name)</span>
          "kid": "_Qq0UL2Fq651Q0Fjd6TvnYE-faHiOpRlPVQcY_-tA4A" <span class="comment">// external (property name)</span>
        }
      }, {
        "id": "did:example:123456789abcdefghi#keys-1",
        "type": "Multikey", <span class="comment">// external (property value)</span>
        "controller": "did:example:pqrstuvwxyz0987654321",
        "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
      }],
      <span class="comment">...</span>
    }
            </pre>
          </section>

          <section>
            <h3>Multikey</h3>
            <p>
The Multikey data model is a specific type of <a>verification method</a> that
utilizes the [[MULTICODEC]] specification to encode key types into a single
binary stream that is then encoded using the [[MULTIBASE]] specification.
To encode a Multikey, the <a>verification method</a> `type` MUST be set to
`Multikey` and the `publicKeyMultibase` value MUST be a [[MULTIBASE]] encoded
[[MULTICODEC]] value. An example of a Multikey is provided below:
            </p>

            <pre class="example nohighlight"
              title="Multikey encoding of a Ed25519 public key">
{
  "@context": ["https://w3id.org/security/multikey/v1"],
  "id": "did:example:123456789abcdefghi#keys-1",
  "type": "Multikey",
  "controller": "did:example:123456789abcdefghi",
  "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
}
            </pre>

            <p>
In the example above, the `publicKeyMultibase` value starts with the letter `z`,
which is the [[MULTIBASE]] header that conveys that the binary data is
base58-encoded using the Bitcoin base-encoding alphabet. The decoded binary data
[[MULTICODEC]] header is `0xed`, which specifies that the remaining data
is a 32-byte raw Ed25519 public key.
            </p>

            <p>
The Multikey data model is also capable of encoding secret keys, sometimes
referred to as <em>private keys</em>.
            </p>

            <pre class="example nohighlight"
              title="Multikey encoding of a Ed25519 secret key">
{
  "@context": ["https://w3id.org/security/suites/secrets/v1"],
  "id": "did:example:123456789abcdefghi#keys-1",
  "type": "Multikey",
  "controller": "did:example:123456789abcdefghi",
  "secretKeyMultibase": "z3u2fprgdREFtGakrHr6zLyTeTEZtivDnYCPZmcSt16EYCER"
}
            </pre>

            <p>
In the example above, the `secretKeyMultibase` value starts with the letter `z`,
which is the [[MULTIBASE]] header that conveys that the binary data is
base58-encoded using the Bitcoin base-encoding alphabet. The decoded binary data
[[MULTICODEC]] header is `0x1300`, which specifies that the remaining data
is a 32-byte raw Ed25519 private key.
            </p>

          </section>

          <section>
            <h3>Referring to Verification Methods</h3>
            <p>
<a>Verification methods</a> can be embedded in or referenced from properties
associated with various <a>verification relationships</a> as described in <a
href="#verification-relationships"></a>. Referencing <a>verification methods</a>
allows them to be used by more than one <a>verification relationship</a>.
            </p>

            <p>
If the value of a <a>verification method</a> property is a <a
data-cite="INFRA#ordered-map">map</a>, the <a>verification method</a> has been
embedded and its properties can be accessed directly. However, if the value is a
URL <a data-cite="INFRA#string">string</a>, the <a>verification method</a> has
been included by reference and its properties will need to be retrieved from
elsewhere in the <a>controller document</a> or from another <a>controller document</a>. This
is done by dereferencing the URL and searching the resulting <a>resource</a> for a
<a>verification method</a> <a data-cite="INFRA#ordered-map">map</a> with an
<code>id</code> property whose value matches the URL.
            </p>

            <pre class="example nohighlight"
            title="Embedding and referencing verification methods">
    {
<span class="comment">...</span>

      "authentication": [
        <span class="comment">// this key is referenced and might be used by</span>
        <span class="comment">// more than one verification relationship</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this key is embedded and may *only* be used for authentication</span>
        {
          "id": "did:example:123456789abcdefghi#keys-2",
          "type": "Multikey", <span class="comment">// external (property value)</span>
          "controller": "did:example:123456789abcdefghi",
          "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
        }
      ],

<span class="comment">...</span>
    }
            </pre>
          </section>
        </section>

        <section>
          <h2>Verification Relationships</h2>

          <p>
A <a>verification relationship</a> expresses the relationship between the
<a>controller</a> and a <a>verification method</a>.
          </p>
          <p>
Different <a>verification relationships</a> enable the associated
<a>verification methods</a> to be used for different purposes. It is up to a
<em>verifier</em> to ascertain the validity of a verification attempt by
checking that the <a>verification method</a> used is contained in the
appropriate <a>verification relationship</a> property of the
<a>controller document</a>.
          </p>
          <p>
The <a>verification relationship</a> between the <a>controller</a> and the
<a>verification method</a> is explicit in the <a>controller document</a>.
<a>Verification methods</a> that are not associated with a particular
<a>verification relationship</a> cannot be used for that <a>verification
relationship</a>. For example, a <a>verification method</a> in the value of
the <code><a>authentication</a></code> property cannot be used to engage in
key agreement protocols with the <a>controller</a>&mdash;the value of the
<code><a>keyAgreement</a></code> property needs to be used for that.
          </p>
          <p>
The <a>controller document</a> does not express revoked keys using a <a>verification
relationship</a>. If a referenced verification method is not in the latest
<a>controller document</a> used to dereference it, then that verification method is
considered invalid or revoked.
          </p>
          <p>
The following sections define several useful <a>verification relationships</a>.
A <a>controller document</a> MAY include any of these, or other properties, to
express a specific <a>verification relationship</a>. In order to maximize global
interoperability, any such properties used SHOULD be registered in the
Data Integrity Specification Registries [TBD: DIS-REGISTRIES].
          </p>

          <section>
            <h2>Authentication</h2>

            <p>
The <code>authentication</code> <a>verification relationship</a> is used to
specify how the <a>controller</a> is expected to be <a>authenticated</a>, for
purposes such as logging into a website or engaging in any sort of
challenge-response protocol.
            </p>

            <dl>
              <dt><dfn>authentication</dfn></dt>
              <dd>
The <code>authentication</code> property is OPTIONAL. If present, the associated
value MUST be a <a data-cite="INFRA#ordered-set">set</a> of one or more
<a>verification methods</a>. Each <a>verification method</a> MAY be embedded or
referenced.
              </dd>
            </dl>

            <pre class="example nohighlight" title="Authentication property
                          containing three verification methods">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/multikey/v1"
      ],
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "authentication": [
        <span class="comment">// this method can be used to authenticate as did:...fghi</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this method is *only* approved for authentication, it may not</span>
        <span class="comment">// be used for any other proof purpose, so its full description is</span>
        <span class="comment">// embedded here rather than using only a reference</span>
        {
          "id": "did:example:123456789abcdefghi#keys-2",
          "type": "Multikey",
          "controller": "did:example:123456789abcdefghi",
          "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
        }
      ],
      <span class="comment">...</span>
    }
            </pre>

            <p>
If authentication is established, it is up to the application to decide what to
do with that information.
            </p>
            <p>
This is useful to any <em>authentication verifier</em> that needs to check to
see if an entity that is attempting to <a>authenticate</a> is, in fact,
presenting a valid proof of authentication. When a <em>verifier</em> receives
some data (in some protocol-specific format) that contains a proof that was made
for the purpose of "authentication", and that says that an entity is identified
by the `id`, then that <em>verifier</em> checks to ensure that the proof can be
verified using a <a>verification method</a> (e.g., public key) listed under
<code><a>authentication</a></code> in the <a>controller document</a>.
            </p>
            <p>
Note that the <a>verification method</a> indicated by the
<code><a>authentication</a></code> property of a <a>controller document</a> can
only be used to <a>authenticate</a> the <a>controller</a>. To
<a>authenticate</a> a different <a>controller</a>, the entity associated with
the value of <code>controller</code> needs to <a>authenticate</a> with its
<em>own</em> <a>controller document</a> and associated
<code><a>authentication</a></code> <a>verification relationship</a>.
            </p>
          </section>

          <section>
            <h2>Assertion</h2>

            <p>
The <code>assertionMethod</code> <a>verification relationship</a> is used to
specify how the <a>controller</a> is expected to express claims, such as for
the purposes of issuing a Verifiable Credential [[?VC-DATA-MODEL]].
            </p>

            <dl>
              <dt><dfn>assertionMethod</dfn></dt>
              <dd>
The <code>assertionMethod</code> property is OPTIONAL. If present, the
associated value MUST be a <a data-cite="INFRA#ordered-set">set</a> of
one or more <a>verification methods</a>. Each <a>verification method</a> MAY be
embedded or referenced.
              </dd>
            </dl>

            <p>
This property is useful, for example, during the processing of a <a>verifiable
credential</a> by a verifier. During verification, a verifier checks to see if a
<a>verifiable credential</a> contains a proof created by the <a>controller</a>
by checking that the <a>verification method</a> used to assert the proof is
associated with the <code><a>assertionMethod</a></code> property in the
corresponding <a>controller document</a>.
            </p>

            <pre class="example nohighlight" title="Assertion method property
                        containing two verification methods">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/multikey/v1"
      ],
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "assertionMethod": [
        <span class="comment">// this method can be used to assert statements as did:...fghi</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this method is *only* approved for assertion of statements, it is not</span>
        <span class="comment">// used for any other verification relationship, so its full description is</span>
        <span class="comment">// embedded here rather than using a reference</span>
        {
          "id": "did:example:123456789abcdefghi#keys-2",
          "type": "Multikey", <span class="comment">// external (property value)</span>
          "controller": "did:example:123456789abcdefghi",
          "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
        }
      ],
      <span class="comment">...</span>
    }
            </pre>
          </section>

          <section>
            <h2>Key Agreement</h2>

            <p>
The <code>keyAgreement</code> <a>verification relationship</a> is used to
specify how an entity can generate encryption material in order to transmit
confidential information intended for the <a>controller</a>, such as for
the purposes of establishing a secure communication channel with the recipient.
            </p>

            <dl>
              <dt><dfn>keyAgreement</dfn></dt>
              <dd>
The <code>keyAgreement</code> property is OPTIONAL. If present, the associated
value MUST be a <a data-cite="INFRA#ordered-set">set</a> of one or more
<a>verification methods</a>. Each <a>verification method</a> MAY be embedded or
referenced.
              </dd>
            </dl>

            <p>
An example of when this property is useful is when encrypting a message intended
for the <a>controller</a>. In this case, the counterparty uses the
cryptographic public key information in the <a>verification method</a> to wrap a
decryption key for the recipient.
            </p>

            <pre class="example nohighlight" title="Key agreement property
                          containing two verification methods">
    {
      "@context": "https://www.w3.org/ns/did/v1",
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "keyAgreement": [
        <span class="comment">// this method can be used to perform key agreement as did:...fghi</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this method is *only* approved for key agreement usage, it will not</span>
        <span class="comment">// be used for any other verification relationship, so its full description is</span>
        <span class="comment">// embedded here rather than using only a reference</span>
        {
          "id": "did:example:123#zC9ByQ8aJs8vrNXyDhPHHNNMSHPcaSgNpjjsBYpMMjsTdS",
          "type": "X25519KeyAgreementKey2019", <span class="comment">// external (property value)</span>
          "controller": "did:example:123",
          "publicKeyMultibase": "z6LSn6p3HRxx1ZZk1dT9VwcfTBCYgtNWdzdDMKPZjShLNWG7"
        }
      ],
      <span class="comment">...</span>
    }
            </pre>
          </section>

          <section>
            <h2>Capability Invocation</h2>

            <p>
The <code>capabilityInvocation</code> <a>verification relationship</a> is used
to specify a <a>verification method</a> that might be used by the
<a>controller</a> to invoke a cryptographic capability, such as the
authorization to update the <a>controller document</a>.
            </p>

            <dl>
              <dt><dfn>capabilityInvocation</dfn></dt>
              <dd>
The <code>capabilityInvocation</code> property is OPTIONAL. If present, the
associated value MUST be a <a data-cite="INFRA#ordered-set">set</a> of
one or more <a>verification methods</a>. Each <a>verification method</a> MAY be
embedded or referenced.
              </dd>
            </dl>

            <p>
An example of when this property is useful is when a <a>controller</a> needs to
access a protected HTTP API that requires authorization in order to use it. In
order to authorize when using the HTTP API, the <a>controller</a>
uses a capability that is associated with a particular URL that is
exposed via the HTTP API. The invocation of the capability could be
expressed in a number of ways, e.g., as a digitally signed
message that is placed into the HTTP Headers.
            </p>
            <p>
The server providing the HTTP API is the <em>verifier</em> of the capability and
it would need to verify that the <a>verification method</a> referred to by the
invoked capability exists in the <code><a>capabilityInvocation</a></code>
property of the <a>controller document</a>. The verifier would also check to make sure
that the action being performed is valid and the capability is appropriate for
the resource being accessed. If the verification is successful, the server has
cryptographically determined that the invoker is authorized to access the
protected resource.
            </p>

            <pre class="example nohighlight" title="Capability invocation property
                          containing two verification methods">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/multikey/v1"
      ],
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "capabilityInvocation": [
        <span class="comment">// this method can be used to invoke capabilities as did:...fghi</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this method is *only* approved for capability invocation usage, it will not</span>
        <span class="comment">// be used for any other verification relationship, so its full description is</span>
        <span class="comment">// embedded here rather than using only a reference</span>
        {
        "id": "did:example:123456789abcdefghi#keys-2",
        "type": "Multikey", <span class="comment">// external (property value)</span>
        "controller": "did:example:123456789abcdefghi",
        "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
        }
      ],
      <span class="comment">...</span>
    }
            </pre>
          </section>

          <section>
            <h2>Capability Delegation</h2>

            <p>
The <code>capabilityDelegation</code> <a>verification relationship</a> is used
to specify a mechanism that might be used by the <a>controller</a> to delegate
a cryptographic capability to another party, such as delegating the authority
to access a specific HTTP API to a subordinate.
            </p>

            <dl>
              <dt><dfn class="lint-ignore">capabilityDelegation</dfn></dt>
              <dd>
The <code>capabilityDelegation</code> property is OPTIONAL. If present, the
associated value MUST be a <a data-cite="INFRA#ordered-set">set</a> of
one or more <a>verification methods</a>. Each <a>verification method</a> MAY be
embedded or referenced.
              </dd>
            </dl>

            <p>
An example of when this property is useful is when a <a>controller</a> chooses
to delegate their capability to access a protected HTTP API to a party other
than themselves. In order to delegate the capability, the <a>controller</a>
would use a <a>verification method</a> associated with the
<code>capabilityDelegation</code> <a>verification relationship</a> to
cryptographically sign the capability over to another <a>controller</a>. The
delegate would then use the capability in a manner that is similar to the
example described in <a href="#capability-invocation"></a>.
            </p>

            <pre class="example nohighlight" title="Capability Delegation property
                          containing two verification methods">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/multikey/v1"
      ],
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "capabilityDelegation": [
        <span class="comment">// this method can be used to perform capability delegation as did:...fghi</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this method is *only* approved for granting capabilities; it will not</span>
        <span class="comment">// be used for any other verification relationship, so its full description is</span>
        <span class="comment">// embedded here rather than using only a reference</span>
        {
        "id": "did:example:123456789abcdefghi#keys-2",
        "type": "Multikey", <span class="comment">// external (property value)</span>
        "controller": "did:example:123456789abcdefghi",
        "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
        }
      ],
      <span class="comment">...</span>
    }
            </pre>
          </section>
        </section>
      </section>

      <section>
        <h2>Relationship to Linked Data</h2>
        <p>
The term Linked Data is used to describe a recommended best practice for
exposing, sharing, and connecting information on the Web using standards, such
as URLs, to identify things and their properties. When information is presented
as Linked Data, other related information can be easily discovered and new
information can be easily linked to it. Linked Data is extensible in a
decentralized way, greatly reducing barriers to large scale integration.
        </p>

        <p>
With the increase in usage of Linked Data for a variety of applications, there
is a need to be able to verify the authenticity and integrity of Linked Data
documents. This specification adds authentication and integrity protection to
data documents through the use of mathematical proofs without sacrificing Linked
Data features such as extensibility and composability.
        </p>

        <p class="note" title="Use of Linked Data is an optional feature">
While  this specification provides mechanisms to digitally sign Linked Data, the
use  of Linked Data is not necessary to gain some of the advantages provided by
this specification.
        </p>

      </section>

    </section>

    </section>

    <section>
      <h2>Cryptographic Suites</h2>
      <p>
A data integrity proof is designed to be easy to use by developers and therefore
strives to minimize the amount of information one has to remember to generate a
proof. Often, just the <a>cryptographic suite</a> name (e.g.
<code>eddsa-2022</code>) is required from developers to initiate the creation of
a proof. These <a>cryptographic suite</a>s are often created or reviewed by
people that have the requisite cryptographic training to ensure that safe
combinations of cryptographic primitives are used. This section specifies the
requirements for authoring cryptographic suite specifications.
      </p>

      <p>
The requirements for all data integrity cryptographic suite specifications are
as follows:
      </p>

      <ul>
        <li>
The specification MUST be published as a human-readable document at a URL.
        </li>
        <li>
The specification MUST identify a cryptographic suite <a>type</a> and any
parameters that can be used with the suite.
        </li>
        <li>
The specification MUST detail the <a>transformation algorithms</a> (if any)
parameters, and other necessary details, if any, used to modify input data into
the data to be protected.
        </li>
        <li>
The specification MUST detail the <a>hashing algorithms</a>
parameters, and other necessary details used to perform cryptographic hashing to
the data to be protected.
        </li>
        <li>
The specification MUST detail the <a>proof generation algorithms</a>,
parameters, and other necessary details used to perform cryptographic protection
of the data.
        </li>
        <li>
The specification MUST detail the <a>proof verification algorithms</a>,
parameters, and other necessary details used to perform cryptographic
verification of the data.
        </li>
        <li>
The specification MUST contain a Security Considerations section detailing
security considerations specific to the cryptographic suite.
        </li>
        <li>
The specification MUST contain a Privacy Considerations section detailing
privacy considerations specific to the cryptographic suite.
        </li>
      </ul>

      <p class="issue" title="Require interoperability report?">
The following language was deemed to be contentious: <em>The specification MUST
provide a link to an interoperability test report to document which
implementations are conformant with the cryptographic suite specification.</em>
        <br>
        <br>
The Working Group is seeking feedback on whether or not this is desired given
the important role that cryptographic suite specifications play in ensuring
data integrity.
      </p>

      <section>
        <h3>DataIntegrityProof</h3>

        <p>
A number of cryptographic suites follow the same basic pattern when expressing a
data integrity proof. This section specifies that general design pattern, a
cryptographic suite type called a `DataIntegrityProof`, which reduces the burden
of writing and implementing cryptographic suites through the reuse of design
primitives and source code.
        </p>

        <p>
When specifing a cryptographic suite that utilizes this design pattern, the
`proof` value takes the following form:
        </p>

        <dl>
          <dt>type</dt>
          <dd>
The `type` property MUST contain the string `DataIntegrityProof`.
          </dd>
          <dt>cryptosuite</dt>
          <dd>
The `cryptosuite` property MUST contain a string specifying the name of the
cryptosuite.
          </dd>
          <dt>proofValue</dt>
          <dd>
The `proofValue` property MUST be used, as specified in <a href="#proofs"></a>.
          </dd>
        </dl>

        <p>
Cryptographic suite designers MUST use mandatory `proof` value properties
defined in Section <a href="#proofs"></a>, and MAY define other properties
specific to their cryptographic suite.
        </p>
      </section>

    </section>

    <section>
      <h2>Algorithms</h2>

      <p>
The algorithms defined below are generalized in that they require a specific
<a>transformation algorithm</a>, <a>hashing algorithm</a>,
<a>proof generation algorithm</a>, and <a>proof verification algorithm</a> to be
used to achieve the algorithm's intended outcome.
      </p>

      <section class="normative">
        <h3>Create Proof Algorithm</h3>

<div class="issue">The proof parameters should be included as headers
and values in the data to be signed.</div>

        <p>
The following algorithm specifies how to create a digital proof that can
be later used to verify the authenticity and integrity of a
<a>unsigned data document</a>. A <a>unsigned data document</a>,
<var>document</var>, <a>proof options</a>, <var>options</var>,
and a <a>private key</a>, <var>privateKey</var>, are required inputs.
The <a>proof options</a> MUST contain an identifier for the
public/private key pair, and an [[!ISO8601]] combined date and
time string, <var>created</var>, containing the current date and time,
accurate to at least one second, in Universal Time Code format. A <a>domain</a> might also be specified in the <var>options</var>. A
<a>signed data document</a> is produced as output. Whenever this
algorithm encodes strings, it MUST use UTF-8 encoding.
        </p>

        <ol class="algorithm">
          <li>
Create a copy of <var>document</var>, hereafter referred to as <var>output</var>.
          </li>
          <li>
Generate a <var>transformed document</var> by canonicalizing
<var>document</var> according to a <a>transformation algorithm</a>
(e.g. the <em>URDNA2015</em> [[!RDF-DATASET-C14N]] algorithm).
        </li>
          <li>
Create a value <var>tbs</var> that represents the data to be signed, and
set it to the result of running the
<a href="#create-verify-hash-algorithm">Create Verify Hash Algorithm</a>,
passing the information in <var>options</var>.
          </li>
          <li>
Digitally sign <var>tbs</var> using the <var>privateKey</var> and the
the <var>digital proof algorithm</var>. The resulting string is the
<a>proofValue</a>.
          </li>
          <li>
Add a <code>proof</code> node to <var>output</var> containing
a <a>data integrity proof</a> using the appropriate
<var>type</var> and <a>proofValue</a> values as well as
all of the data in the <var>proof options</var> (e.g.
<var>created</var>, and if given, any additional proof
options such as <a>domain</a>).
          </li>
          <li>
Return <var>output</var> as the <a>signed data document</a>.
          </li>
        </ol>

      </section>

      <section>
        <h3>Verify Proof Algorithm</h3>
        <p class="issue">
This algorithm is highly specific to digital signatures and needs to be
generalized to other proof mechanisms such as Equihash.
        </p>

        <p>
The following algorithm specifies how to check the authenticity and
integrity of a <a>signed data document</a> by verifying its
digital proof. This algorithm takes a
<a>signed data document</a>, <var>signed document</var> and
outputs a <code>true</code> or <code>false</code> value based on whether or
not the digital proof on <var>signed document</var> was verified. Whenever
this algorithm encodes strings, it MUST use UTF-8 encoding.
        </p>

<div class="issue">Specify how the public key can be obtained, through
some out-of-band process and passed in or it can be retrieved by
derefencing its URL identifier, etc.</div>

        <ol class="algorithm">
          <li>
Get the <a>public key</a> by dereferencing its URL identifier in the
<code>proof</code> node of the default graph of <var>signed document</var>.
Confirm that the <a>unsigned data document</a> that describes the <a>public
key</a> specifies its controller and that its controllers's URL identifier can
be dereferenced to reveal a bi-directional link back to the key. Ensure that the
key's controller is a trusted entity before proceeding to the next step.
          </li>
          <li>
Let <var>document</var> be a copy of <var>signed document</var>.
          </li>
          <li>
Remove any <code>proof</code> nodes from the default graph in
<var>document</var> and save it as <var>proof</var>.
          </li>
          <li>
Generate a <var>transformed document</var> by canonicalizing
<var>document</var> according to the <a>transformation algorithm</a>
(e.g. the </var><em>URDNA2015</em> [[!RDF-DATASET-C14N]] algorithm).
          </li>
          <li>
Create a value <var>tbv</var> that represents the data to be verified, and
set it to the result of running the
<a href="#create-verify-hash-algorithm">Create Verify Hash Algorithm</a>,
passing the information in <var>proof</var>.
          </li>
          <li>
Pass the <a>proofValue</a>, <var>tbv</var>,
and the <a>public key</a> to the <a>proof verification algorithm</a>.
Return the resulting boolean value.
          </li>
        </ol>
      </section>

      <section>
        <h3>Create Verify Hash Algorithm</h3>

        <p class="issue">
This algorithm is too specific to digital signatures and needs to be
generalized for algorithms such as Equihash.
        </p>
        <p>
The following algorithm specifies how to create the data that is used
to generate or verify a digital proof. It takes a canonicalized
<a>unsigned data document</a>, <var>transformed document</var>,
<a>transformation algorithm</a>, a <a>hashing algorithm</a>, and
<a>proof options</a>, <var>input options</var> (by reference).
The <a>proof options</a> MUST contain an identifier for the
public/private key pair, and an [[!ISO8601]] combined date and
time string, <var>created</var>, containing the current date and time,
accurate to at least one second, in Universal Time Code format. A <a>domain</a>
might also be specified in the <var>options</var>.
Its output is a data that can be used to generate or verify a
digital proof (it is usually further hashed as part of the
verification or signing process).
        </p>

        <ol class="algorithm">
          <li>
Let <var>options</var> be a copy of <var>input options</var>.
          </li>
          <li>
If the <a>proofValue</a> parameter, such as <code>jws</code>,
exists in <var>options</var>, remove the entry.
          </li>
          <li>
If <var>created</var> does not exist in <var>options</var>, add an
entry with a value that is an [[!ISO8601]] combined date and
time string containing the current date and time accurate to at least one
second, in Universal Time Code format. For example:
<code>2017-11-13T20:21:34Z</code>.
          </li>
          <li>
Generate <var>output</var> by:
            <ol class="algorithm">
              <li>
Creating a <var>canonicalized options document</var> by canonicalizing
<var>options</var> according to the <a>transformation algorithm</a>
(e.g. the <em>URDNA2015</em> [[!RDF-DATASET-C14N]] algorithm).
              </li>
              <li>
Hash <var>canonicalized options document</var> using the
<a>hashing algorithm</a> (e.g. SHA-256) and set <var>output</var>
to the result.
              </li>
              <li>
Hash <var>transformed document</var> using the <a>hashing algorithm</a>
(e.g. SHA-256) and append it to <var>output</var>.
              </li>
            </ol>
          </li>
          <li>
<div class="issue">This last step needs further clarification. Signing
implementations usually automatically perform their own integrated
hashing of an input message, i.e. signing algorithms are a combination
of a raw signing mechanism and a hashing mechanism such as
RS256 (RSA + SHA-256). Current implementations of RSA-based
data integrity proof suites therefore do not perform this last step
before passing the data to a signing algorithm as it will be performed
internally. The Ed25519Proof2018 algorithm also does not perform
this last step -- and, in fact, uses SHA-512 internally. In short,
this last step should better communicate that the 64 bytes produced
from concatenating the SHA-256 of the canonicalized options with the
SHA-256 of the transformed document are passed into the signing
algorithm with a presumption that the signing algorithm will include
hashing of its own.</div>
Note: It is presumed that the 64-byte <var>output</var> will be used
in a signing algorithm that includes its own hashing algorithm, such
as RS256 (RSA + SHA-256) or EdDsa (Ed25519 which uses SHA-512).
          </li>
          <li>
Return <var>output</var>.
          </li>
        </ol>
      </section>
    </section>

    <section>
      <h2>Security Considerations</h2>
      <p>
The following section describes security considerations that developers
implementing this specification should be aware of in order to create secure
software.
      </p>

      <section>
        <h3>Versioning Cryptography Suites</h3>

        <p>
Cryptography secures information through the use of secrets. Knowledge of the
necessary secret makes it computationally easy to access certain information. The
same information can be accessed if a computationally-difficult, brute-force effort
successfully guesses the secret. All modern cryptography requires the
computationally difficult approach to remain difficult throughout time, which
does not always hold due to breakthroughs in science and mathematics. That is
to say that <em>Cryptography has a shelf life</em>.
        </p>
        <p>
This specification plans for the obsolescence of all cryptographic approaches by
asserting that whatever cryptography is in use today is highly likely to be
broken over time. Software systems have to be able to change the cryptography
in use over time in order to continue to secure information. Such changes might
involve increasing required secret sizes or modifications to the cryptographic
primitives used. However, some combinations of cryptographic parameters
might actually reduce security. Given these assumptions, systems need to be able to
distinguish different combinations of safe cryptographic parameters, also known
as cryptographic suites, from one another. When identifying or versioning
cryptographic suites, there are several approaches that can be taken which
include: parameters, numbers, and dates.
        </p>
        <p>
Parametric versioning specifies the particular cryptographic parameters that are
employed in a cryptographic suite. For example, one could use an identifier such
as `RSASSA-PKCS1-v1_5-SHA1`. The benefit to this scheme is that a well-trained
cryptographer will be able to determine all of the parameters in play by the
identifier. The drawback to this scheme is that most of the population that
uses these sorts of identifiers are not well trained and thus will not understand
that the previously mentioned identifier is a cryptographic suite that is no
longer safe to use. Additionally, this lack of knowledge might lead software
developers to generalize the parsing of cryptographic suite identifiers
such that any combination of cryptographic primitives becomes acceptable,
resulting in reduced security. Ideally, cryptographic suites are implemented
in software as specific, acceptable profiles of cryptographic parameters instead.
        </p>
        <p>
Numbered versioning might specify a major and minor version number such as
`1.0` or `2.1`. Numbered versioning conveys a specific order and suggests that
higher version numbers are more capable than lower version numbers. The benefit
of this approach is that it removes complex parameters that less expert
developers might not understand with a simpler model that conveys that an
upgrade might be appropriate. The drawback of this approach is that its not
clear if an upgrade is necessary, as software version number increases often
don't require an upgrade for the software to continue functioning. This can
lead to developers thinking their usage of a particular version is safe, when
it is not. Ideally, additional signals would be given to developers that use
cryptographic suites in their software that periodic reviews of those
suites for continued security are required.
        </p>
        <p>
Date-based versioning specifies a particular release date for a specific
cryptographic suite. The benefit of a date, such as a year, is that it is
immediately clear to a developer if the date is relatively old or new. Seeing
an old date might prompt the developer to go searching for a newer
cryptographic suite, where as a parametric or number-based versioning scheme
might not. The downside of a date-based version is that some cryptographic
suites might not expire for 5-10 years, prompting the developer to go
searching for a newer cryptographic suite only to not find one that is newer.
While this might be an inconvenience, it is one that results in safer
ecosystem behavior.
        </p>
        <p class="issue" data-number="38">
The following text is currently under debate:<br><br>
It is highly encouraged that cryptographic suite identifiers are versioned
using a year designation. For example, the cryptographic suite identifier
`ecdsa-2022` implies that the suite is probably an acceptable of ECDSA in the
year 2025, but might not be a safe choice in the year 2042. A date-based
versioning mechanism, however, is not enough by itself. All cryptographic
suites that follow this specification are intended to be registered
[[?VC-EXTENSION-REGISTRY]] in a way that clearly signal which cryptosuites
are deprecated, standardized, or experimental. Cryptosuite registration will
follow CFRG, IETF, NIST, FIPS, and safecurves guidance. Use of deprecated suites
are expected to throw errors in implementations unless a `useUnsafeCryptosuites`
option is used specifying exactly the unsafe cryptosuite to use.
Use of experimental suites are expected to throw errors in implementations
unless a `useExperimentalCryptosuites` option is used specifying exactly
the experimental cryptosuite to use.
        </p>

        <p class="issue" title="Resolve VC Extension Registry Governance">
The following text is debated due to the governance rules of the VC
Extension Registry not being finalized:<br><br>
Developers are urged to always refer to the [[?VC-EXTENSION-REGISTRY]] for
the latest standardized cryptography suites as well as cross-checking their
usage against, at least, the
<a href="https://www.iana.org/assignments/cose/cose.xhtml#algorithms">
COSE Algorithms Registry</a>, the
<a href="https://www.iana.org/assignments/jose/jose.xhtml#web-signature-encryption-algorithms">
JOSE Algorithms Registry</a>, and the latest
<a href="https://csrc.nist.gov/publications/detail/fips/186/4/final">
FIPS Digital Signature Standard
</a> guidance.  Depending on your jurisdiction you may also need to consider
additional guidance from
<a href="https://www.etsi.org/deliver/etsi_ts/119300_119399/119312/01.02.01_60/ts_119312v010201p.pdf">ETSI</a>
or other regional regulatory and standards bodies.
        </p>
      </section>

      <section>
        <h3>Protecting Application Developers</h3>

        <p>
Modern cryptographic algorithms provide a number of tunable parameters and
options to ensure that the algorithms can meet the varied requirements of different use cases.
For example, embedded systems have limited processing and memory environments
and might not have the resources to generate the strongest digital signatures
for a given algorithm. Other environments, like financial trading systems,
might only need to protect data for a day while the trade is occurring, while
other environments might need to protect data for multiple decades. To meet
these needs, cryptographic algorithm designers often provide multiple ways to
configure a cryptographic algorithm.
        </p>
        <p>
Cryptographic library implementers often take the specifications created by
cryptographic algorithm designers and specification authors and implement them
such that all options are available to the application developers that use their
libraries. This can be due to not knowing which combination of features a
particular application developer might need for a given cryptographic deployment.
All options are often exposed to application developers.
        </p>
        <p>
Application developers that use cryptographic libraries often do not have the
requisite cryptographic expertise and knowledge necessary to appropriately
select cryptographic parameters and options for a given application. This lack
of expertise can lead to an inappropriate selection of cryptographic parameters
and options for a particular application.
        </p>
        <p>
This specification sets the priority of constituencies to protect application
developers over cryptographic library implementers over cryptographic
specification authors over cryptographic algorithm designers. Given these
priorities, the following recommendations are made:
        </p>
        <ul>
          <li>
Cryptographic algorithm designers are advised [[?RFC7696]] to minimize the
number of options and parameters to as few as possible to ensure that
cryptographic library implementers have a more easily auditable security attack
surface for their software libraries.
          </li>
          <li>
Cryptographic specification authors are advised to, if possible, further
minimize the number of options and parameters to as few as possible to ensure
cryptographic agility while also keeping the auditable security
attack surface for downstream software libraries to a minimum.
          </li>
          <li>
Cryptographic library implementers are advised to, if possible, provide known
good combinations of options and parameters to application developers. There
would ideally be two pre-set default configurations for any algorithmic
class, such as Elliptic Curve Digital Signatures, with no ability
to fine tune parameters and options when using these pre-sets. Library options can be provided to
experts to fine tune their use of the library, use of those options by the general
application developer population is to be discouraged.
          </li>
          <li>
Application developers are advised to choose from a number of pre-set
cryptography library configurations and to avoid modifying cryptographic
options and parameters, or using experimental or deprecated cryptography.
          </li>
        </ul>

        <p>
The guidance above is meant to ensure that useful cryptographic options and
parameters are provided at the lower layers of the architecture while not
exposing those options and parameters to application developers who may not
fully understand the balancing benefits and drawbacks of each option.
        </p>

        <p class="issue"
          title="Use of experimental and deprecated cryptography">
The VCWG is seeking guidance on adding language to allow the use of experimental
or deprecated cryptography. By default, those features will be disabled and will
require the application developer to specifically allow use on a per-cryptographic suite
basis. There will be requirements for all implementing libraries to throw errors
or warnings when deprecated or experimental options are selected without the
appropriate override flags.
        </p>
      </section>

      <section>
        <h3>Agility and Layering</h3>

        <p>
<dfn class="lint-ignore">Cryptographic agility</dfn> is a practice by which one designs
<em>frequently connected</em> information security systems to support
<em>switching between multiple cryptographic primitives and/or algorithms</em>. The primary
goal of cryptographic agility is to enable systems to rapidly adapt to new
cryptographic primitives and algorithms without making disruptive changes to the
systems' infrastructure. Thus, when a particular cryptographic primitive, such
as the SHA-1 algorithm, is determined to be no longer safe to use, systems can
be reconfigured to use a newer primitive via a simple configuration file change.
        </p>
        <p>
Cryptographic agility is most effective when the client and the server in
the information security system are in regular contact. However, when the
messages protected by a particular cryptographic algorithm are long-lived, as
with Verifiable Credentials, and/or when the client (holder) might not be
able to easily recontact the server (issuer), then cryptographic agility does
not provide the desired protections.
        </p>
        <p>
<dfn class="lint-ignore">Cryptographic layering</dfn> is a practice where one
designs <em>rarely connected</em> information security systems to
<em>employ multiple primitives and/or algorithms at the same time</em>. The
primary goal of cryptographic layering is to enable systems to survive the
failure or one or more cryptographic algorithms or primitives without losing
cryptographic protection on the payload. For example, digitally signing a single
piece of information using RSA, ECDSA, and Falcon algorithms in parallel would
provide a mechanism that could survive the failure of two of these three digital
signature algorithms. When a particular cryptographic protection is compromised,
such as an RSA digital signature using 768-bit keys, systems can still utilize
the non-compromised cryptographic protections to continue to protect the
information. Developers are urged to take advantage of this feature for all
signed content that might need to be protected for a year or longer.
        </p>
        <p>
This specification provides for both forms of agility. It provides for
cryptographic agility, which allows one to easily switch from one algorithm to
another. It also provides for cryptographic layering, which allows one to
simultaneously use multiple cryptographic algorithms, typically in parallel,
such that any of those used to protect information can be used without reliance
on or requirement of the others, while still keeping the digital proof format
easy to use for developers.
        </p>
        <p>
        </p>
      </section>

      <section>
        <h3>Transformations</h3>

        <p>
At times, it is beneficial to transform the data being protected during the
cryptographic protection process. Such "in-line" transformation can enable a particular type
of cryptographic protection to be agnostic to the data format it is carried in.
For example, some Data Integrity cryptographic suites utilize RDF Dataset
Canonicalization [[?URDNA2015]] which transforms the initial representation into a
canonical form [[?N-QUADS]] that is then serialized, hashed, and digitally
signed. As long as any syntax expressing the protected data can be transformed
into this canonical form, the digital signature can be verified. This enables
the same digital signature over the information to be expressed in JSON, CBOR,
YAML, and other compatible syntaxes without having to create a cryptographic
proof for every syntax.
        </p>
        <p>
Being able to express the same digital signature across a variety of syntaxes is
beneficial because systems often have native data formats with which they
operate. For example, some systems are written against JSON data, while others
are written against CBOR data. Without transformation, systems that process
their data internally as CBOR are required to store the digitally signed data
structures as JSON (or vice-versa). This leads to double-storing data and can
lead to increased security attack surface if the unsigned representation stored in
databases accidentally deviates from the signed representation. By using
transformations, the digital proof can live in the native data format to
help prevent otherwise undetectable database drift over time.
        </p>
        <p>
This specification is designed to avoid requiring the duplication of signed
information by utilizing "in-line" data transformations. Application developers are urged
to work with cryptographically protected data in the native data format for
their application and not separate storage of cryptographic proofs from the data
being protected. Developers are also urged to regularly confirm that the
cryptographically protected data has not been tampered with as it is written to
and read from application storage.
        </p>
        <p class="issue"
          title="Collision-resistant canonicalization requirements">
The VCWG is seeking feedback on normative language that cryptographic suite
implementers need to follow to ensure that they do not utilize data
transformation mechanisms that can map to the same output. That is, given
different inputs for canonicalization scheme #1 and canonicalization
scheme #2, they must not produce the same output value. As an analogy, this is
the same requirement for cryptographic hashing mechanisms and is why those
schemes are designed to be collision resistant. Cryptographic canonicalization
mechanisms have the same requirement. At present, this isn't a problem because
the three expected canonicalization schemes &mdash; the Universal RDF Dataset
Canonicalization Algorithm 2015 [[?URDNA2015]], JSON Canonicalization Scheme
[[?RFC8785]], and a theoretical future base-encoding canonicalization &mdash; have
entirely different outputs.
        </p>
        <p class="issue"
          title="Avoiding the pitfalls of XML Canonicalization">
The VCWG is seeking feedback on whether to explain why modern canonicalization
schemes are simpler than the far more complex XML Canonicalization schemes of
the early 2000s. Some readers seem to be under the impression that all
canonicalization is difficult and has to be avoided at all costs (including costs
to application developers). The WG would like to understand if it would be helpful
to include a section explaining why some simpler data syntaxes (such as JSON) are
easier to canonicalize than more complex data syntaxes (such as XML).
        </p>
      </section>

      <section>
        <h3>Data Opacity</h3>

        <p>
The inspectability of application data has effects on system efficiency and
developer productivity. When cryptographically protected application data, such
as base-encoded binary data, is not easily processed by application subsystems,
such as databases, it increases the effort of working with the cryptographically
protected information. For example, a cryptographically protected payload that
can be natively stored and indexed by a database will result in a simpler system
that:
        </p>

        <ul>
          <li>
benefits from utilizing existing industry-standard database features with no
changes to the protected information,
          </li>
          <li>
avoids the complexity of duplicating data where one copy of the data preserves
the message and digital signature, while the other copy only stores and indexes
the message and is what drives system behaviour,
          </li>
          <li>
avoids the complexity of bespoke solutions that have to structurally modify
the protected information, such as serializing and deserializing nested
digitally signed data that has multiple nested base-encoded payloads.
          </li>
        </ul>

        <p>
Similarly, a cryptographically protected payload that can be processed by
multiple upstream networked systems increases the ability to properly layer
security architectures. For example, if upstream systems do not have to
repeatedly decode the incoming payload, it increases the ability for a system to
distribute processing load by specializing upstream subsystems to actively
combat attacks. While a digital signature needs to always be checked before
taking substantive action, other upstream checks can be performed on transparent
payloads &mdash; such as identifier-based rate limiting, signature expiration
checking, or nonce/challenge checking &mdash; to reject obviously bad requests.
        </p>
        <p>
Additionally, if a developer is not able to easily view data in a system, the
ability to easily audit or debug system correctness is hampered. For example,
requiring application developers to cut-and-paste base-encoded application data
makes development more challenging and increases the chances that obvious bugs
will be missed because every message needs to go through a manually operated
base-decoding tool.
        </p>
        <p>
There are times, however, where the correct design decision is to make data
opaque. Data that does not need to be processed by other application subsystems,
as well as data that does not need to be modified or accessed by an application
developer, can be serialized into opaque formats. Examples include digital
signature values, cryptographic key parameters, and other data fields that only
need to be accessed by a cryptographic library and need not be modified by the
application developer. There are also examples where data opacity is appropriate
when the underlying subsystem does not expose the application developer to the
underlying complexity of the opaque data, such as databases that perform
encryption at rest. In these cases, the application developer continues to
develop against transparent application data formats while the database manages
the complexity of encrypting and decrypting the application data to and from
long-term storage.
        </p>
        <p>
This specification strives to provide an architecture where application data
remains in its native format and is not made opaque, while other cryptographic
data, such as digital signatures, are kept in their opaque binary encoded form.
Cryptographic suite implementers are urged to consider appropriate use of data
opacity when designing their suites, and to weigh the design trade-offs when
making application data opaque versus providing access to cryptographic data at
the application layer.
        </p>
      </section>

      <section>
        <h3>Verification Method Binding</h3>

        <p class="issue">
Implementers must ensure that a verification method is bound to a particular
controller by going from the verification method to the controller document,
and then ensuring that the controller document also contains the verification
method.
        </p>
      </section>

      <section>
        <h3>Verification Relationship Validation</h3>

        <p class="issue">
Implementers need to ensure that when a verification method is used, that
it matches the verification relationship associated with it and that it lines
up with the proof purpose.
        </p>
      </section>

      <section>
        <h3>Canonicalization Method Correctness</h3>

        <p class="issue">
Canonicalization mechanisms utilized for normalizing input to hashing functions
need to have vetted mathematical proofs associted with them. Canonicalization
mechanisms that create collisions in hash functions can be used to attack
digital signatures.
        </p>
      </section>

    </section>

    <section>
      <h2>Privacy Considerations</h2>
      <p>
The following section describes privacy considerations that developers
implementing this specification should be aware of in order to create
privacy enhancing software.
      </p>

      <section>
        <h3>Unlinkability</h3>

        <p>
When a digitally-signed payload contains data that is seen by multiple
verifiers, it becomes a point of correlation. An example of such data is a
shopping loyalty card number. Correlatable data can be used for tracking
purposes by verifiers, which can sometimes violate privacy expectations. The
fact that some data can be used for tracking might not be immediately apparent.
Examples of such correlatable data include, but are not limited to, a static
digital signature or a cryptographic hash of an image.
        </p>

        <p>
It is possible to create a digitally-signed payload that does not have any
correlatable tracking data while also providing some level of assurance that the
payload is trustworthy for a given interaction. This characteristic is called
<dfn class="lint-ignore">unlinkability</dfn> which ensures that no correlatable
data are used in a digitally-signed payload while still providing some level of
trust, the sufficiency of which must be determined by each verifier.
        </p>

        <p>
It is important to understand that not all use cases require or even permit
unlinkability. There are use cases where linkability and correlation are
required due to regulatory or safety reasons, such as correlating organizations
and individuals that are shipping and storing hazardous materials. Unlinkability
is useful when there is an expectation of privacy for a particular interaction.
        </p>

        <p>
There are at least two mechanisms that can provide some level of unlinkability.
The first method is to ensure that no data value used in the message is ever
repeated in a future message. The second is to ensure that any repeated data
value provides adequate herd privacy such that it becomes practically impossible
to correlate the entity that expects some level of privacy in the interaction.
        </p>

        <p>
A variety of methods can be used to achieve unlinkability. These methods include
ensuring that a message is a single use bearer token with no information that
can be used for the purposes of correlation, using attributes that ensure an
adequate level of herd privacy, and the use of cryptosuites that enable the
entity presenting a message to regenerate new signatures while not compromising
the trust in the message being presented.
        </p>
      </section>

      <section>
        <h3>Selective Disclosure</h3>

        <p>
Selective disclosure is a technique that enables the recipient of a
previously-signed message (that is, a message signed by its creator) to reveal
only parts of the message without disturbing the verifiability of those
parts. For example, one might selectively disclose a digital driver's license for
the purpose of renting a car. This could involve revealing only the issuing
authority, license number, birthday, and authorized motor vehicle class from
the license. Note that in this case, the license number is correlatable
information, but some amount of privacy is preserved because the driver's
full name and address are not shared.
        </p>

        <p>
Not all software or cryptosuites are capable of providing selective disclosure.
If the author of a message wishes it to be selectively disclosable by
its recipient, then they need to enable selective disclosure on the specific
message, and both need to use a capable cryptosuite. The author might
also make it mandatory
to disclose certain parts of the message. A recipient that wants to selectively
disclose partial content of the message needs to utilize software that is able to perform the
technique. An example of a cryptosuite that supports selective disclosure is
`bbs-2022`.
        </p>

        <p>
It is possible to selectively disclose information in a way that does not preserve
unlinkability. For example, one might want to disclose the inspection results related
to a shipment, which include the shipment identifier or lot number, which might
have to be correlatable due to regulatory requirements. However, disclosure of
the entire inspection result might not be required as selectively disclosing just
the pass/fail status could be deemed adequate. For more information on
disclosing information while preserving privacy, see
Section <a href="#unlinkability"></a>.
        </p>

      </section>

    </section>

</body>
</html>
