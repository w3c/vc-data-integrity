<!DOCTYPE html>
<html>
<head>
    <title>Verifiable Credential Data Integrity 1.0</title>
    <meta http-equiv='Content-Type' content='text/html;charset=utf-8'/>
    <!--
      === NOTA BENE ===
      For the three scripts below, if your spec resides on dev.w3 you can check them
      out in the same tree and use relative links so that they'll work offline,
     -->
    <script src='//www.w3.org/Tools/respec/respec-w3c' class='remove'></script>
    <script class='remove' src="./common.js"></script>

    <script type="text/javascript" class="remove">
      var respecConfig = {
          // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
          specStatus:           "CRD",

          // the specification's short name, as in http://www.w3.org/TR/short-name/
          shortName:            "vc-data-integrity",

          // subtitle
          subtitle: "Securing the Integrity of Verifiable Credential Data",

          // if you wish the publication date to be other than today, set this
          //publishDate:  "2023-11-14",

          // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
          // and its maturity status
          // previousPublishDate:  "1977-03-15",
          // previousMaturity:  "WD",

          // if there a publicly available Editor's Draft, this is the link
          edDraftURI:           "https://w3c.github.io/vc-data-integrity/",

          // if this is a LCWD, uncomment and set the end of its review period
          implementationReportURI: "https://w3c.github.io/vc-data-integrity/implementations/",
          crEnd: "2024-01-17",

          // if you want to have extra CSS, append them to this list
          // it is recommended that the respec.css stylesheet be kept
          //extraCSS:             ["spec.css", "prettify.css"],

          // editors, add as many as you like
          // only "name" is required
          editors: [{
            name: "Manu Sporny", url: "https://digitalbazaar.com/",
            company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/",
            w3cid: 41758
          }, {
            name: "Dave Longley", url: "https://digitalbazaar.com/",
            company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/",
            note: "2014-2022", w3cid: 48025
          }, {
            name: "Greg Bernstein", url: "https://www.grotto-networking.com/",
            company: "Invited Expert", w3cid: 140479
          }, {
            name: "Dmitri Zagidulin", url: "https://digitalcredentials.mit.edu/",
            company: "Invited Expert", w3cid: 86708
          }, {
            name: "Sebastian Crane", url: "https://github.com/seabass-labrax",
            company: "Invited Expert", w3cid: 140132
          }],

          // authors, add as many as you like.
          // This is optional, uncomment if you have authors as well as editors.
          // only "name" is required. Same format as editors.

          authors:  [
              { name: "Dave Longley", url: "http://digitalbazaar.com/",
                company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/" },
              { name: "Manu Sporny", url: "http://digitalbazaar.com/",
                company: "Digital Bazaar", companyURL: "http://digitalbazaar.com/" }
          ],

          // extend the bibliography entries
          //localBiblio: webpayments.localBiblio,

          // name of the WG
          group:           "vc",

          // name (with the @w3c.org) of the public mailing to which comments are due
          wgPublicList: "public-vc-wg",

          github: "w3c/vc-data-integrity",

          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          //wgPatentURI:  "",
          maxTocLevel: 3,
          /*preProcess: [ ],
          alternateFormats: [ {uri: "diff-20111214.html", label: "diff to previous version"} ],
          */
          localBiblio:  {
            "DI-EDDSA": {
              title:    "The Edwards Digital Signature Algorithm Cryptosuites v1.0",
              href:     "https://www.w3.org/TR/vc-di-eddsa/",
              authors:  ["David Longley", "Manu Sporny", "Dmitri Zagidulin"],
              status:   "WD",
              publisher:  "W3C Verifiable Credentials Working Group"
            },
            "DI-ECDSA": {
              title:    "The Elliptic Curve Digital Signature Algorithm Cryptosuites v1.0",
              href:     "https://www.w3.org/TR/vc-di-ecdsa/",
              authors:  ["David Longley", "Manu Sporny", "Marty Reed"],
              status:   "WD",
              publisher:  "W3C Verifiable Credentials Working Group"
            },
            "DI-BBSDSA": {
              title:    "The BBS Digital Signature Algorithm Cryptosuites v1.0",
              href:     "https://www.w3.org/TR/vc-di-bbs/",
              authors:  ["Tobias Looker", "Orie Steele"],
              status:   "WD",
              publisher:  "W3C Verifiable Credentials Working Group"
            },
            "JOSE-REGISTRIES": {
              title:    "The JSON Object Signing and Encryption (JOSE) Registries",
              href:     "https://www.iana.org/assignments/jose",
              authors:  ["The Internet Assigned Numbers Authority"],
              status:   "REC",
              publisher:  "The Internet Assigned Numbers Authority"
            },
            "SECURITY-VOCABULARY": {
              title:    "The Security Vocabulary",
              href:     "https://w3id.org/security",
              authors:  ["Ivan Herman", "Manu Sporny","David Longley"],
              status:   "ED",
              publisher:  "Verifiable Credentials Working Group"
            },
            "ZCAP": {
              title:    "Authorization Capabilities for Linked Data",
              href:     "https://w3c-ccg.github.io/zcap-spec/",
              status:   "CGDRAFT",
              publisher:  "Credentials Community Group"
            },
            "MULTIBASE": {
              title: "The Multibase Data Format",
              date: "February 2023",
              href: "https://datatracker.ietf.org/doc/draft-multiformats-multibase",
              authors: [
                "Juan Benet",
                "Manu Sporny"
              ],
              status: "Internet-Draft",
              publisher: "IETF"
            },
            "MULTIHASH": {
              title: "The Multihash Data Format",
              date: "February 2023",
              href: "https://datatracker.ietf.org/doc/draft-multiformats-multihash",
              authors: [
                "Juan Benet",
                "Manu Sporny"
              ],
              status: "Internet-Draft",
              publisher: "IETF"
            },
            "MULTICODEC": {
              title: "The Multi Codec Encoding Scheme",
              date: "February 2022",
              href: "https://github.com/multiformats/multicodec/blob/master/table.csv",
              authors: [
                "The Multiformats Community"
              ],
              status: "Internet-Draft",
              publisher: "IETF"
            },
            "VC-SPECS": {
              title: "The Verifiable Credential Specifications Directory",
              href: "https://w3c.github.io/vc-specs-dir/",
              authors: [
                "Manu Sporny"
              ],
              status: "ED",
              publisher: "W3C Verifiable Credentials Working Group"
            },
            "DID-KEY": {
              title: "The did:key Method",
              href: "https://w3c-ccg.github.io/did-method-key/",
              authors: [
                "Manu Sporny",
                "Dmitri Zagidulin",
                "Dave Longley",
                "Orie Steele"
              ],
              status: "CG-DRAFT",
              publisher: "W3C Credentials Community Group"
            },
            "SHA3": {
              title: "SHA-3 Standard: Permutation-Based Hash and Extendable-Output Functions",
              href: "https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.202.pdf",
              authors: [
                "National Institute of Standards and Technology",
              ],
              status: "National Standard",
              publisher: "U.S. Department of Commerce"
            },
            "SD-JWT": {
              title:    "Selective Disclosure for JWTs (SD-JWT)",
              href:     "https://datatracker.ietf.org/doc/draft-ietf-oauth-selective-disclosure-jwt/",
              authors: [
                "Daniel Fett",
                "Kristina Yasuda",
                "Brian Campbell"
              ],
              status:   "I-D",
              publisher:  "The IETF OAuth Working Group"
            }
          },
          postProcess: [restrictRefs],
          xref: ["INFRA", "MIMESNIFF", "VC-DATA-MODEL-2.0"],
          otherLinks: [{
            key: "Related Specifications",
            data: [{
              value: "The Verifiable Credentials Data Model v2.0",
              href: "https://www.w3.org/TR/VC-DATA-MODEL-2.0/"
            }, {
              value: "The Edwards Digital Signature Algorithm Cryptosuites v1.0",
              href: "https://www.w3.org/TR/vc-di-eddsa/"
            }, {
              value: "The Elliptic Curve Digital Signature Algorithm Cryptosuites v1.0",
              href: "https://www.w3.org/TR/vc-di-ecdsa/"
            }, {
              value: "The BBS Digital Signature Algorithm Cryptosuites v1.0",
              href: "https://www.w3.org/TR/vc-di-bbs/"
            }]
          }]
      };
    </script>
    <style>
code {
  color: rgb(199, 73, 0);
  font-weight: bold;
}
pre {
  overflow-x: auto;
  white-space: pre-wrap;
}
pre .highlight {
  font-weight: bold;
  color: Green;
}
pre .subject {
  font-weight: bold;
  color: RoyalBlue;
}
pre .property {
  font-weight: bold;
  color: DarkGoldenrod;
}
pre .comment {
  font-weight: bold;
  color: SteelBlue;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
ol.algorithm { counter-reset:numsection; list-style-type: none; }
ol.algorithm li { margin: 0.5em 0; }
ol.algorithm li:before { font-weight: bold; counter-increment: numsection; content: counters(numsection, ".") ") "; }
    </style>
</head>
<body>
    <section id='abstract'>
      <p>
This specification describes mechanisms for ensuring the authenticity and
integrity of Verifiable Credentials and similar types of constrained digital
documents using cryptography, especially through the use of digital
signatures and related mathematical proofs.
      </p>
    </section>

    <section id='sotd'>

      <p>
The Working Group is actively seeking implementation feedback for this
specification. In order to exit the Candidate Recommendation phase, the
Working Group has set the requirement of at least two independent
implementations for each mandatory feature in the specification. For details
on the conformance testing process, see the test suites listed in the
<a href="https://w3c.github.io/vc-data-integrity/implementations/">
implementation report</a>.
      </p>

    </section>

    <section class="informative">
      <h2>Introduction</h2>
      <p>
This specification describes mechanisms for ensuring the authenticity and
integrity of Verifiable Credentials and similar types of constrained digital
documents using cryptography, especially through the use of digital signatures
and related mathematical proofs. Cryptographic proofs enable functionality that
is useful to implementors of distributed systems. For example, proofs can be
used to:
      </p>

      <ul>
        <li>
Make statements that can be shared without loss of trust, because their
authorship can be verified by a third party, for example as part of Verifiable
Credentials [[?VC-DATA-MODEL-2.0]] or social media posts.
        </li>
        <li>
Authenticate as an entity identified by a particular identifier, for example, as
the subject identified by a Decentralized Identifier (DID) [[DID-CORE]].
        </li>
        <li>
Delegate authorization for actions in a remote execution environment, via
mechanisms such as Authorization Capabilities [[ZCAP]].
        </li>
        <li>
Agree to contracts where the agreement can be verified by another party.
        </li>
        <li>
Additionally, many proofs that are based on cryptographic digital signatures
provide the benefit of integrity protection, making documents and data
tamper-evident.
        </li>
      </ul>

      <section class="informative">
        <h3>How it Works</h3>

        <p>
The operation of Data Integrity is conceptually simple. To create a
cryptographic proof, the following steps are performed: 1) Transformation,
2) Hashing, and 3) Proof Generation.
        </p>

        <figure id="hiw-creation">
          <img style="margin: auto; display: block; width: 100%;"
               src="diagrams/hiw-creation.svg" alt="
Diagram showing the three steps involved in the creation of a cryptographic
proof. The diagram is laid out left to right with a blue box labeled 'Data'
on the far left. The blue box travels, left to right, through three subsequent
yellow arrows labeled 'Transform Data', 'Hash Data', and 'Generate Proof'. The
resulting blue box at the far right is labeled 'Data with Proof'.
               ">
          <figcaption style="text-align: center;">
To create a cryptographic proof, data is transformed, hashed, and
cryptographically protected.
          </figcaption>
        </figure>

        <p>
<dfn>Transformation</dfn> is a process described by a <dfn>transformation
algorithm</dfn> that takes input data and prepares it for the hashing process.
One example of a possible transformation is to take a record of people's names
that attended a meeting, sort the list alphabetically by the individual's family
name, and rewrite the names on a piece of paper, one per line, in sorted order.
Examples of transformations include
<a href="https://en.wikipedia.org/wiki/Canonicalization">canonicalization</a>
and
<a href="https://en.wikipedia.org/wiki/Binary-to-text_encoding">
binary-to-text</a> encoding.
        </p>

        <p>
<dfn>Hashing</dfn> is a process described by a <dfn>hashing algorithm</dfn> that
calculates an identifier for the transformed data using a
<a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function">
cryptographic hash function</a>. This process is conceptually similar to how a
phone address book functions, where one takes a person's name (the input data)
and maps that name to that individual's phone number (the hash). Examples of
cryptographic hash functions include
<a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function#SHA-3">
SHA-3</a> and
<a href="https://en.wikipedia.org/wiki/Cryptographic_hash_function#BLAKE3">
BLAKE-3</a>.
        </p>

        <p>
<dfn class="lint-ignore">Proof Generation</dfn> is a process described by a
<dfn>proof serialization algorithm</dfn> that calculates a value that protects the
integrity of the input data from modification or otherwise proves a certain
desired threshold of trust. This process is conceptually similar to the way a
wax seal can be used on an envelope containing a letter to establish trust in
the sender and show that the letter has not been tampered with in transit.
Examples of proof serialization functions include
<a href="https://en.wikipedia.org/wiki/Digital_signature">digital signatures</a>
and
<a href="https://en.wikipedia.org/wiki/Proof_of_stake">proofs of stake</a>.
        </p>

        <p>
To verify a cryptographic proof, the following steps are performed:
1) Transformation, 2) Hashing, and 3) Proof Verification.
        </p>

        <figure id="hiw-verification">
          <img style="margin: auto; display: block; width: 100%;"
               src="diagrams/hiw-verification.svg" alt="
Diagram showing the three steps involved in the verification of a cryptographic
proof. The diagram is laid out left to right with a blue box labeled
'Data with Proof' on the far left. The blue box travels, left to right, through
three subsequent yellow arrows labeled 'Transform Data', 'Hash Data', and
'Verify Proof'. The resulting blue box at the far right is labeled 'Data with
Proof'.
               ">
          <figcaption style="text-align: center;">
To verify a cryptographic proof, data is transformed, hashed, and
checked for correctness.
          </figcaption>
        </figure>

        <p>
During verification, the [=transformation=] and [=hashing=] steps are
conceptually the same as described above.
        </p>

        <p>
<dfn class="lint-ignore">Proof Verification</dfn> is a process that is described
by a <dfn>proof verification algorithm</dfn> that applies a cryptographic proof
verification function to see if the input data can be trusted. Possible proof
verification functions include
<a href="https://en.wikipedia.org/wiki/Digital_signature">digital signatures</a>
and
<a href="https://en.wikipedia.org/wiki/Proof_of_stake">proofs of stake</a>.
        </p>

        <p>
This specification details how cryptographic software architects and
implementers can package these processes together into things called
[=cryptographic suites=] and provide them to application developers for the
purposes of protecting the integrity of application data in transit and at rest.
        </p>

      </section>

      <section class="informative">
        <h3>Design Goals and Rationale</h3>

        <p>
This specification optimizes for the following design goals:
        </p>

        <dl>
          <dt>Simplicity</dt>
          <dd>
The technology is designed to be easy to use for application developers,
without requiring significant training in cryptography. It optimizes for the
following priority of constituencies: application developers over cryptographic
suite implementers, over cryptographic suite designers, over cryptographic
algorithm specification authors.  The solution focuses on sensible defaults to
prevent the selection of ineffective protection mechanisms. See section
[[[#protecting-application-developers]]] and
[[[#versioning-cryptography-suites]]] for further details.
          </dd>
          <dt>Composability</dt>
          <dd>
A number of historical digital signature mechanisms have had monolithic
designs which limited use cases by combining data transformation, syntax,
digital signature, and serialization into a single specification. This
specification layers each component such that a broader range of use cases are
enabled, including generalized selective disclosure and serialization-agnostic
signatures. See section [[[#transformations]]], section [[[#data-opacity]]], and
[[[#versioning-cryptography-suites]]] for further rationale.
          </dd>
          <dt>Resilience</dt>
          <dd>
Since digital proof mechanisms might be compromised without warning due to
technological advancements, it is important that [=cryptographic suites=]
provide multiple layers of protection and can be rapidly upgraded. This
specification provides for both algorithmic agility and cryptographic layering,
while still keeping the digital proof format easy for developers to understand
and use. See section [[[#agility-and-layering]]] to understand the particulars.
          </dd>
          <dt>Progressive Extensibility</dt>
          <dd>
Creating and deploying new cryptographic protection mechanisms is designed to be
a deliberate, iterative, and careful process that acknowledges that extension
happens in phases from experimentation, to implementation, to standardization.
This specification strives to balance the need for an increase in the rate of
innovation in cryptography with the need for stable production-grade
cryptography suites. See section [[[#cryptographic-suites]]] for instructions on
establishing new types of cryptographic proofs.
          </dd>
          <dt>Serialization Flexibility</dt>
          <dd>
Cryptographic proofs can be serialized in many different but equivalent ways and
have often been tightly bound to the original document syntax. This
specification enables one to create cryptographic proofs that are not
bound to the original document syntax, which enables more advanced use cases
such as being able to use a single digital signature across a variety of
serialization syntaxes such as JSON and CBOR without the need to regenerate the
cryptographic proof. See section [[[#transformations]]] for an explanation of
the benefits of such an approach.
          </dd>
        </dl>

      <p class="note" title="Application of technology to broader use cases">
While this specification primarily focuses on Verifiable Credentials, the
design of this technology is generalized, such that it can be used for
non-Verifiable Credential use cases. In these instances, implementers are
expected to perform their own due diligence and expert review as to the
applicability of the technology to their use case.
      </p>

      </section>

      <section id="conformance">
        <p>
A <dfn>conforming secured document</dfn> is any [=byte sequence=] that can be
converted to a
<a data-cite="INFRA#parse-json-bytes-to-a-javascript-value">
<dfn>JSON document</dfn></a> that follows the relevant normative requirements in
Sections [[[#proofs]]], [[[#proof-purposes]]], [[[#contexts-and-vocabularies]]],
and [[[#dataintegrityproof]]].
        </p>

        <p>
A <dfn>conforming controller document</dfn> is any [=byte sequence=] that can be
converted to a [=JSON document=] that follows the relevant normative
requirements in Sections [[[#controller-documents]]] and
[[[#contexts-and-vocabularies]]].
        </p>

        <p>
A <dfn>conforming verification method</dfn> is any [=byte sequence=] that can be
converted to a [=JSON document=] that follows the relevant normative
requirements in Sections [[[#verification-methods]]] and
[[[#contexts-and-vocabularies]]].
        </p>

        <p>
A <dfn class="lint-ignore">conforming document</dfn> is either a <a>conforming
secured document</a>, a [=conforming controller document=], or a
[=conforming verification method=].
        </p>

        <p>
A <dfn class="lint-ignore">conforming cryptographic suite specification</dfn> is
any specification that follows the relevant normative requirements in Section
[[[#cryptographic-suites]]].
        </p>

        <p>
A <dfn class="lint-ignore">conforming processor</dfn> is any algorithm realized
as software and/or hardware that generates and/or consumes a
[=conforming document=] according to the relevant normative statements in
Section [[[#algorithms]]]. Conforming processors MUST produce errors
when non-conforming documents are consumed.
        </p>

      </section>

      <section class="informative">
        <h3>Terminology</h3>

        <p>
This section defines the terms used in this specification. A link to these terms
is included whenever they appear in this specification.
        </p>

        <dl class="termlist definitions" data-sort="ascending">
          <dt><dfn class="export">data integrity proof</dfn></dt>
          <dd>
A set of attributes that represent a digital proof and the parameters required
to verify it.
          </dd>
          <dt><dfn>public key</dfn></dt>
          <dd>
Cryptographic material that can be used to verify digital proofs created with a
corresponding [=private key=].
          </dd>
          <dt><dfn>private key</dfn></dt>
          <dd>
Cryptographic material that can be used to generate digital proofs.
          </dd>
          <dt><dfn>proof type</dfn></dt>
          <dd>
A specified set of cryptographic primitives bundled together into a
[=cryptographic suite=] for the purposes of safety and convenience, by
cryptographers for developers (see the section on
<a href="https://www.w3.org/TR/vc-data-integrity/#cryptographic-suites">cryptographic suites</a>).
          </dd>
          <dt><dfn class="export">proof purpose</dfn></dt>
          <dd>
The specific intent for the proof; the reason why an entity created it. The
protected declaration acts as a safeguard to prevent the proof from being
misused for a purpose other than the one it was intended for.
          </dd>
          <dt><dfn>challenge</dfn></dt>
          <dd>
A random or pseudo-random value used by some authentication protocols to
mitigate replay attacks.
          </dd>
          <dt><dfn>domain</dfn></dt>
          <dd>
A string value that specifies the operational domain of a digital proof.
This could be an Internet domain name like <code>example.com</code>, an
ad-hoc value such as <code>mycorp-level3-access</code>, or a very
specific transaction value like <code>8zF6T8J34qP3mqP</code>. A signer could
include a [=domain=] in its digital proof to restrict its use
to particular target, identified by the specified [=domain=].
          </dd>

          <dt><dfn data-lt="authenticated|authenticate">authentication</dfn></dt>
          <dd>
A process by which an entity can prove to a verifier that it has a specific
attribute or controls a specific secret.
          </dd>

          <dt><dfn class="export" data-lt="cryptosuite">cryptographic suite</dfn></dt>
          <dd>
A specification defining the usage of specific cryptographic primitives in
order to achieve a particular security goal. These documents are often used
to specify [=verification methods=], digital signature types,
their identifiers, and other related properties. See Section
[[[#cryptographic-suites]]] for further detail.
          </dd>

          <dt><dfn data-lt="decentralized identifiers|DID|DIDs">decentralized identifier</dfn> (DID)</dt>

          <dd>
A globally unique persistent identifier that does not require a centralized
registration authority and is often generated and/or registered
cryptographically. The generic format of a is defined in [[?DID-CORE]].
          </dd>

          <dt><dfn class="export" data-lt="controller(s)">controller</dfn></dt>

          <dd>
An entity that has the capability to make changes to a
[=controller document=].
          </dd>

          <dt><dfn class="export" data-lt="controller documents">controller document</dfn></dt>

          <dd>
A set of data that specifies one or more relationships between a
[=controller=] and a set of data, such as a set of public cryptographic keys.
          </dd>

          <dt><dfn data-lt="subjects">subject</dfn></dt>

          <dd>
The entity identified by the `id` property in a [=controller document=].
Anything can be a subject: person, group, organization, physical thing, digital
thing, logical thing, etc.
          </dd>

          <dt><dfn data-lt="resources">resource</dfn></dt>

          <dd>
As defined by [[RFC3986]]: "...the term 'resource' is used in a general sense
for whatever might be identified by a URI." Similarly, any resource might serve
as a [=subject=] identified by a [=DID=].
          </dd>

          <dt><dfn data-lt="verifier|verifiers|verifier's">verifier</dfn></dt>
          <dd>
A role an entity performs by receiving data containing one or more
[=data integrity proofs=] and then determining whether or not the proof
is valid.
          </dd>

          <dt><dfn class="export">verification method</dfn></dt>

          <dd>
            <p>
A set of parameters that can be used together with a process to independently
verify a proof. For example, a cryptographic public key can be used as a
verification method with respect to a digital signature; in such usage, it
verifies that the signer possessed the associated cryptographic private key.
            </p>
            <p>
"Verification" and "proof" in this definition are intended to apply broadly. For
example, a cryptographic public key might be used during Diffie-Hellman key
exchange to negotiate a shared symmetric key for encryption. This guarantees the
integrity of the key agreement process. It is thus another type of verification
method, even though descriptions of the process might not use the words
"verification" or "proof."
            </p>
          </dd>

          <dt><dfn class="export">verification relationship</dfn></dt>

          <dd>
            <p>
An expression of the relationship between the [=subject=] and a
[=verification method=]. An example of a verification relationship is
[[[#authentication]]].
            </p>
          </dd>

        </dl>

      </section>
    </section>

    <section>
      <h2>Data Model</h2>

      <p>
This section specifies the data model that is used for expressing
[=data integrity proofs=], [=controller documents=], and
[=verification methods=].
      </p>

      <p>
All of the data model properties and types in this specification map to URLs.
The vocabulary where these URLs are defined is the [[?SECURITY-VOCABULARY]]. The
explicit mechanism that is used to perform this mapping in a secured document is
the `@context` property.
      </p>

      <p>
The mapping mechanism is defined by JSON-LD [[JSON-LD11]]. To ensure a document
can be interoperably consumed without the use of a JSON-LD library, document authors
are advised to ensure that domain experts have 1) specified the expected order for
all values associated with a `@context` property, 2) published cryptographic hashes
for each `@context` file, and 3) deemed that the contents of each `@context` file
are appropriate for the intended use case.
      </p>

      <p>
When a document is processed by a non-JSON-LD processor and there is a
requirement to use the same semantics as those used in a JSON-LD environment,
implementers are advised to 1) enforce the expected order and values in the
`@context` property, and 2) ensure that each `@context` file matches the known
cryptographic hashes for each `@context` file.
      </p>

      <p>
Using static, versioned `@context` files with published cryptographic hashes in
conjunction with JSON Schema is one acceptable approach to implementing the
mechanisms described above, which ensures proper term identification, typing,
and order, when a non-JSON-LD processor is used.
      </p>

      <section>
        <h3>Proofs</h3>
        <p>
A [=data integrity proof=] provides information about the proof mechanism,
parameters required to verify that proof, and the proof value itself. All of this
information is provided using Linked Data vocabularies such as the
[[?SECURITY-VOCABULARY]].
        </p>

        <p>
When expressing a [=data integrity proof=] on an object, a
<dfn class="lint-ignore">`proof`</dfn> property MUST be used.
The `proof` property within a Verifiable Credential is a named graph.
If present, its
value MUST be either a single object, or an unordered set of objects, expressed
using the properties below:
        </p>

        <dl style="margin-left: 1em;">
          <dt>id</dt>
          <dd>
An optional identifier for the proof, which MUST be a URL [[URL]], such as
a UUID as a URN (`urn:uuid:6a1676b8-b51f-11ed-937b-d76685a20ff5`).
The usage of this property is further explained in Section [[[#proof-chains]]].
          </dd>

          <dt>type</dt>
          <dd>
The specific [=proof type=] used for the cryptographic proof MUST be
specified as a string that maps to a URL [[URL]]. Examples of proof types
include `DataIntegrityProof` and `Ed25519Signature2020`.
Proof types determine what other fields are required to secure and
verify the proof.
          </dd>

          <dt><dfn class="lint-ignore">proofPurpose</dfn></dt>
          <dd>
The reason the proof was created MUST be specified as a string that maps to a
URL [[URL]]. The proof purpose acts as a safeguard to prevent the proof from
being misused by being applied to a purpose other than the one that was
intended. For example, without this value the creator of a proof could be
tricked into using cryptographic material typically used to create a Verifiable
Credential (`assertionMethod`) during a login process
(`authentication`) which would then result in the creation of a
Verifiable Credential they never meant to create instead of the intended action,
which was to merely logging into a website.
          </dd>

          <dt>verificationMethod</dt>
          <dd>
A verification method is the means and information needed to verify the proof.
If included, the value MUST be a string that maps to a [[URL]]. An example of a
verification method is a link to a [=public key=] which includes cryptographic
material that is used by a verifier during the verification process. Inclusion
of `verificationMethod` is OPTIONAL, but if it is not included, other properties
such as `cryptosuite` might provide a mechanism by which to obtain the required
information to verify the proof.
          </dd>

          <dt>cryptosuite</dt>
          <dd>
An identifier for the cryptographic suite that can be used to verify the proof. See
[[[#cryptographic-suites]]] for more information. If the proof type is
`DataIntegrityProof`, `cryptosuite` MUST be specified; otherwise,  `cryptosuite`
MAY be specified. If specified, its value MUST be a string.
          </dd>

          <dt><dfn class="lint-ignore">created</dfn></dt>
          <dd>
The date and time the proof was created is OPTIONAL and, if included, MUST be
specified as an [[XMLSCHEMA11-2]] `dateTimeStamp` string, either in Universal
Coordinated Time (UTC), denoted by a Z at the end of the value, or with a time
zone offset relative to UTC. Time values that are incorrectly serialized without
an offset MUST be interpreted as UTC.
          </dd>

          <dt id="defn-proof-expires">expires</dt>
          <dd>
The `expires` property is OPTIONAL and, if present, specifies when the proof
expires. If present, it MUST be an [[XMLSCHEMA11-2]] `dateTimeStamp` string,
either in Universal Coordinated Time (UTC), denoted by a Z at the end of the
value, or with a time zone offset relative to UTC. Time values that are
incorrectly serialized without an offset MUST be interpreted as UTC.
          </dd>

          <dt id="defn-domain">domain</dt>
          <dd>
The `domain` property is OPTIONAL. It conveys one or more security domains in which the
proof is meant to be used. If specified, the associated value MUST be either a
string, or an unordered set of strings. A verifier SHOULD use the value to
ensure that the proof was intended to be used in the security domain in which
the verifier is operating. The specification of the `domain` parameter is useful
in challenge-response protocols where the verifier is operating from within a
security domain known to the creator of the proof. Example domain values
include: `domain.example` (DNS domain), `https://domain.example:8443`
(Web origin), `mycorp-intranet` (bespoke text string), and
`b31d37d4-dd59-47d3-9dd8-c973da43b63a` (UUID).
          </dd>

          <dt id="defn-challenge">challenge</dt>
          <dd>
A string value that SHOULD be included in a proof if a `domain` is specified.
The value is used once for a particular [=domain=] and window of time. This
value is used to mitigate replay attacks. Examples of a challenge value include:
`1235abcd6789`, `79d34551-ae81-44ae-823b-6dadbab9ebd4`, and `ruby`.
          </dd>

          <dt><dfn class="lint-ignore">proofValue</dfn></dt>
          <dd>
A string value that contains the base-encoded binary data necessary to verify
the digital proof using the `verificationMethod` specified. The contents of the
value MUST be expressed with a header and encoding as described in Section
[[[#multibase-0]]]. The contents of this value are determined by a
specific cryptosuite and set to the <em>proof value</em> generated by the
<a href="#add-proof">Add Proof Algorithm</a> for that cryptosuite. Alternative
properties with different encodings specified by the cryptosuite MAY be used,
instead of this property, to encode the data necessary to verify the digital
proof.
          </dd>

          <dt><dfn class="lint-ignore">previousProof</dfn></dt>
          <dd>
An OPTIONAL string value or unordered list of string values. Each value
identifies another [=data integrity proof=] that MUST verify before the
current proof is processed. If an unordered list, all referenced proofs in the
array MUST verify. This property is used in Section [[[#proof-chains]]].
          </dd>

          <dt><dfn class="lint-ignore">nonce</dfn></dt>
          <dd>
An OPTIONAL string value supplied by the proof creator. One use of this
field is to increase privacy by decreasing linkability that is the result
of deterministically generated signatures.
          </dd>

        </dl>

        <p>
A proof can be added to a JSON document like the following:
        </p>

        <pre class="example nohighlight" title="A simple JSON data document">
{
  "myWebsite": "https://hello.world.example/"
};
        </pre>

        <p>
The following proof secures the document above using the `eddsa-jcs-2022`
cryptography suite [[?DI-EDDSA]], which produces a verifiable digital proof by
transforming the input data using the JSON Canonicalization Scheme (JCS)
[[?RFC8785]] and then digitally signing it using an Edwards Digital Signature
Algorithm (EdDSA).
        </p>

        <pre class="example nohighlight"
        title="A simple signed JSON data document">
{
  "myWebsite": "https://hello.world.example/",
  "proof": {
    "type": "DataIntegrityProof",
    "cryptosuite": "eddsa-jcs-2022",
    "created": "2023-03-05T19:23:24Z",
    "verificationMethod": "https://di.example/issuer#z6MkjLrk3gKS2nnkeWcm<wbr>cxiZPGskmesDpuwRBorgHxUXfxnG",
    "proofPurpose": "assertionMethod",
    "proofValue": "zQeVbY4oey5q2M3XKaxup3tmzN4DRFTLVqpLMweBrSxMY2xHX5XTYV<wbr>8nQApmEcqaqA3Q1gVHMrXFkXJeV6doDwLWx"
  }
}
        </pre>

        <p>
Similarly, a proof can be added to a JSON-LD data document like the following:
        </p>

        <pre class="example nohighlight"
          title="A simple JSON-LD data document">
{
  "@context": {"myWebsite": "https://vocabulary.example/myWebsite"},
  "myWebsite": "https://hello.world.example/"
};
        </pre>

        <p>
The following proof secures the document above by using the `ecdsa-rdfc-2019`
cryptography suite [[?DI-ECDSA]], which produces a verifiable digital proof by
transforming the input data using the RDF Dataset Canonicalization Scheme
[[?RDF-CANON]] and then digitally signing it using the Elliptic Curve Digital
Signature Algorithm (ECDSA).
        </p>

        <pre class="example nohighlight"
        title="A simple signed JSON-LD data document">
{
  "@context": [
    {"myWebsite": "https://vocabulary.example/myWebsite"},
    "https://w3id.org/security/data-integrity/v2"
  ],
  "myWebsite": "https://hello.world.example/",
  "proof": {
    "type": "DataIntegrityProof",
    "cryptosuite": "ecdsa-rdfc-2019",
    "created": "2020-06-11T19:14:04Z",
    "verificationMethod": "https://ldi.example/issuer#zDnaepBuvsQ8cpsWrVK<wbr>w8fbpGpvPeNSjVPTWoq6cRqaYzBKVP",
    "proofPurpose": "assertionMethod",
    "proofValue": "zXb23ZkdakfJNUhiTEdwyE598X7RLrkjnXEADLQZ7vZyUGXX8cyJZR<wbr>BkNw813SGsJHWrcpo4Y8hRJ7adYn35Eetq"
  }
}
        </pre>

        <p class="note" title="Representing time values to individuals">
This specification enables the expression of dates and times, such as through
the `created` and `expires` properties. This information might be indirectly
exposed to an individual if a proof is processed and is detected to be outside
an allowable time range. When displaying date and time values related to the
validity of cryptographic proofs, implementers are advised to respect the
<a data-cite="LTLI#locale" href="https://www.w3.org/TR/ltli/#locale">locale</a>
and local calendar preferences of the individual [[?LTLI]]. Conversion of
timestamps to local time values are expected to consider the time zone
expectations of the individual. See
<a data-cite="?VC-DATA-MODEL-2.0#representing-time"></a> for more details about
representing time values to individuals.
        </p>

<div class="issue">Add a note indicating that selective disclosure proof
mechanisms can be compatible with Data Integrity; for example,
an algorithm could produce a merkle tree from a canonicalized set of
N-Quads and then sign the root hash. Disclosure would involve including
the merkle paths for each N-Quad that is to be revealed. This mechanism
would merely consume the normalized output differently (this, and the
proof mechanism would be modifications to this core spec). It might also
be necessary to generate proof parameters such as a private key/seed
that can be used along with an algorithm to deterministically generate
nonces that are concatenated with each N-Quad to prevent rainbow
table or similar attacks.</div>

<div class="issue">Add a note indicating that this specification should not
be construed to indicate that public key controllers should be restricted to a
single public key or that systems that use this spec and involve real people
should identify each person as only ever being a single entity rather than
perhaps N entities with M keys. There are no such restrictions and in many
cases those kinds of restrictions are ill-advised due to privacy
considerations.</div>

      <p>
The Data Integrity specification supports the concept of multiple
proofs in a single document. There are two types of multi-proof
approaches that are identified: Proof Sets (un-ordered) and Proof Chains
(ordered).
      </p>

      <section>
        <h3>Proof Sets</h3>
        <p>
A <dfn>proof set</dfn> is useful when the same data needs to be secured by
multiple entities, but where the order of proofs does not matter, such as in the
case of a set of signatures on a contract. A proof set, which has no order, is
represented by associating a set of proofs with the `proof` key in a document.
        </p>
        <pre class="example nohighlight" title="A proof set in a data document">
{
  "@context": [
    {"myWebsite": "https://vocabulary.example/myWebsite"},
    "https://w3id.org/security/data-integrity/v2"
],
  "myWebsite": "https://hello.world.example/",
  "proof": [{
    "type": "DataIntegrityProof",
    "cryptosuite": "eddsa-rdfc-2022",
    "created": "2020-11-05T19:23:24Z",
    "verificationMethod": "https://ldi.example/issuer/1#z6MkjLrk3gKS2nnkeW<wbr>cmcxiZPGskmesDpuwRBorgHxUXfxnG",
    "proofPurpose": "assertionMethod",
    "proofValue": "z4oey5q2M3XKaxup3tmzN4DRFTLVqpLMweBrSxMY2xHX5XTYVQeVbY8<wbr>nQAVHMrXFkXJpmEcqdoDwLWxaqA3Q1geV6"
  }, {
    "type": "DataIntegrityProof",
    "cryptosuite": "eddsa-rdfc-2022",
    "created": "2020-11-05T13:08:49Z",
    "verificationMethod": "https://pfps.example/issuer/2#z6MkGskxnGjLrk3gK<wbr>S2mesDpuwRBokeWcmrgHxUXfnncxiZP",
    "proofPurpose": "assertionMethod",
    "proofValue": "z5QLBrp19KiWXerb8ByPnAZ9wujVFN8PDsxxXeMoyvDqhZ6Qnzr5CG9<wbr>876zNht8BpStWi8H2Mi7XCY3inbLrZrm95"
  }]
}
        </pre>

      </section>

      <section>
        <h3>Proof Chains</h3>
        <p>
A <dfn>proof chain</dfn> is useful when the same data needs to be signed by
multiple entities and the order of when the proofs occurred matters, such as in
the case of a notary counter-signing a proof that had been created on a
document. A proof chain, where proof order needs to be preserved, is expressed
by providing at least one proof with an `id`, such as a UUID as a URN, and
another proof with a `previousProof` value that identifies the previous proof.
        </p>
        <pre class="example nohighlight"
          title="A proof chain in a data document">
{
  "@context": [
    {"myWebsite": "https://vocabulary.example/myWebsite"},
    "https://w3id.org/security/data-integrity/v2"
],
  "myWebsite": "https://hello.world.example/",
  "proof": [{
    "id": "urn:uuid:60102d04-b51e-11ed-acfe-2fcd717666a7",
    "type": "DataIntegrityProof",
    "cryptosuite": "eddsa-rdfc-2022",
    "created": "2020-11-05T19:23:42Z",
    "verificationMethod": "https://ldi.example/issuer/1#z6MkjLrk3gKS2nnke<wbr>WcmcxiZPGskmesDpuwRBorgHxUXfxnG",
    "proofPurpose": "assertionMethod",
    "proofValue": "zVbY8nQAVHMrXFkXJpmEcqdoDwLWxaqA3Q1geV64oey5q2M3XKaxup<wbr>3tmzN4DRFTLVqpLMweBrSxMY2xHX5XTYVQe"
  }, {
    "type": "DataIntegrityProof",
    "cryptosuite": "eddsa-rdfc-2022",
    "created": "2020-11-05T21:28:14Z",
    "verificationMethod": "https://pfps.example/issuer/2#z6MkGskxnGjLrk3g<wbr>KS2mesDpuwRBokeWcmrgHxUXfnncxiZP",
    "proofPurpose": "assertionMethod",
    "proofValue": "z6Qnzr5CG9876zNht8BpStWi8H2Mi7XCY3inbLrZrm955QLBrp19Ki<wbr>WXerb8ByPnAZ9wujVFN8PDsxxXeMoyvDqhZ",
    "previousProof": "urn:uuid:60102d04-b51e-11ed-acfe-2fcd717666a7"
  }]
}
        </pre>

      </section>
      </section>

      <section>
        <h3>Proof Purposes</h3>

        <p>
A proof that describes its purpose helps prevent it from being misused for some
other purpose.
        </p>

        <p class="issue">
Add a mention of JWK's `key_ops` parameter and WebCrypto's
`KeyUsage` restrictions; explain that Proof Purpose serves a
different goal and allows for finer-grained restrictions.
<br><br>
Dave Longley suggested that proof purposes enable verifiers to know what the
proof creator's intent was so the message can't be accidentally abused for
another purpose, e.g., a message signed for the purpose of merely making an
assertion (and thus perhaps intended to be widely shared) being abused as a
message to authenticate to a service or take some action (invoke a capability).
It's a goal to keep the number of them limited to as few categories as are
really needed to accomplish this goal.
        </p>

        <p>
The following is a list of commonly used [=proof purpose=] values.
        </p>

        <dl>
          <dt>authentication</dt>
          <dd>
Indicates that a given proof is only to be used for the purposes of an
authentication protocol.
          </dd>
          <dt>assertionMethod</dt>
          <dd>
Indicates that a proof can only be used for making assertions, for example
signing a Verifiable Credential.
          </dd>
          <dt>keyAgreement</dt>
          <dd>
Indicates that a proof is used for for key agreement protocols, such as
Elliptic Curve Diffie Hellman key agreement used by popular encryption
libraries.
          </dd>
          <dt>capabilityDelegation</dt>
          <dd>
Indicates that the proof can only be used for delegating capabilities. See the
Authorization Capabilities [[?ZCAP]] specification for more detail.
          </dd>
          <dt>capabilityInvocation</dt>
          <dd>
Indicates that the proof can only be used for invoking capabilities. See the
Authorization Capabilities [[?ZCAP]] specification for more detail.
          </dd>
        </dl>

        <p>
Note: The Authorization Capabilities [[?ZCAP]] specification defines additional
proof purposes for that use case, such as `capabilityInvocation` and
`capabilityDelegation`.
        </p>
      </section>

      <section>
        <h3>Controller Documents</h3>

        <p>
A [=controller document=] is a set of data that specifies one or more
relationships between a [=controller=] and a set of data, such as a set of
public cryptographic keys. The [=controller document=] SHOULD
contain [=verification relationships=] that explicitly permit the use of
certain [=verification methods=] for specific purposes.
        </p>

        <p class="issue atrisk"
          title="Potential for stand-alone Controller Document specification">
There are many commonalities between this section on Controller Documents and
similar sections in other securing mechanisms such as [[?VC-JOSE-COSE]], as well as
sections on similar concepts in specifications such as [[?DID-CORE]]. The Working Group is
currently discussing the possibility of moving this section to an independent
Controller Document specification that can be referenced normatively. If this
migration occurs, it is expected that there will be little to no impact on
implementations, as the normative statements that exist in this section will
remain in this or the new document as an additive set
of requirements on top of the base Controller Document specification.
        </p>

        <div class="issue">Add examples of common Controller documents, such as
controller documents published on a ledger-based registry, or on a mutable medium in
combination with an integrity protection mechanism such as Hashlinks.
        </div>

        <section>
          <h2>Verification Methods</h2>
          <p>
A [=controller document=] can express [=verification methods=], such as
cryptographic [=public keys=], which can be used to [=authenticate=] or
authorize interactions with the [=controller=] or associated parties. For
example, a cryptographic [=public key=] can be used as a <a>verification
method</a> with respect to a digital signature; in such usage, it verifies that
the signer could use the associated cryptographic private key. <a>Verification
methods</a> might take many parameters. An example of this is a set of five
cryptographic keys from which any three are required to contribute to a
cryptographic threshold signature.
          </p>

          <dl>
            <dt><dfn class="lint-ignore">verificationMethod</dfn></dt>
            <dd>
              <p>
The `verificationMethod` property is OPTIONAL. If present, the value
MUST be a [=set=] of <a>verification
methods</a>, where each [=verification method=] is expressed using a
[=map=]. The [=verification method=] [=map=] MUST include the `id`,
`type`, `controller`, and specific verification material
properties that are determined by the value of `type` and are defined
in [[[#verification-material]]]. A [=verification method=] MAY
include additional properties. [=Verification methods=] SHOULD be registered
in the Data Integrity Specification Registries [TBD - DIS-REGISTRIES].
              </p>
              <p class="note">
The `verificationMethod` property is REQUIRED for proofs, unlike controller
documents, for which it is optional. See section [[[#proofs]]].
              </p>

              <dl>
                <dt>id</dt>
                <dd>
                  <p>
The value of the `id` property for a [=verification method=] MUST be a
[=string=] that conforms to the [[URL]] syntax.
                  </p>
                </dd>
                <dt>type</dt>
                <dd>
The value of the `type` property MUST be a [=string=] that either conforms to the
[[URL]] syntax or maps (through interpretation of the `@context` property) to a [[URL]],
and that references exactly one [=verification method=] type.
This specification defines two
[=verification method=] types (<a href="#multikey">`Multikey`</a> and
<a href="#jsonwebkey">`JsonWebKey`</a>); others might be defined by the community.
To maximize global interoperability, such community-defined [=verification method=]
types SHOULD be registered in the [[[VC-SPECS]]] [[[?VC-SPECS]]].
                </dd>
                <dt><span id="defn-controller">controller</span></dt>
                <dd>
The value of the `controller` property MUST be a [=string=] that conforms to
the [[URL]] syntax.
                </dd>
                <dt id="defn-vm-expires">expires</dt>
                <dd>
The `expires` property is OPTIONAL. It is set, in advance, by the
[=controller=] of a  [=verification method=] to signal when that method
can no longer be used for verification purposes. If provided, it MUST be an
[[XMLSCHEMA11-2]] `dateTimeStamp` string specifying when the
[=verification method=] SHOULD cease to be used. Once the value is set, it is
not expected to be updated, and systems depending on the value are expected to
not verify any proofs associated with the [=verification method=] at or after
the time of expiration.
                </dd>
                <dt><dfn class="lint-ignore">revoked</dfn></dt>
                <dd>
The `revoked` property is OPTIONAL. It is set by the [=controller=] of a
[=verification method=] to signal when that method is to no longer to be used
for verification purposes, such as after a security compromise of the
[=verification method=]. If provided, it MUST be an [[XMLSCHEMA11-2]]
`dateTimeStamp` string specifying when the [=verification method=]
SHOULD cease to be used. Once the value is set, it is not expected to be
updated, and systems depending on the value are expected to not verify any
proofs associated with the [=verification method=] at or after the time of
revocation.
                </dd>
              </dl>
            </dd>
          </dl>

          <pre class="example nohighlight"
            title="Example verification method structure">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/data-integrity/v2"
      ]
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "verificationMethod": [{
        "id": <span class="comment">...</span>,
        "type": <span class="comment">...</span>,
        "controller": <span class="comment">...</span>,
        "publicKeyJwk": <span class="comment">...</span>
      }, {
        "id": <span class="comment">...</span>,
        "type": <span class="comment">...</span>,
        "controller": <span class="comment">...</span>,
        "publicKeyMultibase": <span class="comment">...</span>
      }]
    }
          </pre>

          <p class="note"
            title="Verification method controller(s) and controller(s)">
The semantics of the `controller` property are the same when the
subject of the relationship is the [=controller document=] as when the subject of
the relationship is a [=verification method=], such as a cryptographic public
key. Since a key can't control itself, and the key controller cannot be inferred
from the [=controller document=], it is necessary to explicitly express the identity
of the controller of the key. The difference is that the value of
`controller` for a [=verification method=] is <em>not</em>
necessarily a [=controller=]. [=controllers=] are expressed
using the `[=controller=]` property at the highest level of the
[=controller document=].
          </p>

          <section>
            <h3>Verification Material</h3>

            <p>
Verification material is any information that is used by a process that applies
a [=verification method=]. The `type` of a [=verification method=] is
expected to be used to determine its compatibility with such processes. Examples
of verification methods include `JsonWebKey` and `Multikey`.
A [=cryptographic suite=] specification is responsible for specifying the
[=verification method=] `type` and its associated verification material
format. For examples, see
<a href="https://www.w3.org/TR/vc-di-ecdsa/">the Data Integrity ECDSA
Cryptosuites</a> and <a href="https://w3c-ccg.github.io/lds-ed25519-2020/">
the Data Integrity EdDSA Cryptosuites</a>. For a list of <a>verification
method</a> types, please see the [[?SECURITY-VOCABULARY]].
            </p>

            <p>
To increase the likelihood of interoperable implementations, this specification
limits the number of formats for expressing verification material in a
[=controller document=]. The fewer formats that implementers have to
implement, the more likely it will be that they will support all of them. This
approach attempts to strike a delicate balance between easing implementation
and providing support for formats that have historically had broad deployment.
            </p>

            <p>
A [=verification method=] MUST NOT contain multiple verification material
properties for the same material. For example, expressing key material in a
[=verification method=] using both `publicKeyJwk` and
`publicKeyMultibase` at the same time is prohibited.
            </p>

            <p>
An example of a [=controller document=] containing <a>verification
methods</a> using both properties above is shown below.
            </p>

            <pre id="example-various-verification-method-types"
              class="example nohighlight"
              title="Verification methods using publicKeyJwk and publicKeyMultibase">
{
  "@context": [
    "https://www.w3.org/ns/did/v1",
    "https://w3id.org/security/jwk/v1",
    "https://w3id.org/security/multikey/v1"
  ]
  "id": "did:example:123456789abcdefghi",
  <span class="comment">...</span>
  "verificationMethod": [{
    "id": "did:example:123#_Qq0UL2Fq651Q0Fjd6TvnYE-faHiOpRlPVQcY_-tA4A",
    "type": "JsonWebKey",
    "controller": "did:example:123",
    "publicKeyJwk": {
      <span class="comment">// the four properties below are defined by JWK (RFC 7517)</span>
      "crv": "Ed25519",
      "x": "VCpo2LMLhn6iWku8MKvSLg2ZAoC-nlOyPVQaO3FxVeQ",
      "kty": "OKP",
      "kid": "_Qq0UL2Fq651Q0Fjd6TvnYE-faHiOpRlPVQcY_-tA4A"
    }
  }, {
    "id": "did:example:123456789abcdefghi#keys-1",
    "type": "Multikey",
    "controller": "did:example:pqrstuvwxyz0987654321",
    "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
  }],
  <span class="comment">...</span>
}
            </pre>
          </section>

          <section>
            <h3>Multikey</h3>
            <p>
The Multikey data model is a specific type of [=verification method=] that
encodes key types into a single binary stream that is then encoded as a
Multibase value as described in Section [[[#multibase-0]]].
            </p>

            <p>
When specifying a `Multikey`, the object takes the following form:
            </p>

            <dl>
              <dt>type</dt>
              <dd>
The value of the `type` property MUST contain the string `Multikey`.
              </dd>
              <dt><dfn class="lint-ignore">publicKeyMultibase</dfn></dt>
              <dd>
The `publicKeyMultibase` property is OPTIONAL. If present, its value MUST be a
Multibase-encoded value as described in Section [[[#multibase-0]]]. The value format itself,
which is encoded in Multibase, MUST be defined by the cryptographic suite specification used by
the [=verification method=].
              </dd>
              <dt><dfn class="lint-ignore">secretKeyMultibase</dfn></dt>
              <dd>
The `secretKeyMultibase` property is OPTIONAL. If present, its value MUST be a
Multibase-encoded value as described in Section [[[#multibase-0]]]. The value format itself,
which is encoded in Multibase, MUST be defined by the cryptographic suite specification used by
the [=verification method=].
              </dd>
            </dl>

            <p>
              Implementations that perform JSON-LD processing MUST use the `https://w3id.org/security/multikey/v1` context URL for
              Multikey.
            </p>

            <p>
An example of a Multikey is provided below:
            </p>

            <pre class="example nohighlight"
              title="Multikey encoding of a Ed25519 public key">
{
  "@context": ["https://w3id.org/security/multikey/v1"],
  "id": "did:example:123456789abcdefghi#keys-1",
  "type": "Multikey",
  "controller": "did:example:123456789abcdefghi",
  "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
}
            </pre>

            <p>
In the example above, the `publicKeyMultibase` value starts with the letter `z`,
which is the <a href="#multibase-0">Multibase</a> header that conveys that the
binary data is base-58-btc-encoded using the Bitcoin base-encoding alphabet. The
decoded binary data header is `0xed01`, which specifies that the
remaining data is a 32-byte raw Ed25519 [=public key=].
            </p>

            <p>
The Multikey data model is also capable of encoding secret keys, whose subtypes
include <em>symmetric keys</em> and <em>private keys</em>.
            </p>

            <pre class="example nohighlight"
              title="Multikey encoding of a Ed25519 secret key">
{
  "@context": ["https://w3id.org/security/multikey/v1"],
  "id": "did:example:123456789abcdefghi#keys-1",
  "type": "Multikey",
  "controller": "did:example:123456789abcdefghi",
  "secretKeyMultibase": "z3u2fprgdREFtGakrHr6zLyTeTEZtivDnYCPZmcSt16EYCER"
}
            </pre>

            <p>
In the example above, the `secretKeyMultibase` value starts with the letter `z`,
which is the <a href="#multibase-0">Multibase</a> header that conveys that the
binary data is base-58-btc-encoded using the Bitcoin base-encoding alphabet. The
decoded binary data header is `0x8026`, which specifies that the
remaining data is a 32-byte raw Ed25519 private key.
            </p>

          </section>

          <section>
            <h3>JsonWebKey</h3>
            <p>
The JSON Web Key (JWK) data model is a specific type of [=verification method=]
that uses the JWK specification [[RFC7517]] to encode key types into a
set of parameters.
            </p>

            <p>
When specifing a `JsonWebKey`, the object takes the following form:
            </p>

            <dl>
              <dt>type</dt>
              <dd>
The value of the `type` property MUST contain the string `JsonWebKey`.
              </dd>
              <dt><dfn class="lint-ignore">publicKeyJwk</dfn></dt>
              <dd>
The `publicKeyJwk` property is OPTIONAL. If present, its value MUST
be a [=map=] representing a JSON Web Key that
conforms to [[RFC7517]]. The [=map=] MUST NOT
include any members of the private information class, such as `d`, as described
in the <a href="https://datatracker.ietf.org/doc/html/rfc7517#section-8.1.1">JWK
Registration Template</a>. It is RECOMMENDED that verification methods that use
JWKs [[RFC7517]] to represent their [=public keys=] use the value of `kid` as
their fragment identifier. It is RECOMMENDED that JWK `kid` values are set to
the public key fingerprint [[RFC7638]]. See the first key in
[[[#example-various-verification-method-types]]] for an example of a
public key with a compound key identifier.
              </dd>
              <dt><dfn class="lint-ignore">secretKeyJwk</dfn></dt>
              <dd>
The `secretKeyJwk` property is OPTIONAL. If present, its value MUST be a [=map=]
representing a JSON Web Key that conforms to [[RFC7517]].
              </dd>
            </dl>

            <p>
              Implementations that perform JSON-LD processing MUST use the `https://w3id.org/security/jwk/v1` context URL for
              JsonWebKey.
            </p>

            <p>
An example of an object that conforms to this data model is provided below:
            </p>

            <pre class="example nohighlight"
              title="JSON Web Key encoding of an Ed25519 public key">
{
  "@context": ["https://w3id.org/security/jwk/v1"],
  "id": "did:example:123456789abcdefghi#key-1",
  "type": "JsonWebKey",
  "controller": "did:example:123456789abcdefghi",
  "publicKeyJwk": {
    "kty": "OKP",
    "alg": "EdDSA"
    "crv": "Ed25519",
    "kid": "key-1",
    "x": "_1EiHquO2aUx9JARSu0P8jdYT_OVneYxYOnOMAmUcFI",
  }
}
            </pre>

            <p>
In the example above, the `publicKeyJwk` value contains the JSON Web Key.
The `kty` property encodes the key type of "OKP", which means
"Octet string key pairs". The `alg` property identifies the algorithm intended
for use with the public key. The `crv` property identifies the particular
curve type of the public key. The `kid` property specifies how the public key
might be referenced in software systems; if present, the `kid` value SHOULD match the
`id` property of the encapsulating `JsonWebKey` object. Finally, the `x`
property specifies the point on the Ed25519 curve that is associated with the
public key.
            </p>

            <p>
The `publicKeyJwk` property MUST NOT contain any property marked as
"Private" in any registry contained in the JOSE Registries [[JOSE-REGISTRIES]].
            </p>

            <p>
The JSON Web Key data model is also capable of encoding <em>secret keys</em>, sometimes
referred to as <em>private keys</em>.
            </p>

            <pre class="example nohighlight"
              title="JSON Web Key encoding of an Ed25519 secret key">
{
  "@context": ["https://w3id.org/security/jwk/v1"],
  "id": "did:example:123456789abcdefghi#key-1",
  "type": "JsonWebKey",
  "controller": "did:example:123456789abcdefghi",
  "secretKeyJwk": {
    "kty": "OKP",
    "alg": "EdDSA"
    "crv": "Ed25519",
    "kid": "key-1",
    "d": "Q6JwjCUdThSnoxfXHSFt5C1nVFycY_ZpW7qVzK644_g",
    "x": "_1EiHquO2aUx9JARSu0P8jdYT_OVneYxYOnOMAmUcFI",
  }
}
            </pre>

            <p>
The private key example above is almost identical to the previous example of the
public key, except that the information is stored in the `secretKeyJwk` property
(rather than the `publicKeyJwk`), and the private key value is encoded in the `d`
property thereof (alongside the `x` property, which still specifies the point on
the Ed25519 curve that is associated with the public key).
            </p>

          </section>

          <section>
            <h3>Referring to Verification Methods</h3>
            <p>
[=Verification methods=] can be embedded in or referenced from properties
associated with various [=verification relationships=] as described in
[[[#verification-relationships]]]. Referencing [=verification methods=]
allows them to be used by more than one [=verification relationship=].
            </p>

            <p>
If the value of a [=verification method=] property is a [=map=], the
[=verification method=] has been embedded and its properties can be accessed
directly. However, if the value is a URL [=string=], the <a>verification
method</a> has been included by reference and its properties will need to be
retrieved from elsewhere in the [=controller document=] or from another
[=controller document=]. This is done by dereferencing the URL and searching
the resulting [=resource=] for a [=verification method=] [=map=] with
an `id` property whose value matches the URL.
            </p>

            <pre class="example nohighlight"
            title="Embedding and referencing verification methods">
    {
<span class="comment">...</span>

      "authentication": [
        <span class="comment">// this key is referenced and might be used by</span>
        <span class="comment">// more than one verification relationship</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this key is embedded and may *only* be used for authentication</span>
        {
          "id": "did:example:123456789abcdefghi#keys-2",
          "type": "Multikey",
          "controller": "did:example:123456789abcdefghi",
          "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
        }
      ],

<span class="comment">...</span>
    }
            </pre>
          </section>
        </section>

        <section>
          <h2>Verification Relationships</h2>

          <p>
A [=verification relationship=] expresses the relationship between the
[=controller=] and a [=verification method=].
          </p>
          <p>
Different [=verification relationships=] enable the associated
[=verification methods=] to be used for different purposes. It is up to a
<em>verifier</em> to ascertain the validity of a verification attempt by
checking that the [=verification method=] used is contained in the
appropriate [=verification relationship=] property of the
[=controller document=].
          </p>
          <p>
The [=verification relationship=] between the [=controller=] and the
[=verification method=] is explicit in the [=controller document=].
[=Verification methods=] that are not associated with a particular
[=verification relationship=] cannot be used for that <a>verification
relationship</a>. For example, a [=verification method=] in the value of
the `[=authentication=]` property cannot be used to engage in
key agreement protocols with the [=controller=]&mdash;the value of the
`[=keyAgreement=]` property needs to be used for that.
          </p>
          <p>
The [=controller document=] does not express revoked keys using a <a>verification
relationship</a>. If a referenced verification method is not in the latest
[=controller document=] used to dereference it, then that verification method is
considered invalid or revoked.
          </p>
          <p>
The following sections define several useful [=verification relationships=].
A [=controller document=] MAY include any of these, or other properties, to
express a specific [=verification relationship=]. In order to maximize global
interoperability, any such properties used SHOULD be registered in the
Data Integrity Specification Registries [TBD: DIS-REGISTRIES].
          </p>

          <section>
            <h2>Authentication</h2>

            <p>
The `authentication` [=verification relationship=] is used to
specify how the [=controller=] is expected to be [=authenticated=], for
purposes such as logging into a website or engaging in any sort of
challenge-response protocol.
            </p>

            <dl>
              <dt id="defn-authentication">authentication</dt>
              <dd>
The `authentication` property is OPTIONAL. If present, the associated
value MUST be a [=set=] of one or more
[=verification methods=]. Each [=verification method=] MAY be embedded or
referenced.
              </dd>
            </dl>

            <pre class="example nohighlight" title="Authentication property
                          containing three verification methods">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/multikey/v1"
      ],
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "authentication": [
        <span class="comment">// this method can be used to authenticate as did:...fghi</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this method is *only* approved for authentication, it may not</span>
        <span class="comment">// be used for any other proof purpose, so its full description is</span>
        <span class="comment">// embedded here rather than using only a reference</span>
        {
          "id": "did:example:123456789abcdefghi#keys-2",
          "type": "Multikey",
          "controller": "did:example:123456789abcdefghi",
          "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
        }
      ],
      <span class="comment">...</span>
    }
            </pre>

            <p>
If authentication is established, it is up to the application to decide what to
do with that information.
            </p>
            <p>
This is useful to any <em>authentication verifier</em> that needs to check to
see if an entity that is attempting to [=authenticate=] is, in fact,
presenting a valid proof of authentication. When a <em>verifier</em> receives
some data (in some protocol-specific format) that contains a proof that was made
for the purpose of "authentication", and that says that an entity is identified
by the `id`, then that <em>verifier</em> checks to ensure that the proof can be
verified using a [=verification method=] (e.g., [=public key=]) listed
under `[=authentication=]` in the [=controller document=].
            </p>
            <p>
Note that the [=verification method=] indicated by the
`[=authentication=]` property of a [=controller document=] can
only be used to [=authenticate=] the [=controller=]. To
[=authenticate=] a different [=controller=], the entity associated with
the value of `controller` needs to [=authenticate=] with its
<em>own</em> [=controller document=] and associated
`[=authentication=]` [=verification relationship=].
            </p>
          </section>

          <section>
            <h2>Assertion</h2>

            <p>
The `assertionMethod` [=verification relationship=] is used to
specify how the [=controller=] is expected to express claims, such as for
the purposes of issuing a Verifiable Credential [[?VC-DATA-MODEL-2.0]].
            </p>

            <dl>
              <dt>
                <dfn id="defn-assertionMethod" class="lint-ignore">
                  assertionMethod
                </dfn>
              </dt>
              <dd>
The `assertionMethod` property is OPTIONAL. If present, the
associated value MUST be a [=set=] of
one or more [=verification methods=]. Each [=verification method=] MAY be
embedded or referenced.
              </dd>
            </dl>

            <p>
This property is useful, for example, during the processing of a <a>verifiable
credential</a> by a verifier. During verification, a verifier checks to see if a
[=verifiable credential=] contains a proof created by the [=controller=]
by checking that the [=verification method=] used to assert the proof is
associated with the `[=assertionMethod=]` property in the
corresponding [=controller document=].
            </p>

            <pre class="example nohighlight" title="Assertion method property
                        containing two verification methods">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/multikey/v1"
      ],
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "assertionMethod": [
        <span class="comment">// this method can be used to assert statements as did:...fghi</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this method is *only* approved for assertion of statements, it is not</span>
        <span class="comment">// used for any other verification relationship, so its full description is</span>
        <span class="comment">// embedded here rather than using a reference</span>
        {
          "id": "did:example:123456789abcdefghi#keys-2",
          "type": "Multikey",
          "controller": "did:example:123456789abcdefghi",
          "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
        }
      ],
      <span class="comment">...</span>
    }
            </pre>
          </section>

          <section>
            <h2>Key Agreement</h2>

            <p>
The `keyAgreement` [=verification relationship=] is used to
specify how an entity can generate encryption material in order to transmit
confidential information intended for the [=controller=], such as for
the purposes of establishing a secure communication channel with the recipient.
            </p>

            <dl>
              <dt>
                <dfn id="defn-keyAgreement" class="lint-ignore">
                  keyAgreement
                </dfn>
              </dt>
              <dd>
The `keyAgreement` property is OPTIONAL. If present, the associated
value MUST be a [=set=] of one or more
[=verification methods=]. Each [=verification method=] MAY be embedded or
referenced.
              </dd>
            </dl>

            <p>
An example of when this property is useful is when encrypting a message intended
for the [=controller=]. In this case, the counterparty uses the
cryptographic [=public key=] information in the [=verification method=] to
wrap a decryption key for the recipient.
            </p>

            <pre class="example nohighlight" title="Key agreement property
                          containing two verification methods">
    {
      "@context": "https://www.w3.org/ns/did/v1",
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "keyAgreement": [
        <span class="comment">// this method can be used to perform key agreement as did:...fghi</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this method is *only* approved for key agreement usage, it will not</span>
        <span class="comment">// be used for any other verification relationship, so its full description is</span>
        <span class="comment">// embedded here rather than using only a reference</span>
        {
          "id": "did:example:123#zC9ByQ8aJs8vrNXyDhPHHNNMSHPcaSgNpjjsBYpMMjsTdS",
          "type": "X25519KeyAgreementKey2019", <span class="comment">// external (property value)</span>
          "controller": "did:example:123",
          "publicKeyMultibase": "z6LSn6p3HRxx1ZZk1dT9VwcfTBCYgtNWdzdDMKPZjShLNWG7"
        }
      ],
      <span class="comment">...</span>
    }
            </pre>
          </section>

          <section>
            <h2>Capability Invocation</h2>

            <p>
The `capabilityInvocation` [=verification relationship=] is used
to specify a [=verification method=] that might be used by the
[=controller=] to invoke a cryptographic capability, such as the
authorization to update the [=controller document=].
            </p>

            <dl>
              <dt>
                <dfn id="defn-capabilityInvocation" class="lint-ignore">
                  capabilityInvocation
                </dfn>
              </dt>
              <dd>
The `capabilityInvocation` property is OPTIONAL. If present, the
associated value MUST be a [=set=] of
one or more [=verification methods=]. Each [=verification method=] MAY be
embedded or referenced.
              </dd>
            </dl>

            <p>
An example of when this property is useful is when a [=controller=] needs to
access a protected HTTP API that requires authorization in order to use it. In
order to authorize when using the HTTP API, the [=controller=]
uses a capability that is associated with a particular URL that is
exposed via the HTTP API. The invocation of the capability could be
expressed in a number of ways, e.g., as a digitally signed
message that is placed into the HTTP Headers.
            </p>
            <p>
The server providing the HTTP API is the <em>verifier</em> of the capability and
it would need to verify that the [=verification method=] referred to by the
invoked capability exists in the `[=capabilityInvocation=]`
property of the [=controller document=]. The verifier would also check to make sure
that the action being performed is valid and the capability is appropriate for
the resource being accessed. If the verification is successful, the server has
cryptographically determined that the invoker is authorized to access the
protected resource.
            </p>

            <pre class="example nohighlight" title="Capability invocation property
                          containing two verification methods">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/multikey/v1"
      ],
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "capabilityInvocation": [
        <span class="comment">// this method can be used to invoke capabilities as did:...fghi</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this method is *only* approved for capability invocation usage, it will not</span>
        <span class="comment">// be used for any other verification relationship, so its full description is</span>
        <span class="comment">// embedded here rather than using only a reference</span>
        {
        "id": "did:example:123456789abcdefghi#keys-2",
        "type": "Multikey",
        "controller": "did:example:123456789abcdefghi",
        "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
        }
      ],
      <span class="comment">...</span>
    }
            </pre>
          </section>

          <section>
            <h2>Capability Delegation</h2>

            <p>
The `capabilityDelegation` [=verification relationship=] is used
to specify a mechanism that might be used by the [=controller=] to delegate
a cryptographic capability to another party, such as delegating the authority
to access a specific HTTP API to a subordinate.
            </p>

            <dl>
              <dt><dfn class="lint-ignore" id="defn-capabilityDelegation">capabilityDelegation</dfn></dt>
              <dd>
The `capabilityDelegation` property is OPTIONAL. If present, the
associated value MUST be a [=set=] of
one or more [=verification methods=]. Each [=verification method=] MAY be
embedded or referenced.
              </dd>
            </dl>

            <p>
An example of when this property is useful is when a [=controller=] chooses
to delegate their capability to access a protected HTTP API to a party other
than themselves. In order to delegate the capability, the [=controller=]
would use a [=verification method=] associated with the
`capabilityDelegation` [=verification relationship=] to
cryptographically sign the capability over to another [=controller=]. The
delegate would then use the capability in a manner that is similar to the
example described in [[[#capability-invocation]]].
            </p>

            <pre class="example nohighlight" title="Capability Delegation property
                          containing two verification methods">
    {
      "@context": [
        "https://www.w3.org/ns/did/v1",
        "https://w3id.org/security/multikey/v1"
      ],
      "id": "did:example:123456789abcdefghi",
      <span class="comment">...</span>
      "capabilityDelegation": [
        <span class="comment">// this method can be used to perform capability delegation as did:...fghi</span>
        "did:example:123456789abcdefghi#keys-1",
        <span class="comment">// this method is *only* approved for granting capabilities; it will not</span>
        <span class="comment">// be used for any other verification relationship, so its full description is</span>
        <span class="comment">// embedded here rather than using only a reference</span>
        {
        "id": "did:example:123456789abcdefghi#keys-2",
        "type": "Multikey",
        "controller": "did:example:123456789abcdefghi",
        "publicKeyMultibase": "z6MkmM42vxfqZQsv4ehtTjFFxQ4sQKS2w6WR7emozFAn5cxu"
        }
      ],
      <span class="comment">...</span>
    }
            </pre>
          </section>
        </section>
      </section>

      <section>
        <h2>Multibase</h2>

        <p class="issue"
           title="Multibase may be standardized at IETF">
The [[?MULTIBASE]] specification has been dispatched at IETF and may be
standardized there. There is active discussion on this initiative in
the <a href="https://mailarchive.ietf.org/arch/browse/multiformats/">
Multiformats mailing list at IETF</a>. If the Multibase draft is stabilized
before this specification goes to the Proposed Recommendation phase, the table
below will be replaced with normative references to the Multibase
specification at IETF. It is the intention of the Working Group to ensure
alignment between the Multibase values used in this specification and the
Multibase values defined by the current Multibase community and any potential
future IETF Multiformats Working Group.
        </p>

        <p>
A Multibase string includes a single character header which identifies the
base and encoding alphabet used to encode a binary value, followed by the
encoded binary value (using that base and alphabet). The common Multibase
header values and their associated base encoding alphabets as provided below
are normative:
        </p>

        <table class="simple">
          <thead>
            <tr>
              <th>Multibase&nbsp;Header</th>
              <th>Description</th>
            </tr>
          </thead>

          <tbody>
            <tr>
              <td>`u`</td>
              <td>
The base-64-url-no-pad alphabet is used to encode the bytes. The base-alphabet
consists of the following characters, in order:
`ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_`
              </td>
            </tr>
            <tr>
              <td>`z`</td>
              <td>
The base-58-btc alphabet is used to encode the bytes. The base-alphabet consists
of the following characters, in order:
`123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz`
              </td>
            </tr>
          </tbody>
        </table>

        <p>
Other Multibase encoding values MAY be used, but interoperability is not
guaranteed between implementations using such values.
        </p>

        <p>
To base-encode a binary value into a Multibase string, an implementation MUST
apply the algorithm in Section [[[#base-encode]]] to the binary value,
with the desired base encoding and alphabet from the table above, ensuring to
prepend the associated Multibase header from the table above to the result.
Any algorithm with equivalent output MAY be used.
        </p>

        <p>
To base-decode a Multibase string, an implementation MUST apply the algorithm
in Section [[[#base-decode]]] to the string following the first
character (Multibase header), with the alphabet associated with the
Multibase header. Any algorithm with equivalent output MAY be used.
        </p>

      </section>

      <section>
        <h2>Multihash</h2>

        <p class="issue" title="Multihash may be standardized at IETF">
The [[?MULTIHASH]] specification has been dispatched at IETF and may be
standardized. There is active discussion on this initiative in
the <a href="https://mailarchive.ietf.org/arch/browse/multiformats/">
Multiformats mailing list at IETF</a>. If the IETF draft is stabilized
before this specification goes to the Proposed Recommendation phase, the table
below will be replaced with normative references to the Multihash
specification. It is the intention of the Working Group to ensure
alignment between the Multihash values used in this specification and the
Multihash values defined by the current Multihash community and any potential
future IETF Multiformats Working Group.
        </p>

        <p>
A Multihash value starts with a binary header, which identifies the specific
cryptographic hash algorithm and parameters used to generate the digest,
followed by the cryptographic digest value. The normative Multihash header
values defined by this specification, and their associated output sizes and
associated specifications, are provided below:
        </p>

        <table class="simple">
          <thead>
            <tr>
              <th>Multihash&nbsp;Identifier</th>
              <th>Multihash&nbsp;Header</th>
              <th>Description</th>
            </tr>
          </thead>

          <tbody>
            <tr>
              <td>`sha2-256`</td>
              <td>`0x12`</td>
              <td>
SHA-2 with 256 bits (32 bytes) of output, as defined by [[RFC6234]].
              </td>
            </tr>
            <tr>
              <td>`sha2-384`</td>
              <td>`0x20`</td>
              <td>
SHA-2 with 384 bits (48 bytes) of output, as defined by [[RFC6234]].
              </td>
            </tr>
            <tr>
              <td>`sha3-256`</td>
              <td>`0x16`</td>
              <td>
SHA-3 with 256 bits (32 bytes) of output, as defined by [[SHA3]].
              </td>
            </tr>
            <tr>
              <td>`sha3-384`</td>
              <td>`0x15`</td>
              <td>
SHA-3 with 384 bits (48 bytes) of output, as defined by [[SHA3]].
              </td>
            </tr>
          </tbody>
        </table>

        <p>
Other Multihash encoding values MAY be used, but interoperability is not
guaranteed between implementations.
        </p>

        <p>
To encode to a Multihash value, an implementation MUST prepend the associated
Multihash header value to the cryptographic hash value.
        </p>

        <p>
To decode a Multihash value, an implementation MUST remove the prepended
Multihash header value, which identifies the type of cryptographic hashing
algorithm as well as its output length, leaving the raw cryptographic hash
value which MUST match the output length associated with the Multihash header.
        </p>

      </section>

      <section>
        <h2>Resource Integrity</h2>

        <p class="issue atrisk" title="Unification of cryptographic hash expression formats are under discussion">
The Working Group is currently attempting to determine whether cryptographic hash
expression formats can be unified across all of the VCWG core specifications.
Candidates for this mechanism include `digestSRI` and `digestMultibase`. There
are arguments for and against unification that the WG is currently debating.
        </p>

        <p>
When a link to an external resource is included in a
[=conforming secured document=], it is desirable to know whether the resource
that is identified has changed since the proof was created. This applies to
cases where there is an external resource that is remotely retrieved as well as
to cases where the [=verifier=] might have a locally cached copy of the
resource.
        </p>
        <p>
To enable confirmation that a resource referenced by a [=conforming secured document=]
has not changed since the document was secured, an implementer MAY include a
property named <dfn class="lint-ignore">`digestMultibase`</dfn> in any object
that includes an `id` property. If present, the `digestMultibase` value MUST be
a single string value, or an array of string values that are
<a href="#multibase-0">Multibase</a>-encoded <a href="#multihash">Multihash</a>
values.
        </p>
        <p>
JSON-LD context authors are expected to add `digestMultibase` to contexts that will 
be used in documents that refer to other resources and include an associated 
content integrity hash. For example, the [[[VC-DATA-MODEL-2.0]]]
context (`https://www.w3.org/ns/credentials/v2`) includes it.
        </p>

        <p>
An example of a resource integrity protected object is shown below:
        </p>

        <pre class="example nohighlight"
          title="An integrity-protected image that is associated with an object">
{
  ...
  "image": {
    "id": "https://university.example.org/images/58473",
    "digestMultibase": "zQmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n"
  },
  ...
}
        </pre>

        <p>
Implementers are urged to consult appropriate sources, such as the
<a href="https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf">
FIPS 180-4 Secure Hash Standard</a> and the
<a href="https://media.defense.gov/2022/Sep/07/2003071834/-1/-1/0/CSA_CNSA_2.0_ALGORITHMS_.PDF">
Commercial National Security Algorithm Suite 2.0</a> to ensure that they are
choosing a hash algorithm that is appropriate for their use case.
        </p>

      </section>

      <section>
        <h2>Relationship to Linked Data</h2>
        <p>
The term Linked Data is used to describe a recommended best practice for
exposing, sharing, and connecting information on the Web using standards, such
as URLs, to identify things and their properties. When information is presented
as Linked Data, other related information can be easily discovered and new
information can be easily linked to it. Linked Data is extensible in a
decentralized way, greatly reducing barriers to large scale integration.
        </p>

        <p>
With the increase in usage of Linked Data for a variety of applications, there
is a need to be able to verify the authenticity and integrity of Linked Data
documents. This specification adds authentication and integrity protection to
data documents through the use of mathematical proofs without sacrificing Linked
Data features such as extensibility and composability.
        </p>

        <p class="note" title="Use of Linked Data is an optional feature">
While  this specification provides mechanisms to digitally sign Linked Data, the
use  of Linked Data is not necessary to gain some of the advantages provided by
this specification.
        </p>

      </section>

      <section>
        <h2>Relationship to Verifiable Credentials</h2>

        <p>
Cryptographic suites that implement this specification can be used to secure
[=verifiable credentials=] and [=verifiable presentations=]. Implementers
that are addressing those use cases are cautioned that additional checks might
be appropriate when processing those types of documents.
        </p>

        <p>
There are some use cases where it is important to ensure that the
[=verification method=] used in a proof is associated with the
<a data-cite="?VC-DATA-MODEL-2.0#issuer">`issuer`</a> in a
<a data-cite="?VC-DATA-MODEL-2.0#dfn-verifiable-credential">
verifiable credential</a>, or the
<a data-cite="?VC-DATA-MODEL-2.0#dfn-holders">`holder`</a> in a
<a data-cite="?VC-DATA-MODEL-2.0#dfn-verifiable-presentation">
verifiable presentation</a>, during the process of
<a data-cite="?VC-DATA-MODEL-2.0#issuer-0">validation</a>. One
way to check for such an association is to ensure that the value of the
`controller` property of a proof's [=verification method=]
matches the URL value used to identify the
<a data-cite="?VC-DATA-MODEL-2.0#issuer">`issuer`</a> or
<a data-cite="?VC-DATA-MODEL-2.0#dfn-holders">`holder`</a>, respectively.
This particular association indicates that the
<a data-cite="?VC-DATA-MODEL-2.0#issuer">`issuer`</a> or
<a data-cite="?VC-DATA-MODEL-2.0#dfn-holders">`holder`</a>, respectively,
is the controller of the [=verification method=] used to verify
the proof.
        </p>

        <p>
Document authors and implementers are advised to understand the difference
between the validity period of a <a href="#proofs">proof</a>, which is expressed
using the <a href="#dfn-created">`created`</a> and <a
href="#defn-proof-expires">`expires`</a> properties, and the validity period of
a <a data-cite="?VC-DATA-MODEL-2.0#dfn-credential">credential</a>,
which is expressed using the
<a data-cite="?VC-DATA-MODEL-2.0#defn-validFrom">`validFrom`</a> and
<a data-cite="?VC-DATA-MODEL-2.0#defn-validUntil">`validUntil`</a> properties.
While these properties might sometimes express the same validity periods, at
other times they might not be aligned. When verifying a
<a href="#proofs">proof</a>, it is important to ensure that the time of interest
(which might be the current time or any other time) is within the
validity period for the proof (that is, between
<a href="#dfn-created">`created`</a> and
<a href="#defn-proof-expires">`expires`</a> ).
When <a data-cite="?VC-DATA-MODEL-2.0#validation">validating</a> a
[=verifiable credential=], it is important to ensure that the time of
interest is within the validity period for the
<a data-cite="?VC-DATA-MODEL-2.0#dfn-credential">credential</a> (that is,
betweeen
<a data-cite="?VC-DATA-MODEL-2.0#defn-validFrom">`validFrom`</a> and
<a data-cite="?VC-DATA-MODEL-2.0#defn-validUntil">`validUntil`</a>). Note that a
failure to validate either the validity period for the <a
href="#proofs">proof</a>, or the validity period for the
<a data-cite="?VC-DATA-MODEL-2.0#dfn-credential">credential</a>, might result
in accepting data that ought to have been rejected.
        </p>

        <p>
Finally, implementers are also urged to understand that there is a difference
between the <a href="#dfn-revoked">revocation time</a> and
<a href="#defn-vm-expires">expiration time</a> for a [=verification method=],
and the revocation information associated with a [=verifiable credential=].
The <a href="#dfn-revoked">revocation time</a> and
<a href="#defn-vm-expires">expiration time</a> for a [=verification method=]
are expressed using the `revocation` and `expires` properties, respectively, and
are related to events such as a private key being compromised or expiring and
can provide timing information which might reveal details about a controller
such as their security practices or when they might have been compromised. The
revocation information for a [=verifiable credential=] is expressed using
the `credentialStatus` property and is related to events such as an individual
losing the privilege that is granted by the [=verifiable credential=] and
does not provide timing information, which enhances privacy.
        </p>
      </section>

      <section>
        <h2>Contexts and Vocabularies</h2>

        <p class="issue" title="(AT RISK) Hash values might change during Candidate Recommendation">
This section lists cryptographic hash values that might change during the
Candidate Recommendation phase based on implementer feedback that requires
the referenced files to be modified.
        </p>
        <p>
Implementations that perform JSON-LD processing MUST treat the following
JSON-LD context URLs as already resolved, where the resolved document matches
the corresponding hash values below:
        </p>

        <table class="simple">
          <thead>
            <tr>
              <th>URL</th>
              <th>Hash</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="white-space: nowrap;">
https://w3id.org/security/data-integrity/v2

              </td>
              <td>
sha256: `v/POI0jhSjPansxhJAP1fwepCBZ2HK77fRZfCCyBDs0=`
              </td>
            </tr>
            <tr>
              <td style="white-space: nowrap;">
https://w3id.org/security/multikey/v1
              </td>
              <td>
sha256: `uiwYLeLZL35HGEvMqPzwvq7m05hsUnv2ZMGVu8fFhZc=`
              </td>
            </tr>
            <tr>
              <td style="white-space: nowrap;">
https://w3id.org/security/jwk/v1
              </td>
              <td>
sha256: `9h/GLRVuGCl0rn/ye6lzf219aN7Sgzq9yBFqUoOI54k=`
              </td>
            </tr>
          </tbody>
        </table>

        <p>
          It is possible to confirm the cryptographic digests listed above by running
          a command like the following (replacing `&lt;DOCUMENT_URL>`
          with the appropriate value) through a modern UNIX-like OS command line interface:
          `curl -sL -H "Accept: application/ld+json" &lt;DOCUMENT_URL> | openssl dgst -sha256 -binary | openssl base64 -nopad
          -a`.
        </p>

        <p>
The security vocabulary terms that the JSON-LD contexts listed above resolve
to are in the <a href="https://w3id.org/security">https://w3id.org/security#</a>
namespace. That is, all security terms in this vocabulary are of the form
`https://w3id.org/security#TERM`, where `TERM` is the name of a term.
        </p>

        <p>
Implementations that perform RDF processing MUST treat
the JSON-LD serialization of the vocabulary URL as already dereferenced, where the dereferenced document matches
the corresponding hash value below.
        </p>

        <p>
When dereferencing the
<a href="https://w3id.org/security">https://w3id.org/security#</a> URL,
the media type of the data that is returned depends on HTTP content negotiation. These are as follows:
        </p>

        <table class="simple">
          <thead>
            <tr>
              <th>Media Type</th>
              <th>Description and Hash</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>
application/ld+json
              </td>
              <td>
The vocabulary in JSON-LD format [[?JSON-LD11]].<br><br>

sha256: `LEaoTyf796eTaSlYWjfPe3Yb+poCW9TjWYTbFDmC0tc=`
              </td>
            </tr>
            <tr>
              <td>
text/turtle
              </td>
              <td>
The vocabulary in Turtle format [[?TURTLE]].<br><br>
sha256: `McnhLyt7+/A/0iLb3CUXD0itNw+7bwwjtzOww/zwoyI=`
              </td>
            </tr>
            <tr>
              <td>
text/html
              </td>
              <td>
The vocabulary in HTML+RDFa Format [[?HTML-RDFA]].<br><br>
sha256: `eUHP1xiSC157iTPDydZmxg/hvmX3g/nnCn+FO25d4dc=`
              </td>
            </tr>
          </tbody>
        </table>

        <p>
It is possible to confirm the cryptographic digests listed above by running
a command like the following (replacing `&lt;MEDIA_TYPE>` and `&lt;DOCUMENT_URL>`
with the appropriate values) through a modern UNIX-like OS command line interface:
`curl -sL -H "Accept: &lt;MEDIA_TYPE>" &lt;DOCUMENT_URL> | openssl dgst -sha256 -binary | openssl base64 -nopad -a`.
        </p>

        <p>
Authors of application-specific vocabularies and specifications SHOULD ensure
that their JSON-LD context and vocabulary files are permanently cacheable
using the approaches to caching described above or a functionally equivalent
mechanism.
        </p>

        <p>
Implementations MAY load application-specific JSON-LD context files from the
network during development, but SHOULD permanently cache JSON-LD context files
used in [=conforming documents=] in production settings to increase their
security and privacy characteristics. Caching goals MAY be achieved through
approaches such as those described above or functionally equivalent mechanisms.
        </p>
        <p>
Some applications, such as digital wallets, that are capable of holding arbitrary
[=verifiable credentials=] or other data-integrity-protected documents, from
any issuer and using any contexts, might need to be able to load externally
linked resources, such as JSON-LD context files, in production settings. This is
expected to increase user choice, scalability, and decentralized upgrades in the
ecosystem over time. Authors of such applications are advised to read the
security and privacy sections of this document for further considerations.
        </p>

        <p>
For further information regarding processing of JSON-LD contexts and
vocabularies, see <a data-cite="?VC-DATA-MODEL-2.0#base-context">Verifiable
Credentials v2.0: Base Context</a> and <a data-cite="?VC-DATA-MODEL-2.0#vocabularies">
Verifiable Credentials v2.0: Vocabularies</a>.
        </p>

        <section>
          <h3>Context Injection</h3>

          <p>
The `@context` property is used to ensure that implementations are using the
same semantics when terms in this specification are processed. For example, this
can be important when properties like `type` are processed and its value, such
as `DataIntegrityProof`, are used.
          </p>

          <p>
If an `@context` property is not provided in a document that is being secured or
verified, or the Data Integrity terms used in the document are not mapped by
existing values in the `@context` property, implementations MUST inject or add
an `@context` property with a value of
`https://w3id.org/security/data-integrity/v2`.
          </p>

          <p>
Context injection is expected to be unnecessary sometimes, such as when the Verifiable
Credential Data Model v2.0 context (`https://www.w3.org/ns/credentials/v2`)
exists as a value in the `@context` property, as that context maps all of the
necessary Data Integrity terms that were previously mapped by
`https://w3id.org/security/data-integrity/v2`.
          </p>
        </section>

        <section>
          <h3>Securing Data Losslessly</h3>

          <p>
HTML processors are designed to continue processing if recoverable errors are
detected. JSON-LD processors operate in a similar manner. This design philosophy
was meant to ensure that developers could use only the parts of the JSON-LD
language that they find useful, without causing the processor to throw errors
on things that might not be important to the developer. Among other effects,
this philosophy led to JSON-LD processors being designed to not throw errors,
but rather warn developers, when encountering things such as undefined terms.
          </p>

          <p>
When converting from JSON-LD to an RDF Dataset, such as when canonicalizing a
document [[?RDF-CANON]], undefined terms and relative URLs can be dropped
silently. When values are dropped, they are not protected by a digital proof. This
creates a mismatch of expectations, where a developer, who is unaware of how
a JSON-LD processor works, might think that certain data was being secured,
and then be surprised to find that it was not, when no error was thrown.
This specification requires that any recoverable loss of data when
performing JSON-LD transformations result in an error, to avoid a mismatch
in the security expectations of developers.
          </p>

          <p>
Implementations that use JSON-LD processing, such as RDF Dataset
Canonicalization [[?RDF-CANON]], MUST throw an error, which SHOULD be
`DATA_LOSS_DETECTION_ERROR`, when data is dropped by a JSON-LD processor,
such as when an undefined term is detected in an input document.
          </p>

          <p>
Similarly, since [=conforming secured documents=] can be transferred from one
security domain to another, [=conforming processors=] that process the
[=conforming secured document=] cannot assume any particular base URL for
the document. When deserializing to RDF, implementations MUST ensure that the
base URL is set to null.
          </p>
        </section>

        <section>
          <h3>Datatypes</h3>

          <p>
This section defines datatypes that are used by this specification.
          </p>

        <section>
          <h4 id="cryptosuiteString">The `cryptosuiteString` Datatype</h3>

          <p>
This specification encodes cryptographic suite identifiers as enumerable
strings, which is useful in processes that need to efficiently encode such
strings, such as compression algorithms. In environments that support data types
for string values, such as RDF [[?RDF-CONCEPTS]], cryptographic identifier
content is indicated using a literal value whose datatype is set to
`https://w3id.org/security#cryptosuiteString`.
          </p>

          <p>
The `cryptosuiteString` datatype is defined as follows:
          </p>

          <dl>
            <dt>The URL denoting this datatype</dt>
            <dd>
`https://w3id.org/security#cryptosuiteString`
            </dd>
            <dt>The lexical space</dt>
            <dd>
The union of all cryptosuite strings, expressed using American Standard Code
for Information Interchange [[ASCII]] strings, that are defined by the
collection of all Data Integrity cryptosuite specifications.
            </dd>
            <dt>The value space</dt>
            <dd>
The union of all cryptosuite types that are expressed using the `cryptosuite`
property, as defined in Section [[[#dataintegrityproof]]].
            </dd>
            <dt>The lexical-to-value mapping</dt>
            <dd>
Any element of the lexical space is mapped to the result of parsing it into an
internal representation that uniquely identifies the cryptosuite type from all
other possible cryptosuite types.
            </dd>
            <dt>The canonical mapping</dt>
            <dd>
Any element of the value space is mapped to the corresponding string in the
lexical space.
            </dd>
          </dl>
        </section>

        <section>
          <h4 id="multibase">The `multibase` Datatype</h3>

          <p>
<a href="#multibase">Multibase</a>-encoded strings are used to encode binary
data into ASCII-only formats, which are useful in environments that cannot
directly represent binary values. This specification makes use of this encoding.
In environments that support data types for string values, such as RDF
[[?RDF-CONCEPTS]], <a href="#multibase">Multibase</a>-encoded content is
indicated using a literal value whose datatype is set to
`https://w3id.org/security#multibase`.
          </p>

          <p>
The `multibase` datatype is defined as follows:
          </p>

          <dl>
            <dt>The URL denoting this datatype</dt>
            <dd>
`https://w3id.org/security#multibase`
            </dd>
            <dt>The lexical space</dt>
            <dd>
Any string that starts with a <a href="#multibase">Multibase</a> character and
the rest of the characters consist of allowable characters in the respective
base-encoding alphabet.
            </dd>
            <dt>The value space</dt>
            <dd>
The standard mathematical concept of all integer numbers.
            </dd>
            <dt>The lexical-to-value mapping</dt>
            <dd>
Any element of the lexical space is mapped to the value space by base-decoding
the value based on the base-decoding alphabet associated with the
first <a href="#multibase">Multibase</a> character in the lexical string.
            </dd>
            <dt>The canonical mapping</dt>
            <dd>
The canonical mapping consists of using the lexical-to-value mapping.
            </dd>
          </dl>
        </section>

      </section>

    </section>

    </section>

    <section>
      <h2>Cryptographic Suites</h2>
      <p>
A data integrity proof is designed to be easy to use by developers and therefore
strives to minimize the amount of information one has to remember to generate a
proof. Often, just the [=cryptographic suite=] name (e.g.
`eddsa-rdfc-2022`) is required from developers to initiate the creation of
a proof. These [=cryptographic suite=]s are often created or reviewed by
people that have the requisite cryptographic training to ensure that safe
combinations of cryptographic primitives are used. This section specifies the
requirements for authoring cryptographic suite specifications.
      </p>

      <p>
The requirements for all data integrity cryptographic suite specifications are
as follows:
      </p>

      <ul>
        <li>
The specification MUST be published as a human-readable document at a URL.
        </li>
        <li>
The specification MUST identify a cryptographic suite `type` and any
parameters that can be used with the suite.
        </li>
        <li>
The specification MUST detail the [=transformation algorithms=] (if any),
parameters, and other necessary details, used to modify input data into the data
to be protected.
        </li>
        <li>
The specification MUST detail the [=hashing algorithms=]
parameters, and other necessary details used to perform cryptographic hashing to
the data to be protected.
        </li>
        <li>
The specification MUST detail the [=proof serialization algorithms=],
parameters, and other necessary details used to perform cryptographic protection
of the data.
        </li>
        <li>
The specification MUST detail the [=proof verification algorithms=],
parameters, and other necessary details used to perform cryptographic
verification of the data.
        </li>
        <li>
The specification MUST define a <dfn class="export"
data-lt="cryptosuite instantiation algorithm">data integrity cryptographic
suite instantiation algorithm</dfn> that accepts a set of options
([=map=] |options|) and returns a [=cryptosuite instance=]
([=struct=] |cryptosuite|). This algorithm SHOULD be listed in [[[VC-SPECS]]].
A <dfn class="export" data-local-lt="cryptosuite instance">data integrity
cryptographic suite instance</dfn> [=struct=] has the following
[=struct/items=].
          <dl data-dfn-for="cryptosuite instance">
            <dt><dfn>createProof</dfn></dt>
            <dd>
An algorithm that takes an [=unsecured data document=] ([=map=]
|unsecuredDocument|) and proof options ([=map=] |options|) as input, and
produces a [=data integrity proof=] ([=map=]) or an error.
            </dd>
            <dt><dfn>verifyProof</dfn></dt>
            <dd>
An algorithm that takes a [=secured data document=] ([=map=]
|securedDocument|) as input, and produces a <dfn>cryptosuite verification
result</dfn> or an error. The [=cryptosuite verification result=] is a
[=struct=] that contains the following [=struct/items=]:
              <dl data-dfn-for="cryptosuite verification result">
                <dt><dfn class="lint-ignore">verified</dfn></dt>
                <dd>
A [=boolean=] that is `true` if the verification succeeded, or `false`
otherwise.
                </dd>
                <dt><dfn class="lint-ignore">verifiedDocument</dfn></dt>
                <dd>
A [=map=] that represents the [=secured data document=] with the verified
proofs removed if [=cryptosuite verification result/verified=] is `true`, or
<a data-cite="INFRA#nulls">null</a> otherwise.
                </dd>
              </dl>
The structure MAY contain other implementation-specific information that is
useful for developers, such as debugging information. If an error is produced,
the verification process failed to complete. An error, such as a network error,
does not mean that a future attempt at verification would fail.
            </dd>
          </dl>
        </li>
        <li>
The specification MUST detail any known resource starvation attack that can
occur in an algorithm and provide testable mitigations against each attack.
        </li>
        <li>
The specification MUST contain a Security Considerations section detailing
security considerations specific to the cryptographic suite.
        </li>
        <li>
The specification MUST contain a Privacy Considerations section detailing
privacy considerations specific to the cryptographic suite.
        </li>
        <li>
The JSON-LD context associated with the cryptographic suite MUST have its terms
protected from unsafe redefinition, by use of the `@protected` keyword.
        </li>
      </ul>

      <p>
A [=cryptosuite instance=] is instantiated using a [=cryptosuite instantiation
algorithm=] and is made available to algorithms in an implementation-specific
manner. Implementations MAY use [[[VC-SPECS]]] [[VC-SPECS]] to discover known
[=cryptosuite instantiation algorithms=].
      </p>

      <p class="issue" title="Require interoperability report?">
The following language was deemed to be contentious: <em>The specification MUST
provide a link to an interoperability test report to document which
implementations are conformant with the cryptographic suite specification.</em>
        <br>
        <br>
The Working Group is seeking feedback on whether or not this is desired given
the important role that cryptographic suite specifications play in ensuring
data integrity.
      </p>

      <section>
        <h3>DataIntegrityProof</h3>

        <p>
A number of cryptographic suites follow the same basic pattern when expressing a
data integrity proof. This section specifies that general design pattern, a
cryptographic suite type called a `DataIntegrityProof`, which reduces the burden
of writing and implementing cryptographic suites through the reuse of design
primitives and source code.
        </p>

        <p>
When specifing a cryptographic suite that utilizes this design pattern, the
`proof` value takes the following form:
        </p>

        <dl>
          <dt>type</dt>
          <dd>
The `type` property MUST contain the string `DataIntegrityProof`.
          </dd>
          <dt>cryptosuite</dt>
          <dd>
The value of the `cryptosuite` property MUST be a string that identifies the
[=cryptographic suite=]. If the processing environment supports subtypes
of `string`, the type of the `cryptosuite` value MUST be the
`https://w3id.org/security#cryptosuiteString` subtype of `string`.
          </dd>
          <dt>proofValue</dt>
          <dd>
The `proofValue` property MUST be used, as specified in [[[#proofs]]].
          </dd>
        </dl>

        <p>
Cryptographic suite designers MUST use mandatory `proof` value properties
defined in Section [[[#proofs]]], and MAY define other properties specific to
their cryptographic suite.
        </p>

        <p class="note" title="Design Patterns of Legacy Cryptographic Suites">
One of the design patterns seen in Data Integrity cryptosuites from
2012 to 2020 was use of the `type` property to establish a specific type for a
cryptographic suite. For example, the
<a href="https://www.w3.org/TR/vc-di-eddsa/#the-ed25519signature2020-suite">
Ed25519Signature2020 cryptographic suite</a> was one such specification. This
led to a greater burden on cryptographic suite implementations, where every new
cryptographic suite required a new JSON-LD Context to be specified, resulting
in a sub-optimal developer experience. A streamlined version of this design
pattern emerged in 2020, such that a developer would only need to include a
single JSON-LD Context to support all modern cryptographic suites. This
encouraged more modern cryptosuites &mdash; such as the EdDSA Cryptosuites
[[?DI-EDDSA]] and the ECDSA Cryptosuites [[?DI-ECDSA]] &mdash; to be built
based on the streamlined pattern described in this section.
        <br><br>
To improve the developer experience, authors creating new Data Integrity
cryptographic suite specifications SHOULD use the modern pattern &mdash; where
the `type` is set to `DataIntegrityProof`; the `cryptosuite` property carries
the identifier for the cryptosuite; and any cryptosuite-specific cryptographic
data is encapsulated (i.e., not directly exposed as application layer data)
within `proofValue`. A list of cryptographic suite specifications that are
known to follow this pattern is provided in the
<a href="https://w3c.github.io/vc-specs-dir/#proof">Proof types section of
the Verifiable Credentials Specifications Directory</a>.
        </p>
      </section>

    </section>

    <section>
      <h2>Algorithms</h2>

      <p>
The algorithms defined below operate on documents represented as <dfn
data-cite="RFC8259#section-4">JSON objects</dfn>. This specification follows
[[JSON-LD-API]] in representing a JSON object as an [[Infra]] [=map=]. An
<dfn class="export">unsecured data document</dfn> is a [=map=] with no
`proof` [=map/key=]. A <dfn class="export">secured data document</dfn> is a
[=map=] with a `proof` [=map/key=].
      </p>

      <p class="issue" title="Verification hash algorithm definition">
At present the creation of the verification hash is delegated to the
cryptographic suite specification when generating and verifying a proof. It is
expected that this algorithm is going to be common to most cryptographic suites.
It is predicted that the algorithm that generates the verification hash
will eventually be defined in this specification.
      </p>

      <section class="normative">
        <h2>Base Encode</h2>

        <p>
The following algorithm specifies how to encode an array of bytes, where each
byte represents a base-256 value, to a different base representation that uses a
particular base alphabet, such as base-64-url-no-pad or base-58-btc. The
required inputs are the |bytes|, |targetBase|, and
|baseAlphabet|. The output is a string that contains the base-encoded
value. All mathematical operations MUST be performed using integer arithmetic.
Alternatives to the algorithm provided below MAY be used as long as the
outputs of the alternative algorithm remain the same.
        </p>

        <ol class="algorithm">
          <li>
Initialize the following variables; |zeroes| to `0`, |length| to
`0`, |begin| to `0`, and |end| to the length of
|bytes|.
          </li>
          <li>
Set |begin| and |zeroes| to the number of leading `0` byte
values in |bytes|.
          </li>
          <li>
Set |baseValue| to an empty byte array that is the size of the final
base-expanded value. Calculate the final |size| of |baseValue|
by dividing log(256) by log(|targetBase|) and then multiplying the
length of |bytes| minus the leading |zeroes|. Add `1` to the
value of |size|.
          </li>
          <li>
Process each byte in |bytes| as |byte| starting at offset
|begin|:
            <ol class="algorithm">
              <li>
Set the |carry| value to |byte|.
              </li>
              <li>
Perform base-expansion by starting at the end of the |baseValue| array.
Initialize an iterator |i| to `0`. Set |basePosition| to
|size| minus `1`. Perform the following loop as long as |carry|
does not equal `0` or |i| is less than |length|, and
|basePosition| does not equal `-1`.
                <ol class="algorithm">
                  <li>
Multiply the value in |baseValue[basePosition]| by `256` and add
it to |carry|.
                  </li>
                  <li>
Set the value at |baseValue[basePosition]| to the remainder after
dividing |carry| by |targetBase|.
                  </li>
                  <li>
Set the value of |carry| to |carry| divided by
|targetBase| ensuring that integer division is used to perform the
division.
                  </li>
                  <li>
Decrement |basePosition| by `1` and increment |i| by `1`.
                  </li>
                </ol>
              </li>
              <li>
Set |length| to |i| and increment |begin| by `1`.
              </li>
            </ol>
          </li>
          <li>
Set the |baseEncodingPosition| to |size| minus |length|.
While the |baseEncodingPosition| does not equal |size| and the
|baseValue[baseEncodingPosition]| does not equal `0`, increment
|baseEncodingPosition|. This step skips the leading zeros in the
base-encoded result.
          </li>
          <li>
Initialize the |baseEncoding| by repeating the first entry in the
|baseAlphabet| by the value of |zeroes| (the number of leading
zeroes in |bytes|).
          </li>
          <li>
Convert the rest of the |baseValue| to the base-encoding. While the
|baseEncodingPosition| is less than |size|, increment the
|baseEncodingPosition|: Set |baseEncodedValue| to
|baseValue|[|baseEncodingPosition|]. Append
|baseAlphabet|[|baseEncodedValue|] to |baseEncoding|.
          </li>
          <li>
Return |baseEncoding| as the base-encoded value.
          </li>
        </ol>

        <pre class="example" title="An implementation of the general base-encoding algorithm above in Javascript">
/**
* @param {Uint8Array} bytes 
* @param {number} targetBase 
* @param {string} baseAlphabet 
* @returns string
*/
function baseEncode(bytes, targetBase, baseAlphabet) {
  let zeroes = 0;
  let length = 0;
  let begin = 0;
  let end = bytes.length;

  // count the number of leading bytes that are zero
  while(begin !== end && bytes[begin] === 0) {
    begin++;
    zeroes++;
  }

  // allocate enough space to store the target base value
  const baseExpansionFactor = Math.log(256) / Math.log(targetBase);
  let size = Math.floor((end - begin) * baseExpansionFactor + 1);
  let baseValue = new Uint8Array(size);

  // process the entire input byte array
  while(begin !== end) {
    let carry = bytes[begin];

    // for each byte in the array, perform base-expansion
    let i = 0;
    for(let basePosition = size - 1;
        (carry !== 0 || i < length) && (basePosition !== -1);
        basePosition--, i++) {
      carry += Math.floor(256 * baseValue[basePosition]);
      baseValue[basePosition] = Math.floor(carry % targetBase);
      carry = Math.floor(carry / targetBase);
    }

    length = i;
    begin++;
  }

  // skip leading zeroes in base-encoded result
  let baseEncodingPosition = size - length;
  while(baseEncodingPosition !== size &&
        baseValue[baseEncodingPosition] === 0) {
    baseEncodingPosition++;
  }

  // convert the base value to the base encoding
  let baseEncoding = baseAlphabet.charAt(0).repeat(zeroes)
  for(; baseEncodingPosition < size; ++baseEncodingPosition) {
    baseEncoding += baseAlphabet.charAt(baseValue[baseEncodingPosition])
  }

  return baseEncoding;
}
        </pre>
      </section>

      <section class="normative">
        <h2>Base Decode</h2>

        <p>
The following algorithm specifies how to decode an array of bytes, where each
byte represents a base-encoded value, to a different base representation that
uses a particular base alphabet, such as base-64-url-no-pad or base-58-btc. The
required inputs are the |sourceEncoding|, |sourceBase|, and
|baseAlphabet|. The output is an array of bytes that contains the
base-decoded value. All mathematical operations MUST be performed using integer
arithmetic. Alternatives to the algorithm provided below MAY be used as long as
the outputs of the alternative algorithm remain the same.
        </p>

        <ol class="algorithm">
          <li>
Initialize a |baseMap| mapping by associating each character
in |baseAlphabet| to its integer position in the
|baseAlphabet| string.
          </li>
          <li>
Initialize the following variables; |sourceOffset| to `0`,
|zeroes| to `0`, and |decodedLength| to `0`.
          </li>
          <li>
Set |zeroes| and |sourceOffset| to the number of leading
|baseAlphabet[0]| values in |sourceEncoding|.
          </li>
          <li>
Set |decodedBytes| to an empty byte array that is the size of the final
base-converted value. Calculate the size of |decodedBytes|
by dividing log(|sourceBase|) by log(`256`) and then multiplying by the
length of |sourceEncoding| minus the leading zeroes. Add 1 to the value
of size.
          </li>
          <li>
Process each character in |sourceEncoding| as |character|
starting at offset |sourceOffset|:
            <ol class="algorithm">
              <li>
Set the |carry| value to the integer value in the |baseMap|
that is associated with |character|.
              </li>
              <li>
Perform base-decoding by starting at the end of the |decodedBytes|
array. Initialize an iterator |i| to `0`. Set |byteOffset|
to |decodedSize| minus `1`. Perform the following loop as long as,
|carry| does not equal `0` or |i| is less than
|decodedLength|, and |byteOffset| does not equal `-1`:
                <ol class="algorithm">
                  <li>
Add the result of multiplying |sourceBase| by
|decodedBytes|[|byteOffset|] to |carry|.
                  </li>
                  <li>
Set |decodedBytes|[|byteOffset|] to the remainder of
dividing |carry| by `256`.
                  </li>
                  <li>
Set |carry| to |carry| divided by `256`, ensuring that integer
division is used to perform the division.
                  </li>
                  <li>
Decrement |byteOffset| by `1` and increment |i| by `1`.
                  </li>
                </ol>
                <li>
Set |decodedLength| to |i| and increment
|sourceOffset| by `1`.
                </li>
              </li>
            </ol>
          </li>
          <li>
Set the |decodedOffset| to |decodedSize| minus
|decodedLength|. While the |decodedOffset| does not equal
the |decodedSize| and
|decodedBytes|[|decodedOffset|] equals `0`, increment
|decodedOffset| by `1`. This step skips the leading zeros in the
final base-decoded byte array.
          </li>
          <li>
Set the size of the |finalBytes| array to |zeroes| plus,
|decodedSize| minus |decodedOffset|. Initialize the first
|zeroes| bytes in |finalBytes| to `0`.
          </li>
          <li>
Starting at an offset equal to the number of |zeroes| in
|finalBytes| plus `1`, copy all bytes in |decodedBytes|, up
to |decodedSize|, starting at offset |decodedOffset| to
|finalBytes|.
          </li>
        </ol>

        <pre class="example" title="An implementation of the general base-decoding algorithm above in Javascript">
/**
* @param {string} sourceEncoding
* @param {number} sourceBase 
* @param {string} baseAlphabet 
* @returns Uint8Array
*/
function baseDecode(sourceEncoding, sourceBase, baseAlphabet) {
  // build the base-alphabet to integer value map
  baseMap = {};
  for(let i = 0; i < baseAlphabet.length; i++) {
    baseMap[baseAlphabet[i]] = i;
  }

  // skip and count zero-byte values in the sourceEncoding
  let sourceOffset = 0;
  let zeroes = 0;
  let decodedLength = 0;
  while(sourceEncoding[sourceOffset] === baseAlphabet[0]) {
    zeroes++;
    sourceOffset++;
  }

  // allocate the decoded byte array
  const baseContractionFactor = Math.log(sourceBase) / Math.log(256);
  let decodedSize = Math.floor((
    (sourceEncoding.length - sourceOffset) * baseContractionFactor) + 1);
  let decodedBytes = new Uint8Array(decodedSize);

  // perform base-conversion on the source encoding
  while(sourceEncoding[sourceOffset]) {
    // process each base-encoded number
    let carry = baseMap[sourceEncoding[sourceOffset]];

    // convert the base-encoded number by performing base-expansion
    let i = 0
    for(let byteOffset = decodedSize - 1;
      (carry !== 0 || i < decodedLength) && (byteOffset !== -1);
      byteOffset--, i++) {
      carry += Math.floor(sourceBase * decodedBytes[byteOffset]);
      decodedBytes[byteOffset] = Math.floor(carry % 256);
      carry = Math.floor(carry / 256);
    }

    decodedLength = i;
    sourceOffset++;
  }

  // skip leading zeros in the decoded byte array
  let decodedOffset = decodedSize - decodedLength;
  while(decodedOffset !== decodedSize && decodedBytes[decodedOffset] === 0) {
    decodedOffset++;
  }

  // create the final byte array that has been base-decoded
  let finalBytes = new Uint8Array(zeroes + (decodedSize - decodedOffset));
  let j = zeroes;
  while(decodedOffset !== decodedSize) {
    finalBytes[j++] = decodedBytes[decodedOffset++];
  }

  return finalBytes;
}
        </pre>

      </section>

      <section class="normative">
        <h3>Add Proof</h3>

        <p>
The following algorithm specifies how a digital proof can be added to an
[=unsecured data document=], and can then be used to verify the output
document's authenticity and integrity. Required inputs are an <a>unsecured data
document</a> ([=map=] |unsecuredDocument|), a [=cryptosuite instance=]
([=struct=] |cryptosuite|), and a set of options ([=map=] |options|). Output is
a [=secured data document=] ([=map=]) or an error. Whenever this algorithm
encodes strings, it MUST use UTF-8 encoding.
        </p>

        <ol class="algorithm">
          <li>
Let |proof| be the result of calling the [=cryptosuite instance/createProof=]
algorithm specified in |cryptosuite|.|createProof| with |unsecuredDocument|
and |options| passed as a parameters. If the algorithm produces an error,
the error MUST be propagated and SHOULD convey the error type.
          </li>
          <li>
If one or more of the |proof|.|type|, |proof|.|verificationMethod|, and
|proof|.|proofPurpose| values is not set, an error MUST be raised and SHOULD
convey an error type of
<a href="#PROOF_GENERATION_ERROR">PROOF_GENERATION_ERROR</a>.
          </li>
          <li>
If |options| has a non-null |domain| [=struct/item=], it MUST be equal to
|proof|.|domain| or an error MUST be raised and SHOULD convey
an error type of <a href="#PROOF_GENERATION_ERROR">PROOF_GENERATION_ERROR</a>.
          </li>
          <li>
If |options| has a non-null |challenge| [=struct/item=], it MUST be equal to
|proof|.|challenge| or an error MUST be raised and SHOULD
convey an error type of
<a href="#PROOF_GENERATION_ERROR">PROOF_GENERATION_ERROR</a>.
          </li>
          <li>
Let |securedDataDocument| be a copy of |unsecuredDocument|.
          </li>
          <li>
Set |securedDataDocument|.|proof| to the value of |proof|.
          </li>
          <li>
Return |securedDataDocument| as the [=secured data document=].
          </li>
        </ol>

      </section>
      <section>
        <h3>Add Proof Set/Chain</h3>
        <p>
The following algorithm specifies how to incrementally add a proof to a proof
set or proof chain starting with a secured document containing either a proof or
proof set/chain. Required inputs are a [=secured data document=]
([=map=] |securedDocument|), a [=cryptographic suite=]
(|suite:cryptosuite instance|), and a set of options ([=map=] |options|). Output
is a new [=secured data document=] ([=map=]). Whenever this algorithm
encodes strings, it MUST use UTF-8 encoding.
        </p>

        <ol class="algorithm">
          <li>
Let |proof| be set to |securedDocument|.|proof|. Let
|allProofs| be an empty list. If |proof| is a list, copy all
the elements of |proof| to |allProofs|. If |proof|
is an object add a copy of that object to |allProofs|.
          </li>
          <li>
Let the |unsecuredDocument| be a copy of the |securedDocument|
with the |proof| attribute removed. Let |output| be a copy of
the |unsecuredDocument|.
          </li>
          <li>
Let |matchingProofs| be an empty list.
          </li>
          <li>
If |options| has a `previousProof` [=struct/item=] that is a string, add the
element from |allProofs| with an `id` attribute matching `previousProof` to
|matchingProofs|. If a proof with `id` equal to `previousProof`does not exist in
|allProofs|, an error MUST be raised and SHOULD convey an error type of
<a href="#PROOF_GENERATION_ERROR">PROOF_GENERATION_ERROR</a>.
          </li>
          <li>
If |options| has a `previousProof` [=struct/item=] that is an array, add each
element from |allProofs| with an `id` attribute that matches an element of that
array. If any element of `previousProof` array has an `id` attribute that does
not match the `id` attribute of any element of |allProofs|, an error MUST be
raised and SHOULD convey an error type of
<a href="#PROOF_GENERATION_ERROR">PROOF_GENERATION_ERROR</a>.
          </li>
          <li>
Set |unsecuredDocument.proof| to |matchingProofs|.
            <p class="note">
This step is critical, as it <q>binds</q> the previous proofs to the document
prior to signing. The |proof| value for the document will be updated
in a later step of this algorithm.
            </p>
          </li>
          <li>
Run steps 1 through 6 of the algorithm in section [[[#add-proof]]], passing
|unsecuredDocument|, |suite|, and |options|. If no exceptions are raised, append
the generated |proof| value to the |allProofs|; otherwise, raise the exception.
          </li>
          <li>
Set |output|.|proof| to the value of |allProofs|.
          </li>
          <li>
Return |output| as the new [=secured data document=].
          </li>
        </ol>
      </section>

      <section>
        <h3>Verify Proof</h3>

        <p>
The following algorithm specifies how to check the authenticity and integrity of
a [=secured data document=] by verifying its digital proof. The algorithm
takes as input:
        </p>

        <dl>
          <dt>|mediaType|</dt>
          <dd>
A [=MIME type|media type=]
          </dd>
          <dt>|documentBytes|</dt>
          <dd>
A [=byte sequence=] whose media type is |mediaType|
          </dd>
          <dt>|cryptosuite|</dt>
          <dd>
A [=cryptosuite instance=]
          </dd>
          <dt>|expectedProofPurpose|</dt>
          <dd>
An optional [=string=], used to ensure that the |proof| was generated by the
proof creator for the expected reason by the verifier. See [[[#proof-purposes]]]
for common values
          <dt>|domain|</dt>
          <dd>
An optional [=set=] of [=strings=], used by the proof creator to lock a proof to
a particular security domain, and used by the verifier to ensure that a proof is
not being used across different security domains
          </dd>
          <dt>|challenge|</dt>
          <dd>
An optional [=string=] [=challenge=], used by the verifier to ensure that an
attacker is not replaying previously created proofs
          </dd>
        </dl>

        <p>
This algorithm returns a <dfn>verification result</dfn>, a [=struct=] whose
[=struct/items=] are:
        </p>
        <dl data-dfn-for="verification result">
          <dt><dfn data-dfn-for="verification result">verified</dfn></dt>
          <dd>`true` or `false`</dd>
          <dt><dfn data-dfn-for="verification result">verifiedDocument</dfn></dt>
          <dd>
<a data-cite="INFRA#nulls">Null</a>, if [=verification result/verified=] is
`false`; otherwise, an [=unsecured data document=]
          </dd>
          <dt><dfn data-dfn-for="verification result">media type</dfn></dt>
          <dd>
<a data-cite="INFRA#nulls">Null</a>, if [=verification result/verified=] is
`false`; otherwise, a [=MIME type|media type=], which MAY include [=MIME
type/parameters=]
          </dd>
          <dt><dfn data-dfn-for="verification result" class="lint-ignore">warnings</dfn></dt>
          <dd>
a [=list=] of
<dfn data-cite="VC-DATA-MODEL-2.0#dfn-problemdetails">ProblemDetails</dfn>,
which defaults to an empty [=list=]</dd>
          <dt><dfn data-dfn-for="verification result">errors</dfn></dt>
          <dd>
a [=list=] of [=ProblemDetails=], which defaults to an empty [=list=]</dd>
        </dl>

        <p>
When a step says "an error MUST be raised", it means that a [=verification
result=] MUST be returned with a [=verification result/verified=] of `false`
and a non-empty [=verification result/errors=] list.
        </p>

        <ol class="algorithm">
          <li>
Let |securedDocument:map| be the result of running [=parse JSON bytes to an
Infra value=] on |documentBytes|.
          </li>
          <li>
If either |securedDocument| is not a [=map=] or |securedDocument|.|proof|
is not a [=map=], an error MUST be raised and SHOULD convey an error type of
<a href="https://www.w3.org/TR/VC-DATA-MODEL-2.0#PARSING_ERROR">
PARSING_ERROR</a>.
          </li>
          <li>
Let |proof:map| be |securedDocument|.|proof|.
          </li>
          <li>
If one or more of |proof|.|type|,
|proof|.|verificationMethod|, and
|proof|.|proofPurpose| does not [=map/exist=],
an error MUST be raised and SHOULD convey an error type of
<a href="#MALFORMED_PROOF_ERROR">MALFORMED_PROOF_ERROR</a>.
          </li>
          <li>
If |expectedProofPurpose| was given, and it does not match
|proof|.|proofPurpose|,
an error MUST be raised and SHOULD convey an error type of
<a href="#MISMATCHED_PROOF_PURPOSE_ERROR">MISMATCHED_PROOF_PURPOSE_ERROR</a>.
          </li>
          <li>
If |domain| was given, and it does not contain the same [=strings=] as
|proof|.|domain| (treating a single [=string=] as a [=set=] containing just
that [=string=]), an error MUST be raised and SHOULD convey an error type of <a
href="#INVALID_DOMAIN_ERROR">INVALID_DOMAIN_ERROR</a>.
          </li>
          <li>
If |challenge| was given, and it does not match
|proof|.|challenge|, an error MUST be raised and SHOULD
convey an error type of
<a href="#INVALID_CHALLENGE_ERROR">INVALID_CHALLENGE_ERROR</a>.
          </li>
          <li>
Let |cryptosuiteVerificationResult| be the result of running the
|cryptosuite|.[=cryptosuite instance/verifyProof=] algorithm with
|securedDocument| provided as input.
          </li>
          <li>
Return a [=verification result=] with [=struct/items=]:
            <dl data-link-for="verification result">
              <dt>[=verified=]</dt>
              <dd>|cryptosuiteVerificationResult|.|verified|</dd>
              <dt>[=verifiedDocument=]</dt>
              <dd>|cryptosuiteVerificationResult|.|verifiedDocument|</dd>
              <dt>[=media type=]</dt>
              <dd>|mediaType|</dd>
            </dl>
          </li>
        </ol>

      </section>
      <section>
        <h3>Verify Proof Sets and Chains</h3>
        <p>
In a proof set or proof chain, a [=secured data document=] has a
`proof` attribute which contains a list of proofs
(|allProofs|).
The following algorithm provides one method of checking the authenticity and
integrity of a [=secured data document=], achieved by verifying every
proof in |allProofs|. Other approaches are possible, particularly if
it is only desired to verify a subset of the proofs contained in
|allProofs|. If another approach is taken to verify only a subset of the
proofs, then it is important to note that any proof in that subset with a
`previousProof` can only be considered verified if the proofs it
references are also considered verified.
        </p>
        <p>
Required input is a
[=secured data document=] (|securedDocument|). A list of
[=verification result=]s corresponding to each proof in |allProofs| is
generated, and a single boolean result is returned as output.
        </p>
        <ol class="algorithm">
          <li>
Set |allProofs| to </var>|securedDocument|.|proof|.
          </li>
          <li>
Set |verificationResults| to an empty list.
          </li>
          <li>
For each |proof| in |allProofs|, do the following steps:
            <ol class="algorithm">
              <li>
Let |matchingProofs| be an empty list.
              </li>
              <li>
If |proof| contains a `previousProof` attribute and that attribute is a string,
add the element from |allProofs| with an `id` attribute matching `previousProof`
to `matchingProofs`. If a proof with `id` does not exist in |allProofs|, an
error MUST be raised and SHOULD convey an error type of
<a href="#MALFORMED_PROOF_ERROR">MALFORMED_PROOF_ERROR</a>. If the
`previousProof` attribute is an array, add each element from |allProofs| with an
`id` attribute that matches an element of that array. If any element of
`previousProof` array has an `id` attribute that does not match the `id`
attribute of any element of |allProofs|, an error MUST be raised and SHOULD
convey an error type of
<a href="#MALFORMED_PROOF_ERROR">MALFORMED_PROOF_ERROR</a>.
              </li>
              <li>
Let |unsecuredDocument| be a copy of |securedDocument| with the proof value
removed and then set |unsecuredDocument|.|proof| to |matchingProofs|.
              </li>
              <li>
Run steps 4 through 8 of the algorithm in section [[[#verify-proof]]] on
|unsecuredDocument|; if no exceptions are raised, add |cryptosuiteVerificationResult|
to |verificationResults|.
                </li>
            </ol>
          </li>
          <li>
Let |combinedVerificationResult| be `true`.
          </li>
          <li>
For each |cryptosuiteVerificationResult| in |verificationResults|:
            <ol class="algorithm">
              <li>
If |cryptosuiteVerificationResult|.|verified| is `false`, set |combinedVerificationResult|
to `false`.
              </li>
            </ol>
          </li>
          <li>
Return |combinedVerificationResult|.
          </li>
        </ol>
      </section>

      <section class="normative">
        <h3>Retrieve Verification Method</h3>

        <p>
The following algorithm specifies how to safely retrieve a verification method,
such as a cryptographic [=public key=], by using a [=verification method=]
identifier contained in a [=data integrity proof=]. Required inputs are a
<strong>[=data integrity proof=]</strong> (|proof|) and a set of
<strong>dereferencing options</strong> (|options|). A
<strong>verification method</strong> is produced as output.
        </p>

        <ol class="algorithm">
          <li>
Let |vmIdentifier| be set to
|proof|.|verificationMethod|.
          </li>
          <li>
Let |vmPurpose| be set to |proof|.|proofPurpose|.
          </li>
          <li>
If |vmIdentifier| is not a valid URL, an error MUST be raised and SHOULD
convey an error type of
<a href="#INVALID_VERIFICATION_METHOD_URL">INVALID_VERIFICATION_METHOD_URL</a>.
          </li>
          <li>
Let |controllerDocumentUrl| be the result of parsing
|vmIdentifier| according to the rules of the URL scheme and extracting
the primary resource identifier (without the fragment identifier).
          </li>
          <li>
Let |vmFragment| be the result of parsing |vmIdentifier|
according to the rules of the URL scheme and extracting the secondary
resource identifier (the fragment identifier).
          </li>
          <li>
Let |controllerDocument| be the result of dereferencing
|controllerDocumentUrl|, according to the rules
of the URL scheme and using the supplied |options|.
          </li>
          <li>
If |controllerDocument|.|id| does not match the
|controllerDocumentUrl|, an error MUST be raised and SHOULD
convey an error type of
<a href="#INVALID_CONTROLLER_DOCUMENT_ID">INVALID_CONTROLLER_DOCUMENT_ID</a>.
          </li>
          <li>
If |controllerDocument| is not a valid [=controller document=],
an error MUST be raised and SHOULD
convey an error type of
<a href="#INVALID_CONTROLLER_DOCUMENT">INVALID_CONTROLLER_DOCUMENT</a>.
          </li>
          <li>
Let |verificationMethod| be the result of dereferencing the
|vmFragment| from the |controllerDocument| according to the
rules of the media type of the |controllerDocument|.
          </li>
          <li>
If |verificationMethod| is not a valid [=verification method=],
an error MUST be raised and SHOULD convey an error type of
<a href="#INVALID_VERIFICATION_METHOD">INVALID_VERIFICATION_METHOD</a>.
          </li>
          <li>
If |verificationMethod| is not associated with the array of
|vmPurposes| in the |controllerDocument|, either by reference
(URL) or by value (object), an error MUST be raised and SHOULD convey an error
type of <a href="#INVALID_PROOF_PURPOSE_FOR_VERIFICATION_METHOD">
INVALID_PROOF_PURPOSE_FOR_VERIFICATION_METHOD</a>.
          </li>
          <li>
Return |verificationMethod| as the
<strong>verification method</strong>.
          </li>
        </ol>

        <p>
The following example provides a minimum conformant
[=controller document=] containing a minimum conformant
[=verification method=] as required by the algorithm in this section:
        </p>

        <pre class="example" title="Minimum conformant controller document">
{
  "id": "https://controller.example/123",
  "verificationMethod": [{
    "id": "https://controller.example/123#key-456",
    "type": "ExampleVerificationMethodType",
    "controller": "https://controller.example/123",
    <span class="comment">// public cryptographic material goes here</span>
  }],
  "authentication": ["#key-456"]
}
        </pre>

      </section>

      <section class="normative">
        <h3>Processing Errors</h3>

        <p>
The algorithms described in this specification, as well as in various cryptographic
suite specifications, throw specific types of errors. Implementers might find
it useful to convey these errors to other libraries or software systems. This
section provides specific URLs, descriptions, and error codes for the errors,
such that an ecosystem implementing technologies described by this
specification might interoperate more effectively when errors occur.
        </p>

        <p>
When exposing these errors through an HTTP interface, implementers SHOULD use
[[RFC9457]] to encode the error data structure. If [[RFC9457]] is used:
        </p>

        <ul>
          <li>
The `type` value of the error object MUST be a URL that starts with the value
`https://w3id.org/security#` and ends with the value in the section listed
below.
          </li>
          <li>
The `code` value MUST be the integer code described in the table below
(in parentheses, beside the type name).
          </li>
          <li>
The `title` value SHOULD provide a short but specific human-readable string for
the error.
          </li>
          <li>
The `detail` value SHOULD provide a longer human-readable string for the error.
          </li>
        </ul>

        <dl>
          <dt id="PROOF_GENERATION_ERROR">PROOF_GENERATION_ERROR (-16)</dt>
          <dd>
A request to generate a proof failed. See Section [[[#add-proof]]], and Section
[[[#add-proof-set-chain]]].
          </dd>
          <dt id="MALFORMED_PROOF_ERROR">MALFORMED_PROOF_ERROR (-17)</dt>
          <dd>
A proof that is malformed was detected. See Section [[[#verify-proof]]].
          </dd>
          <dt id="MISMATCHED_PROOF_PURPOSE_ERROR">MISMATCHED_PROOF_PURPOSE_ERROR (-18)</dt>
          <dd>
The `proofPurpose` value in a proof did not match the expected value. See
Section [[[#verify-proof]]].
          </dd>
          <dt id="INVALID_DOMAIN_ERROR">INVALID_DOMAIN_ERROR (-19)</dt>
          <dd>
The `domain` value in a proof did not match the expected value. See Section
[[[#verify-proof]]].
          </dd>
          <dt id="INVALID_CHALLENGE_ERROR">INVALID_CHALLENGE_ERROR (-20)</dt>
          <dd>
The `challenge` value in a proof did not match the expected value. See Section
[[[#verify-proof]]].
          </dd>
          <dt id="INVALID_VERIFICATION_METHOD_URL">INVALID_VERIFICATION_METHOD_URL (-21)</dt>
          <dd>
The `verificationMethod` value in a proof was malformed. See Section
[[[#retrieve-verification-method]]].
          </dd>
          <dt id="INVALID_CONTROLLER_DOCUMENT_ID">INVALID_CONTROLLER_DOCUMENT_ID (-22)</dt>
          <dd>
The `id` value in a [=controller document=] was malformed. See Section
[[[#retrieve-verification-method]]].
          </dd>
          <dt id="INVALID_CONTROLLER_DOCUMENT">INVALID_CONTROLLER_DOCUMENT (-23)</dt>
          <dd>
The [=controller document=] was malformed. See Section
[[[#retrieve-verification-method]]].
          </dd>
          <dt id="INVALID_VERIFICATION_METHOD">INVALID_VERIFICATION_METHOD (-24)</dt>
          <dd>
The [=verification method=] in a [=controller document=] was malformed.
See Section [[[#retrieve-verification-method]]].
          </dd>
          <dt id="INVALID_PROOF_PURPOSE_FOR_VERIFICATION_METHOD">INVALID_PROOF_PURPOSE_FOR_VERIFICATION_METHOD (-25)</dt>
          <dd>
The [=verification method=] in a [=controller document=] was not
associated using the expected [=verification relationship=] as expressed in
the `proofPurpose` property in the proof. See Section
[[[#retrieve-verification-method]]].
          </dd>
        </dl>
      </section>
    </section>

    <section>
      <h2>Security Considerations</h2>
      <p>
The following section describes security considerations that developers
implementing this specification should be aware of in order to create secure
software.
      </p>

      <section>
        <h3>Versioning Cryptography Suites</h3>

        <p>
Cryptography secures information through the use of secrets. Knowledge of the
necessary secret makes it computationally easy to access certain information. The
same information can be accessed if a computationally-difficult, brute-force effort
successfully guesses the secret. All modern cryptography requires the
computationally difficult approach to remain difficult throughout time, which
does not always hold due to breakthroughs in science and mathematics. That is
to say that <em>Cryptography has a shelf life</em>.
        </p>
        <p>
This specification plans for the obsolescence of all cryptographic approaches by
asserting that whatever cryptography is in use today is highly likely to be
broken over time. Software systems have to be able to change the cryptography
in use over time in order to continue to secure information. Such changes might
involve increasing required secret sizes or modifications to the cryptographic
primitives used. However, some combinations of cryptographic parameters
might actually reduce security. Given these assumptions, systems need to be able to
distinguish different combinations of safe cryptographic parameters, also known
as cryptographic suites, from one another. When identifying or versioning
cryptographic suites, there are several approaches that can be taken which
include: parameters, numbers, and dates.
        </p>
        <p>
Parametric versioning specifies the particular cryptographic parameters that are
employed in a cryptographic suite. For example, one could use an identifier such
as `RSASSA-PKCS1-v1_5-SHA1`. The benefit to this scheme is that a well-trained
cryptographer will be able to determine all of the parameters in play by the
identifier. The drawback to this scheme is that most of the population that
uses these sorts of identifiers are not well trained and thus will not understand
that the previously mentioned identifier is a cryptographic suite that is no
longer safe to use. Additionally, this lack of knowledge might lead software
developers to generalize the parsing of cryptographic suite identifiers
such that any combination of cryptographic primitives becomes acceptable,
resulting in reduced security. Ideally, cryptographic suites are implemented
in software as specific, acceptable profiles of cryptographic parameters instead.
        </p>
        <p>
Numbered versioning might specify a major and minor version number such as
`1.0` or `2.1`. Numbered versioning conveys a specific order and suggests that
higher version numbers are more capable than lower version numbers. The benefit
of this approach is that it removes complex parameters that less expert
developers might not understand with a simpler model that conveys that an
upgrade might be appropriate. The drawback of this approach is that its not
clear if an upgrade is necessary, as software version number increases often
don't require an upgrade for the software to continue functioning. This can
lead to developers thinking their usage of a particular version is safe, when
it is not. Ideally, additional signals would be given to developers that use
cryptographic suites in their software that periodic reviews of those
suites for continued security are required.
        </p>
        <p>
Date-based versioning specifies a particular release date for a specific
cryptographic suite. The benefit of a date, such as a year, is that it is
immediately clear to a developer if the date is relatively old or new. Seeing
an old date might prompt the developer to go searching for a newer
cryptographic suite, where as a parametric or number-based versioning scheme
might not. The downside of a date-based version is that some cryptographic
suites might not expire for 5-10 years, prompting the developer to go
searching for a newer cryptographic suite only to not find one that is newer.
While this might be an inconvenience, it is one that results in safer
ecosystem behavior.
        </p>
        <p class="issue" data-number="38">
The following text is currently under debate:<br><br>
It is highly encouraged that cryptographic suite identifiers are versioned
using a year designation. For example, the cryptographic suite identifier
`ecdsa-2022` implies that the suite is probably an acceptable of ECDSA in the
year 2025, but might not be a safe choice in the year 2042. A date-based
versioning mechanism, however, is not enough by itself. All cryptographic
suites that follow this specification are intended to be registered
[[?VC-SPECS]] in a way that clearly signal which cryptosuites
are deprecated, standardized, or experimental. Cryptosuite registration will
follow CFRG, IETF, NIST, FIPS, and safecurves guidance. Use of deprecated suites
are expected to throw errors in implementations unless a `useUnsafeCryptosuites`
option is used specifying exactly the unsafe cryptosuite to use.
Use of experimental suites are expected to throw errors in implementations
unless a `useExperimentalCryptosuites` option is used specifying exactly
the experimental cryptosuite to use.
        </p>

      </section>

      <section>
        <h3>Protecting Application Developers</h3>

        <p>
Modern cryptographic algorithms provide a number of tunable parameters and
options to ensure that the algorithms can meet the varied requirements of different use cases.
For example, embedded systems have limited processing and memory environments
and might not have the resources to generate the strongest digital signatures
for a given algorithm. Other environments, like financial trading systems,
might only need to protect data for a day while the trade is occurring, while
other environments might need to protect data for multiple decades. To meet
these needs, cryptographic algorithm designers often provide multiple ways to
configure a cryptographic algorithm.
        </p>
        <p>
Cryptographic library implementers often take the specifications created by
cryptographic algorithm designers and specification authors and implement them
such that all options are available to the application developers that use their
libraries. This can be due to not knowing which combination of features a
particular application developer might need for a given cryptographic deployment.
All options are often exposed to application developers.
        </p>
        <p>
Application developers that use cryptographic libraries often do not have the
requisite cryptographic expertise and knowledge necessary to appropriately
select cryptographic parameters and options for a given application. This lack
of expertise can lead to an inappropriate selection of cryptographic parameters
and options for a particular application.
        </p>
        <p>
This specification sets the priority of constituencies to protect application
developers over cryptographic library implementers over cryptographic
specification authors over cryptographic algorithm designers. Given these
priorities, the following recommendations are made:
        </p>
        <ul>
          <li>
Cryptographic algorithm designers are advised [[?RFC7696]] to minimize the
number of options and parameters to as few as possible to ensure that
cryptographic library implementers have a more easily auditable security attack
surface for their software libraries.
          </li>
          <li>
Cryptographic specification authors are advised to, if possible, further
minimize the number of options and parameters to as few as possible to ensure
cryptographic agility while also keeping the auditable security
attack surface for downstream software libraries to a minimum.
          </li>
          <li>
Cryptographic library implementers are advised to, if possible, provide known
good combinations of options and parameters to application developers. There
would ideally be two pre-set default configurations for any algorithmic
class, such as Elliptic Curve Digital Signatures, with no ability
to fine tune parameters and options when using these pre-sets. Library options can be provided to
experts to fine tune their use of the library, use of those options by the general
application developer population is to be discouraged.
          </li>
          <li>
Application developers are advised to choose from a number of pre-set
cryptography library configurations and to avoid modifying cryptographic
options and parameters, or using experimental or deprecated cryptography.
          </li>
        </ul>

        <p>
The guidance above is meant to ensure that useful cryptographic options and
parameters are provided at the lower layers of the architecture while not
exposing those options and parameters to application developers who may not
fully understand the balancing benefits and drawbacks of each option.
        </p>

        <p class="issue"
          title="Use of experimental and deprecated cryptography">
The VCWG is seeking guidance on adding language to allow the use of experimental
or deprecated cryptography. By default, those features will be disabled and will
require the application developer to specifically allow use on a per-cryptographic suite
basis. There will be requirements for all implementing libraries to throw errors
or warnings when deprecated or experimental options are selected without the
appropriate override flags.
        </p>
      </section>

      <section>
        <h3>Conventions for Naming Cryptography Suites</h3>
        <p>
Section [[[#versioning-cryptography-suites]]] emphasized the importance of
providing relatively easy to understand information concerning the timeliness of
particular cryptographic suite, while section
[[[#protecting-application-developers]]] further emphasized minimizing the
number of options to be specified. Indeed, section [[[#cryptographic-suites]]]
lists requirements for cryptographic suites which include detailed specification
of algorithm, transformation, hashing, and serialization. Hence, the name of the
cryptographic suite does not need to include all this detail, which implies the
<em>parametric versioning</em> mentioned in section
[[[#versioning-cryptography-suites]]] is neither necessary nor desirable.
        </p>
        <p>
The recommended naming convention for cryptographic suites is a
string composed of a signature algorithm identifier, separated by a hyphen from
an option identifier (if the cryptosuite supports incompatible
implementation options), followed by a hyphen and designation of the
approximate year that the suite was proposed.
        </p>
        <p>
For example, the [[?DI-EDDSA]] is based on EdDSA digital signatures, supports
two incompatible options based on canonicalization approaches, and was proposed
in roughly the year 2022, so it would have two different cryptosuite names:
<q>eddsa-rdfc-2022</q> and <q>eddsa-jcs-2022</q>.
        </p>
        <p>
Although the [[?DI-ECDSA]] is based on ECDSA digital signatures, supports the
same two incompatible canonicalization approaches as [[?DI-EDDSA]], and supports
two different levels of security (128 bit and 192 bit) via two alternative sets
of elliptic curves and hashes, it has only two cryptosuite names:
<q>ecdsa-rdfc-2019</q> and <q>ecdsa-jcs-2019</q>. The security level and corresponding
curves and hashes are determined from the multi-key format of the public key
used in validation.
        </p>
      </section>

      <section>
        <h3>Agility and Layering</h3>

        <p>
<dfn class="lint-ignore">Cryptographic agility</dfn> is a practice by which one designs
<em>frequently connected</em> information security systems to support
<em>switching between multiple cryptographic primitives and/or algorithms</em>. The primary
goal of cryptographic agility is to enable systems to rapidly adapt to new
cryptographic primitives and algorithms without making disruptive changes to the
systems' infrastructure. Thus, when a particular cryptographic primitive, such
as the SHA-1 algorithm, is determined to be no longer safe to use, systems can
be reconfigured to use a newer primitive via a simple configuration file change.
        </p>
        <p>
Cryptographic agility is most effective when the client and the server in
the information security system are in regular contact. However, when the
messages protected by a particular cryptographic algorithm are long-lived, as
with Verifiable Credentials, and/or when the client (holder) might not be
able to easily recontact the server (issuer), then cryptographic agility does
not provide the desired protections.
        </p>
        <p>
<dfn class="lint-ignore">Cryptographic layering</dfn> is a practice where one
designs <em>rarely connected</em> information security systems to
<em>employ multiple primitives and/or algorithms at the same time</em>. The
primary goal of cryptographic layering is to enable systems to survive the
failure or one or more cryptographic algorithms or primitives without losing
cryptographic protection on the payload. For example, digitally signing a single
piece of information using RSA, ECDSA, and Falcon algorithms in parallel would
provide a mechanism that could survive the failure of two of these three digital
signature algorithms. When a particular cryptographic protection is compromised,
such as an RSA digital signature using 768-bit keys, systems can still utilize
the non-compromised cryptographic protections to continue to protect the
information. Developers are urged to take advantage of this feature for all
signed content that might need to be protected for a year or longer.
        </p>
        <p>
This specification provides for both forms of agility. It provides for
cryptographic agility, which allows one to easily switch from one algorithm to
another. It also provides for cryptographic layering, which allows one to
simultaneously use multiple cryptographic algorithms, typically in parallel,
such that any of those used to protect information can be used without reliance
on or requirement of the others, while still keeping the digital proof format
easy to use for developers.
        </p>
        <p>
        </p>
      </section>

      <section>
        <h3>Transformations</h3>

        <p>
At times, it is beneficial to transform the data being protected during the
cryptographic protection process. Such "in-line" transformation can enable a
particular type of cryptographic protection to be agnostic to the data format it
is carried in. For example, some Data Integrity cryptographic suites utilize RDF
Dataset Canonicalization [[?RDF-CANON]] which transforms the initial
representation into a canonical form [[?N-QUADS]] that is then serialized,
hashed, and digitally signed. As long as any syntax expressing the protected
data can be transformed into this canonical form, the digital signature can be
verified. This enables the same digital signature over the information to be
expressed in JSON, CBOR, YAML, and other compatible syntaxes without having to
create a cryptographic proof for every syntax.
        </p>
        <p>
Being able to express the same digital signature across a variety of syntaxes is
beneficial because systems often have native data formats with which they
operate. For example, some systems are written against JSON data, while others
are written against CBOR data. Without transformation, systems that process
their data internally as CBOR are required to store the digitally signed data
structures as JSON (or vice-versa). This leads to double-storing data and can
lead to increased security attack surface if the unsigned representation stored in
databases accidentally deviates from the signed representation. By using
transformations, the digital proof can live in the native data format to
help prevent otherwise undetectable database drift over time.
        </p>
        <p>
This specification is designed to avoid requiring the duplication of signed
information by utilizing "in-line" data transformations. Application developers are urged
to work with cryptographically protected data in the native data format for
their application and not separate storage of cryptographic proofs from the data
being protected. Developers are also urged to regularly confirm that the
cryptographically protected data has not been tampered with as it is written to
and read from application storage.
        </p>
        <p class="advisement">
Some transformations, such as RDF Dataset Canonicalization [[?RDF-CANON]], have
mitigations for input data sets that can be used by attackers to consume
excessive processing cycles. This class of attack is called
<a data-cite="?RDF-CANON#dataset-poisoning">dataset poisoning</a>, and all
modern RDF Dataset canonicalizers are required to detect these sorts of bad
inputs and halt processing. The test suites for RDF Dataset Canonicalization
includes such poisoned datasets to ensure that such mitigations exist in all
conforming implementations. Generally speaking, cryptographic suite
specifications that use transformations are required to mitigate these sorts of
attacks, and implementers are urged to ensure that the software libraries that
they use enforce these mitigations. These attacks are in the same general
category as any resource starvation attack, such as HTTP clients that
deliberately slow connections, thus starving connections on the server.
Implementers are advised to consider these sorts of attacks when implementing
defensive security strategies.
        </p>
        <p class="issue"
          title="Collision-resistant canonicalization requirements">
The VCWG is seeking feedback on normative language that cryptographic suite
implementers need to follow to ensure that they do not utilize data
transformation mechanisms that can map to the same output. That is, given
different inputs for canonicalization scheme #1 and canonicalization scheme #2,
they must not produce the same output value. As an analogy, this is the same
requirement for cryptographic hashing mechanisms and is why those schemes are
designed to be collision resistant. Cryptographic canonicalization mechanisms
have the same requirement. At present, this isn't a problem because the three
expected canonicalization schemes &mdash; the Universal RDF Dataset
Canonicalization Algorithm 2015 [[?RDF-CANON]], JSON Canonicalization
Scheme [[?RFC8785]], and a theoretical future base-encoding canonicalization
&mdash; have entirely different outputs.
        </p>
        <p class="issue"
          title="Avoiding the pitfalls of XML Canonicalization">
The VCWG is seeking feedback on whether to explain why modern canonicalization
schemes are simpler than the far more complex XML Canonicalization schemes of
the early 2000s. Some readers seem to be under the impression that all
canonicalization is difficult and has to be avoided at all costs (including costs
to application developers). The WG would like to understand if it would be helpful
to include a section explaining why some simpler data syntaxes (such as JSON) are
easier to canonicalize than more complex data syntaxes (such as XML).
        </p>
      </section>

      <section>
        <h3>Data Opacity</h3>

        <p>
The inspectability of application data has effects on system efficiency and
developer productivity. When cryptographically protected application data, such
as base-encoded binary data, is not easily processed by application subsystems,
such as databases, it increases the effort of working with the cryptographically
protected information. For example, a cryptographically protected payload that
can be natively stored and indexed by a database will result in a simpler system
that:
        </p>

        <ul>
          <li>
benefits from utilizing existing industry-standard database features with no
changes to the protected information,
          </li>
          <li>
avoids the complexity of duplicating data where one copy of the data preserves
the message and digital signature, while the other copy only stores and indexes
the message and is what drives system behaviour,
          </li>
          <li>
avoids the complexity of bespoke solutions that have to structurally modify
the protected information, such as serializing and deserializing nested
digitally signed data that has multiple nested base-encoded payloads.
          </li>
        </ul>

        <p>
Similarly, a cryptographically protected payload that can be processed by
multiple upstream networked systems increases the ability to properly layer
security architectures. For example, if upstream systems do not have to
repeatedly decode the incoming payload, it increases the ability for a system to
distribute processing load by specializing upstream subsystems to actively
combat attacks. While a digital signature needs to always be checked before
taking substantive action, other upstream checks can be performed on transparent
payloads &mdash; such as identifier-based rate limiting, signature expiration
checking, or nonce/challenge checking &mdash; to reject obviously bad requests.
        </p>
        <p>
Additionally, if a developer is not able to easily view data in a system, the
ability to easily audit or debug system correctness is hampered. For example,
requiring application developers to cut-and-paste base-encoded application data
makes development more challenging and increases the chances that obvious bugs
will be missed because every message needs to go through a manually operated
base-decoding tool.
        </p>
        <p>
There are times, however, where the correct design decision is to make data
opaque. Data that does not need to be processed by other application subsystems,
as well as data that does not need to be modified or accessed by an application
developer, can be serialized into opaque formats. Examples include digital
signature values, cryptographic key parameters, and other data fields that only
need to be accessed by a cryptographic library and need not be modified by the
application developer. There are also examples where data opacity is appropriate
when the underlying subsystem does not expose the application developer to the
underlying complexity of the opaque data, such as databases that perform
encryption at rest. In these cases, the application developer continues to
develop against transparent application data formats while the database manages
the complexity of encrypting and decrypting the application data to and from
long-term storage.
        </p>
        <p>
This specification strives to provide an architecture where application data
remains in its native format and is not made opaque, while other cryptographic
data, such as digital signatures, are kept in their opaque binary encoded form.
Cryptographic suite implementers are urged to consider appropriate use of data
opacity when designing their suites, and to weigh the design trade-offs when
making application data opaque versus providing access to cryptographic data at
the application layer.
        </p>
      </section>

      <section>
        <h3>Verification Method Binding</h3>

        <p class="issue">
Implementers must ensure that a verification method is bound to a particular
controller by going from the verification method to the controller document,
and then ensuring that the controller document also contains the verification
method.
        </p>
      </section>

      <section>
        <h3>Verification Relationship Validation</h3>

        <p>
When an implementation is <a href="#verify-proof">verifying a proof</a>, it is
imperative that it verify not only that the [=verification method=] used to
generate the proof is listed in the [=controller document=], but also that it
was intended to be used to generate the proof that is being verified. This process
is known as "verification relationship validation".
        </p>
        <p>
The process for verification relationship validation is outlined in Section
[[[#retrieve-verification-method]]].
        </p>
        <p>
This process is used to ensure that cryptographic material, such as a private
cryptographic key, is not misused by application to an unintended purpose. An
example of cryptographic material misuse would be if a private cryptographic
key meant to be used to issue a Verifiable Credential was instead used to
log into a website (that is, for authentication). Not checking a verification relationship
is dangerous because the restriction and protection profile for some
cryptographic material could be determined by its intended use. For example,
some applications could be trusted to use cryptographic material for only
one purpose, or some cryptographic material could be more protected,
such as through storage in a hardware security module in a data center
versus as an unencrypted file on a laptop.
        </p>
      </section>

      <section>
        <h3>Proof Purpose Validation</h3>

        <p>
When an implementation is <a href="#verify-proof">verifying a proof</a>, it is
imperative that it verify that the [=proof purpose=] match the intended use.
        </p>

        <p>
This process is used to ensure that proofs are not misused by an application for
an unintended purpose, as this is dangerous for the proof creator. An example of
misuse would be if a proof that stated its purpose was for securing assertions
in [=verifiable credentials=] was instead used for [=authentication=] to
log into a website. In this case, the proof creator attached proofs to any
number of [=verifiable credentials=] that they expected to be distributed to
an unbounded number of other parties. Any one of these parties could log into a
website as the proof creator if the website erroneously accepted such a proof as
[=authentication=] instead of its intended purpose.
        </p>

      </section>

      <section>
        <h3>Canonicalization Method Security</h3>

        <p>
The way in which a transformation, such as canonicalization, is performed can
affect the security characteristics of a system. Selecting the best
canonicalization mechanisms depends on the use case. Often,
the simplest mechanism that satisfies the desired security requirements
is the best choice. This section attempts to provide simple guidance to help
implementers choose between the two main canonicalization mechanisms referred to
in this specification, namely JSON Canonicalization Scheme [[RFC8785]] and
RDF Dataset Canonicalization [[RDF-CANON]].
        </p>
        <p>
If an application only uses JSON and does not depend on any form of RDF
semantics, then using a cryptography suite that uses JSON
Canonicalization Scheme [[RFC8785]] is an attractive approach.
        </p>
        <p>
If an application uses JSON-LD and needs to secure the semantics of
the document, then using a cryptography suite that
uses RDF Dataset Canonicalization [[RDF-CANON]] is an attractive
approach.
        </p>
        <p>
Implementers are also advised that other mechanisms that perform no
transformations are available, that secure the data by wrapping it in a
cryptographic envelope instead of embedding the proof in the data, such as
JWTs [[?RFC7519]] and CWTs [[?RFC8392]]. These approaches have simplicity
advantages in some use cases, at the expense of some of the benefits provided
by the approach detailed in this specification.
        </p>
      </section>

      <section>
        <h3>Canonicalization Method Correctness</h3>

        <p>
One of the algorithmic processes used by this specification is canonicalization,
which is a type of [=transformation=]. Canonicalization is the process of
taking information that might be expressed in a variety of semantically
equivalent ways as input, and expressing all output in a single way, called a
"canonical form".
        </p>
        <p>
The security of a resulting [=data integrity proof=] that utilizes
canonicalization is highly dependent on the correctness of the algorithm. For
example, if a canonicalization algorithm converts two inputs that have different
meanings into the same output, then the author's intentions can be
misrepresented to a [=verifier=]. This can be used as an attack vector by
adversaries.
        </p>
        <p>
Additionally, if semantically relevant information in an input is not present in
the output, then an attacker could insert such information into a message
without causing proof verification to fail. This is similar to another
transformation that is commonly used when cryptographically signing messages:
cryptographic hashing. If an attacker is able to produce the same cryptographic
hash from a different input, then the cryptographic hash algorithm is not
considered secure.
        </p>
        <p>
Implementers are strongly urged to ensure proper vetting of any canonicalization
algorithms to be used for [=transformation=] of input to a [=hashing=]
process. Proper vetting includes, at a minimum, association with a peer reviewed
mathematical proof of algorithm correctness; multiple implementations and vetting
by experts in a standards setting organization is preferred. Implementers are
strongly urged not to invent or use new mechanisms unless they have formal
training in information canonicalization and/or access to experts in the field
who are capable of producing a peer reviewed mathematical proof of algorithm
correctness.
        </p>
      </section>

      <section>
        <h3>Network Requests</h3>

        <p>
This specification is designed in such a way that no network requests are
required when verifying a proof on a [=conforming secured document=].
Readers might note, however, that <a href="#data-model">JSON-LD contexts</a>
and [=verification methods=] can contain URLs that might be retrieved
over a network connection. This concern exists for any URL that might be
loaded from the network during or after verification.
        </p>
        <p>
To the extent possible, implementers are urged to permanently or aggressively
cache such information to reduce the attack surface on an implementation that
might need to fetch such URLs over the network. For example, caching techniques
for <a href="#data-model">JSON-LD contexts</a> are described in Section
[[[#contexts-and-vocabularies]]], and some [=verification methods=], such as
`did:key` [[?DID-KEY]], do not need to be fetched from the network at all.
        </p>
        <p>
When it is not possible to use cached information, such as when a specific HTTP
URL-based instance of a [=verification method=] is encountered for the first
time, implementers are cautioned to use defensive measures to mitigate <a
href="https://en.wikipedia.org/wiki/Denial-of-service_attack">
denial-of-service attacks</a> during any process that might fetch a resource
from the network.
        </p>
      </section>

      <section>
        <h3>Other Security Considerations</h3>

        <p>
Since the technology to secure documents described by this specification is
generalized in nature, the security implications of its use might not be
immediately apparent to readers. To understand the sort of security
concerns one might need to consider in a complete software system, implementers
are urged to read about how this technology is used in the
[=verifiable credentials=] ecosystem [[?VC-DATA-MODEL-2.0]]; see the section
on <a data-cite="?VC-DATA-MODEL-2.0#security-considerations">
Verifiable Credential Security Considerations</a> for more information.
        </p>
      </section>

    </section>

    <section>
      <h2>Privacy Considerations</h2>
      <p>
The following section describes privacy considerations that developers
implementing this specification should be aware of in order to create
privacy enhancing software.
      </p>

      <section>
        <h3>Unlinkability</h3>

        <p>
When a digitally-signed payload contains data that is seen by multiple
verifiers, it becomes a point of correlation. An example of such data is a
shopping loyalty card number. Correlatable data can be used for tracking
purposes by verifiers, which can sometimes violate privacy expectations. The
fact that some data can be used for tracking might not be immediately apparent.
Examples of such correlatable data include, but are not limited to, a static
digital signature or a cryptographic hash of an image.
        </p>

        <p>
It is possible to create a digitally-signed payload that does not have any
correlatable tracking data while also providing some level of assurance that the
payload is trustworthy for a given interaction. This characteristic is called
<dfn class="lint-ignore">unlinkability</dfn> which ensures that no correlatable
data are used in a digitally-signed payload while still providing some level of
trust, the sufficiency of which must be determined by each verifier.
        </p>

        <p>
It is important to understand that not all use cases require or even permit
unlinkability. There are use cases where linkability and correlation are
required due to regulatory or safety reasons, such as correlating organizations
and individuals that are shipping and storing hazardous materials. Unlinkability
is useful when there is an expectation of privacy for a particular interaction.
        </p>

        <p>
There are at least two mechanisms that can provide some level of unlinkability.
The first method is to ensure that no data value used in the message is ever
repeated in a future message. The second is to ensure that any repeated data
value provides adequate herd privacy such that it becomes practically impossible
to correlate the entity that expects some level of privacy in the interaction.
        </p>

        <p>
A variety of methods can be used to achieve unlinkability. These methods include
ensuring that a message is a single use bearer token with no information that
can be used for the purposes of correlation, using attributes that ensure an
adequate level of herd privacy, and the use of cryptosuites that enable the
entity presenting a message to regenerate new signatures while not compromising
the trust in the message being presented.
        </p>
      </section>

      <section>
        <h3>Selective Disclosure</h3>

        <p>
Selective disclosure is a technique that enables the recipient of a
previously-signed message (that is, a message signed by its creator) to reveal
only parts of the message without disturbing the verifiability of those
parts. For example, one might selectively disclose a digital driver's license for
the purpose of renting a car. This could involve revealing only the issuing
authority, license number, birthday, and authorized motor vehicle class from
the license. Note that in this case, the license number is correlatable
information, but some amount of privacy is preserved because the driver's
full name and address are not shared.
        </p>

        <p>
Not all software or cryptosuites are capable of providing selective disclosure.
If the author of a message wishes it to be selectively disclosable by its
recipient, then they need to enable selective disclosure on the specific
message, and both need to use a capable cryptosuite. The author might also make
it mandatory to disclose certain parts of the message. A recipient that wants to
selectively disclose partial content of the message needs to utilize software
that is able to perform the technique. An example of a cryptosuite that supports
selective disclosure is `bbs-2023`.
        </p>

        <p>
It is possible to selectively disclose information in a way that does not
preserve unlinkability. For example, one might want to disclose the inspection
results related to a shipment, which include the shipment identifier or lot
number, which might have to be correlatable due to regulatory requirements.
However, disclosure of the entire inspection result might not be required as
selectively disclosing just the pass/fail status could be deemed adequate. For
more information on disclosing information while preserving privacy, see Section
[[[#unlinkability]]].
        </p>
      </section>

      <section>
        <h3>Previous Proofs</h3>

        <p>
When using the `previousProof` feature defined in [[[#proof-chains]]],
implementations are required to digitally sign over one or more previous proofs,
so as to include them in the secured payload. This inevitably exposes
information related to each entity that added a previous proof.
        </p>
        <p>
At minimum, the [=verification method=] for the previous proof, such as a
public key, is seen by the creator of the next proof in a proof chain. This
can be a privacy concern if the creator of the previous proof did not intend
to be included in a proof chain, but is an inevitable outcome when
adding a non-repudiable digital signature to a document of any kind.
        </p>
        <p>
It is possible to use more advanced cryptographic mechanisms, such as a
<a href="https://en.wikipedia.org/wiki/Group_signature">group signature</a>,
to hide the identity of the signer of a message,
and it is also possible for a Data Integrity cryptographic suite
to mitigate this privacy concern.
        </p>
      </section>

      <section>
        <h3>Fingerprinting Network Requests</h3>

        <p>
Fingerprinting concerns exist for any URL that might be loaded from the network
during or after <a href="#verify-proof">proof verification</a>. This
specification is designed in such a way that no network requests are necessary
when verifying a proof on a [=conforming secured document=]. Readers might
note, however, that <a href="#data-model">JSON-LD contexts</a> and
[=verification methods=] can contain resource URLs that might be retrieved
over a network connection leading to fingerprinting concerns.
        </p>

        <p>
For example, creators of [=conforming documents=] might craft unique
per-document URLs for <a href="#data-model">JSON-LD contexts</a> and
[=verification methods=]. When verifying such a document, a verifier fetching
that information from the network would reveal their interest in the
[=conforming document=] to the creator of the document, which might lead to
a mismatch in privacy expectations for any entity that is not the creator of
the document.
        </p>

        <p>
Implementers are urged to follow the guidance in Section [[[#network-requests]]]
on URL caching and implementing defensively when fetching URLs from the network.
Usage of techniques such as
<a href="https://datatracker.ietf.org/doc/html/draft-ietf-ohai-ohttp">
Oblivious HTTP</a> to retrieve resources from the network, without revealing the
client that is making the request, are encouraged. Additionally, heuristics
might be used to determine whether creators of [=conforming documents=] are
using fingerprinting URLs in a way that might violate privacy expectations.
These heuristics could be used to display warnings to entities that might
process documents containing suspected fingerprinting URLs.
        </p>
      </section>

      <section>
        <h3>Canonicalization Method Privacy</h3>

        <p>
The way in which a transformation, namely canonicalization, is performed can
affect the privacy characteristics of a system. Selecting the best
canonicalization mechanism depends on the use case.
This section attempts to provide simple guidance to help
implementers pick between the two main canonicalization mechanisms referred to
in this specification, namely JSON Canonicalization Scheme [[RFC8785]] and
RDF Dataset Canonicalization [[RDF-CANON]], from a privacy perspective.
        </p>
        <p>
If an application does not require performing a selective disclosure of
information in a secured document, nor does it utilize JSON-LD, then JSON
Canonicalization Scheme [[RFC8785]] is an attractive approach.
        </p>
        <p>
If an application uses JSON-LD and might require selective disclosure
of information in a secured document, then using a cryptography suite that
uses RDF Dataset Canonicalization [[RDF-CANON]] is an attractive
approach.
        </p>
        <p>
Implementers are also advised that other selective disclosure mechanisms that
perform no transformations are available, that secure the data by wrapping it in a
cryptographic envelope instead of embedding the proof in the data, such as
SD-JWTs [[?SD-JWT]]. This approach has simplicity advantages in some use cases,
at the expense of some of the benefits provided by the approach detailed in
this specification.
        </p>
      </section>

      <section>
        <h3>Other Privacy Considerations</h3>

        <p>
Since the technology to secure documents described by this specification is
generalized in nature, the privacy implications of its use might not be
immediately apparent to readers. To understand the sort of privacy
concerns one might need to consider in a complete software system, implementers
are urged to read about how this technology is used in the
[=verifiable credentials=] ecosystem [[?VC-DATA-MODEL-2.0]]; see the section
on <a data-cite="?VC-DATA-MODEL-2.0#privacy-considerations">
Verifiable Credential Privacy Considerations</a> for more information.
        </p>
      </section>

    </section>

    <section>
      <h2>Accessibility Considerations</h2>
      <p>
The following section describes accessibility considerations that developers
implementing this specification are urged to consider in order to ensure that
their software is usable by people with different cognitive, motor, and visual
needs. As a general rule, this specification is used by system software and does
not directly expose individuals to information subject to accessibility
considerations. However, there are instances where individuals might be
indirectly exposed to information expressed by this specification and thus the
guidance below is provided for those situations.
      </p>

      <section>
        <h2>Presenting Time Values</h2>
        <p>
This specification enables the expression of dates and times related to the
validity period of cryptographic proofs. This information might be indirectly
exposed to an individual if a proof is processed and is detected to be outside
an allowable time range. When exposing these dates and times to an individual,
implementers are urged to take into account
<a data-cite="?VC-DATA-MODEL-2.0#representing-time">cultural normas and locales
when representing dates and times</a> in display software. In addition to these
considerations, presenting time values in a way that eases the cognitive burden
on the individual receiving the information is a suggested best practice.
        </p>
        <p>
For example, when conveying the expiration date for a particular set of
digitally signed information, implementers are urged to present the time of
expiration using language that is easier to understand rather than language that
optimizes for accuracy. Presenting the expiration time as "This ticket expired
three days ago." is preferred over a phrase such as "This ticket expired on July
25th 2023 at 3:43 PM." The former provides a relative time that is easier to
comprehend than the latter time, which requires the individual to do the
calculation in their head and presumes that they are capable of doing such a
calculation.
        </p>
      </section>

    </section>

    <section class="informative">
      <h2>Revision History</h2>

      <p>
This section contains the substantive changes that have been made to this
specification over time.
      </p>

      <p>
Changes since the
<a href="https://www.w3.org/TR/2022/WD-vc-data-integrity-20221110/">
First Public Working Draft</a>:
      </p>
      <ul>
        <li>
Added a section on proof purpose validation.
        </li>
        <li>
Refactored chained proof functionality.
        </li>
        <li>
Added the algorithm to retrieve a verification method.
        </li>
        <li>
Added `JsonWebKey` and `Multikey` definitions and context files.
        </li>
        <li>
Deprecated `Ed25519Signature2020` and moved into separate specification.
        </li>
        <li>
Updated Multibase and Multihash references and add text to normatively define
certain Multikey values.
        </li>
        <li>
Added Internationalization and Accessibility Considerations sections.
        </li>
        <li>
Added cryptographic hashes for context and vocabulary files and note that those
files are to be cached.
        </li>
        <li>
Added section on relationship to Linked Data and Verifiable Credentials.
        </li>
        <li>
Added algorithms for proof sets and chains.
        </li>
        <li>
Added `nonce` and `expires` to proofs.
        </li>
        <li>
Added requirement to protect terms in JSON-LD mode.
        </li>
        <li>
Required cryptosuite specifications that do RDF canonicalization to abort when
poison graphs are detected.
        </li>
        <li>
Added section on how context injection is implemented.
        </li>
        <li>
Added error definitions with anchors to specification and vocabulary.
        </li>
        <li>
Added definitions for secret key expression.
        </li>
        <li>
Added `revoked` and `expires` to verification methods.
        </li>
        <li>
Updated proof `domain` property to allow for an array of values.
        </li>
        <li>
Added `cryptosuiteString` type to proofs to enable proof compression.
        </li>
        <li>
Added `digestMultibase` property and `multibase` data type for securing remote
content, and guidance on adding `digestMultibase` to contexts.
        </li>
        <li>
Narrowed date time values to use `dateTimeStamp`.
        </li>
        <li>
Ensure that base URL is set to null when processing as RDF.
        </li>
        <li>
Added requirement that `DataIntegrityProof` objects need to contain the `cryptosuite` property.
        </li>
      </ul>
    </section>
    <section class="appendix informative">
      <h2>Understanding Proof Sets and Proof Chains</h2>
      <p>
Sections [[[#proof-sets]]] and [[[#proof-chains]]] describe how multiple proofs
can be expressed in a [=secured data document=]; that is, instead of a single
[=proof=] included in the [=secured data document=], one can express multiple
proofs in an array as shown in [[[#example-a-proof-set-in-a-data-document]]] and
[[[#example-a-proof-chain-in-a-data-document]]]. The elements of this array are
members of a [=proof set=] and, optionally, a [=proof chain=]. The purpose of
this section is to explain the intended use of each of these features and, in
particular, their differing security properties. These differing security
properties lead to differences in the processing in section
[[[#add-proof-set-chain]]].
      </p>
      <p>
This section represents [=secured data documents=], including their proofs, in
an abbreviated manner so that the important security properties can be
observed.
      </p>
      <p>
Consider a scenario with three signatories: a CEO, a CFO, and a VP of
Engineering. Each will need to have a public key and secret key pair for signing
a document. We denote the secret/public keys of each of these signatories by
<em>secretCEO/publicCEO</em>, <em>secretCFO/publicCFO</em>, and
<em>secretVPE/publicVPE</em>, respectively.
      </p>
      <p>
When constructing a [=proof set=] where each of the signatories signs an
|unsecuredDataDocument| without concern, we construct a proof symbolically as:
      </p>
      <pre class="example nohighlight" title="Symbolic expression of how a proof is created">
{
  "type": "DataIntegrityProof",
  "cryptosuite": "eddsa-jcs-2022",
  "created": "2023-03-05T19:23:24Z",
  "proofPurpose": "assertionMethod",
  "verificationMethod": <code>publicCEO</code>,
  "proofValue": <strong>signature(<code>secretCEO</code>, <code>unsecuredDataDocument</code>)</strong>
}
      </pre>
      <p>
Where <em>publicCEO</em> is used as a placeholder for a reference that resolves
to the CEO's public key and <strong>signature(`secretKey`,
`unsecuredDataDocument`)</strong> denotes the computation of a digital signature
by a particular data integrity cryptosuite using a particular secret key over a
particular document. The `type`, `cryptosuite`, `created`, and `proofPurpose`
attributes do not factor into our discussion so we will omit them. In
particular, below we show all the proofs in a [=proof set=] on a document that
has been signed by the VP of Engineering, the CFO, and the CEO:
      </p>
      <pre class="example nohighlight" title="Symbolic expression of a proof set">
{
  <span class="comment">// Remainder of secured data document not shown (above)</span>
  "proof": [{
    "verificationMethod": <code>publicVPE</code>,
    "proofValue": <strong>signature(<code>secretVPE</code>, <code>unsecuredDataDocument</code>)</strong>
  }, {
    "verificationMethod": <code>publicCFO</code>,
    "proofValue": <strong>signature(<code>secretCFO</code>, <code>unsecuredDataDocument</code>)</strong>
  }, {
    "verificationMethod": <code>publicCEO</code>,
    "proofValue": <strong>signature(<code>secretCEO</code>, <code>unsecuredDataDocument</code>)</strong>
  }]
}
      </pre>
      <p>
A [=holder=] or any other intermediary receiving a [=secured data document=]
containing a [=proof set=] is able to remove any of the `proof` values within
the set prior to passing it on to another entity and the [=secured data
document=] will still verify. This might or might not have been the intent. For
the signatories sending a birthday card to a valued employee, using a [=proof
set=] is probably fine. If we are trying to model a business process where
approvals ascend the company hierarchy, this would not be ideal, since any
intermediary could remove signatures from the [=proof set=] and still have it
verify; for instance, in the example below, it looks like the CFO and CEO
approved something without the VP of Engineering's concurrence.
      </p>
      <pre class="example nohighlight" title="Removal of a signature in a proof set">
{
  <span class="comment">// Remainder of secured data document not shown (above)</span>
  "proof": [{
    "verificationMethod": <code>publicCFO</code>,
    "proofValue": <strong>signature(<code>secretCFO</code>, <code>unsecuredDataDocument</code>)</strong>
  }, {
    "verificationMethod": <code>publicCEO</code>,
    "proofValue": <strong>signature(<code>secretCEO</code>, <code>unsecuredDataDocument</code>)</strong>
  }]
}
      </code></pre>
      <p>
It is possible to introduce a dependency between [=proofs=] in a [=proof set=]
by setting the `id` property of each proof such that another proof can reference
it. In other words, a <em>dependent proof</em> will be referenced by other
<em>relying proofs</em> by using the `previousProof` property. Such
<em>dependency chains</em> can have arbitrary depth. The <strong>intent</strong>
of such a [=proof chain=] is to model an approval chain in a business process or
a notary witnessing analog signatures.
      </p>
      <p>
The examples below demonstrate how a [=proof chain=] can be constructed when the
VP of Engineering signs off on the document first; based on the VP of
Engineering's signature and a review, the CFO then signs off on the document;
and finally, based on both prior signatures and a review, the CEO signs off on
the document. Since others will be referring to the VP of Engineering's
signature, we need to add an `id` to the proof. First the VP of
Engineering signs the [=unsecured data document=]:
      </p>
      <pre class="example nohighlight"
        title="Proof chain containing first proof with `id` property set">
{
  <span class="comment">// Remainder of secured data document not shown (above)</span>
  "proof": {
    <span class="highlight">"id": "urn:proof-1"</span>,
    "verificationMethod": <code>publicVPE</code>,
    "proofValue": <strong>signature(<code>secretVPE</code>, <code>unsecuredDataDocument</code>)</strong>
  }
}
      </pre>
      <p>
Next, the CFO receives the document, verifies that the VP of Engineering signed
it, and signs it based on a review and on the signature of the VP of
Engineering. For this, we need to set up the [=proof chain=] by indicating a
dependency on the proof in the document just received. We do this by
setting the `previousProof` property of the second proof to the value
`urn:proof-1`, which "binds" the second proof to the first proof, which is
then signed. The following example shows how the dependency on the first proof
is created:
      </p>
      <pre class="example nohighlight" title="Proof chain containing two proofs">
{
  <span class="comment">// Remainder of secured data document not shown (above)</span>
  "proof": [{
    "id": "urn:proof-1",
    "verificationMethod": <code>publicVPE</code>,
    "proofValue": <strong>signature(<code>secretVPE</code>, <code>unsecuredDataDocument</code>)</strong>
  }, {
    "id": "urn:proof-2",
    "verificationMethod": <code>publicCFO</code>,
    <span class="highlight">"previousProof": "urn:proof-1"</span>,
    "proofValue": <strong>signature(<code>secretCFO</code>, <code>unsecuredDataDocumentWithProof1</code>)</strong>
  }]
}
      </pre>
      <p>
Now, when the CEO verifies the received [=secured data document=] with the
above [=proof chain=], they will check that the CFO signed based on the
signature of the VP of Engineering. First, they will check the proof with an
`id` property whose value is `urn:proof-1` against the public key of the VP of
Engineering. Note that this proof is over the original document.
      </p>
      <p>
Next, the CEO will check the proof with an `id` property whose value is
`urn:proof-2` against the public key of the CFO. However, to make sure that the
CFO signed the document with proof that the VP of Engineering had already
signed, we verify this proof over the combination of the document and
`urn:proof-1`. If verification is successful, the CEO signs, producing a proof
over the document which includes `urn:proof-1` and `urn:proof-2`. The final
[=proof chain=] looks like this:
      </p>
      <pre class="example nohighlight" title="Proof chain containing three proofs">
{
  <span class="comment">// Remainder of secured data document not shown (above)</span>
  "proof": [{
    "id": "urn:proof-1",
    "verificationMethod": <code>publicVPE</code>,
    "proofValue": <strong>signature(<code>secretVPE</code>, <code>unsecuredDataDocument</code>)</strong>
  }, {
    "id": "urn:proof-2",
    "verificationMethod": <code>publicCFO</code>,
    "previousProof": "urn:proof-1",
    "proofValue": <strong>signature(<code>secretCFO</code>, <code>unsecuredDataDocumentWithProof1</code>)</strong>
  }, {
    "id": "urn:proof-3",
    "verificationMethod": <code>publicCEO</code>,
    "previousProof": "urn:proof-2",
    "proofValue": <strong>signature(<code>secretCEO</code>, <code>unsecuredDataDocumentWithProof2</code>)</strong>
  }]
}
      </pre>
      <p>
The recipient of this [=secured data document=] then validates it in a similar
way, checking each proof in the chain.
      </p>
    </section>

    <section class="informative">
      <h2>Acknowledgements</h2>

      <p>
The specification authors would like to thank the base-x software library
contributors and the Bitcoin Core developers who wrote the original code, shared
under an MIT License, found in Section [[[#base-encode]]] and Section
[[[#base-decode]]].
      </p>
  </body>
</html>
